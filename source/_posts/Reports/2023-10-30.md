# 一、BuilDiff

[weiyao1996/BuilDiff: BuilDiff: 3D Building Shape Generation using Single-Image Conditional Point Cloud Diffusion Models (github.com)](https://github.com/weiyao1996/BuilDiff)

主要包括：
- 图像编码器，将图片编码为潜在特征向量 z
  - 不是使用在公共图像数据库(例如 ImageNet[4])上预训练的编码器直接将输入图像映射到~~作为建筑物模糊条件的~~潜在特征向量，**而是对编码器进行微调，并使用训练集的建筑物图像训练额外的解码器**
- 降噪网络(基于 **PVCNNs**：可以看作对点云做卷积，输入输出都是点云数据)
  - 输入：噪声点云 $x_t \in \mathbb{R}^{K \times 3}$ (K 是点的数量)、图片特征向量 $z_I \in \mathbb{R}^d$、时间/步数 t 编码后的特征向量
  - 输出：预测出来的噪声 $\epsilon_\theta(x_t,t,z_I)\in\mathbb{R}^{K\times3}$
  - 网络结构：集合抽象 SA，特征传播 FP(PointNet++中提出)
    - SA：将点云中的主要点提取出来
    - FP：将主要点的特征传播到所有初始点，可以得到每个点的分数(识别出噪声点云)


**降噪网络**
![image.png|666](https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231024104815.png)

## 1.1 BuilDiff 训练流程

![image.png|666](https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231021114740.png)

### 1.图像编码器训练

![image.png|666](https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231023200406.png)

图像 $I$ 经过编码后得到 $z_{I}$，解码后得到 $\hat I$

整个编码网络的训练损失：$\mathcal L_{AE}=\mathcal L_{rec}(I,\hat{I})+\mathcal L_{con}(z_{I},z_{I}^{a})$

### 2.以图像为条件的点云扩散

![image.png|444](https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231024111221.png)

- 从 GT 点云数据集 $q(x_{0})$ 中采样一个 $x_{0}$，从高斯分布中采样一个噪声 $\epsilon$
- 从 1~T 步中采样一个步骤 t
- 对 $x_{0}$ 加噪：$x_{t}=\sqrt{\bar{\alpha}_{t}}x_{0}+\sqrt{1-\bar{\alpha}_{t}}\epsilon$
- **求噪声损失**：$\mathcal{L}_{eps}=\left\|\epsilon-\epsilon_\theta(x_t,t,z_I)\right\|^2$
- 得到降噪后的点云：$\hat{x}_0=\frac{1}{\sqrt{\bar{\alpha}_t}}(x_t-\sqrt{1-\bar{\alpha}_t}\epsilon_\theta(x_t,t,z_I))$
- **求投影损失**：$\mathcal{L}_{reg}=\lambda(t)\Omega(proj(x_0),proj(\hat{x}_0))$，将 $x_0$ 和 $\hat x_{0}$ 投影到 ground 地面上（将生成的建筑物点云投影到地面上）
- 两个损失共同优化降噪网络 $\epsilon_\theta$

### 3.点云上采样扩散

以**图像编码** $z_I$ 和**由基础扩散推断的低分辨率点云**作为输入，目标在于生成具有细粒度结构的高分辨率点云

目的：从 $x_0 \in \mathbb{R}^{K \times 3}$ 中得到 $x_0\in\mathbb{R}^{N\times3}$ (N > K)，本文 N=4096, K=1024

与 2 中的训练结构类似，只是多了一个低分辨率点云作为输入

## 1.2网络基础
### a.PointNet++

[PointNet++：点集在度量空间中的深度层次特征学习 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/482689844)

SA：set abstraction，**将点云中的主要点提取出来**
- PVCs(sampling)：提取点云特征，从输入点中选择点集，点集中的点定义了局部区域的质心
- Group(grouping)：寻找质心周围的“邻域”点来构建局部区域集
- MLPs(pointnet)：使用一个 MLP 编码局部区域模式为特征向量

FP：feature propagatin，**将主要点的特征传播到所有初始点**
- 最近邻插值 Nearest-Neighbor-Interpolation(Interpolation)
- MLPs
- PVCs

降噪网络中的SA和FP：
![image.png|666](https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231024104815.png)

**PointNet++结构：可以用于点的分类和分割**
![image.png|666](https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231030154311.png)

**PointNet结构**
![image.png|666](https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231030155645.png)

### b.PVCNN(PointVoxel CNN)

[PVCNN论文阅读 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/209229692)

先前的方法：
- 基于体素的点云深度学习方法，虽然体素化相对于[最远点采样](https://blog.csdn.net/minhuaQAQ/article/details/107280596)更快，但是如果想要获得高分辨率的体素化结果，其内存占用和计算耗时会 **cubically(立方级别)** 增长
- 基于点的点云深度学习方法，虽然内存占用很少，但受点云稀疏性的影响，大概有 80% 的时间都消耗在点云计算的准备工作中，所以直接处理点云可能比较耗时

PVCNN 体素卷积优势：
- 以点的形式存储数据，减少内存占用
- 以体素化形式进行卷积，避免处理点云的不规则、稀疏性带来的数据访问耗时，提高局部感知能力

PVConvs 结构：

![image.png|666](https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231024222944.png)


# 二、RODIN

[RODIN Diffusion (microsoft.com)](https://3d-avatar-diffusion.microsoft.com/)

- BuilDiff 中使用点云作为 3D 表示
- RODIN 使用**三个轴向正交特征平面**来作为 3D 表示

![image.png|666](https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231028214552.png)

RODIN主要思路：
- 输入图像、文本、z(为了可以做到无条件输入的生成)，根据扩散模型生成**三个轴向正交特征平面**
- 将查询的三维点投影到三个平面上得到特征，并将特征聚合在一起
- 根据聚合特征和观察方向，经过MLP，输出每个点的密度和颜色(NeRF)
- ...