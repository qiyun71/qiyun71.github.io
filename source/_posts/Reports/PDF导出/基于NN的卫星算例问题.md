#### 讨论

- 根据目标参数expT的均值(7,1,2,1)和标准差(0.3,0.2,0.4,0.2)，生成服从正态分布的m组exp数据
  - 生成的数据根据torch.mean和torch.std再计算会有一定偏差，比如表中正态分布生成m=100组exp数据和m=1000组exp数据，1000组数据经过再次计算得到的均值和标准差，相较于100组偏差更小
- 对m组的实验FR数据进行修正，得到m组修正后的参数，然后根据torch.mean和torch.std再计算得到均值和标准差
  - 论文中是跟原始的（用于生成分布的）均值和标准差进行对比，但是实际应该与再计算的均值和标准差进行比较才更准确

|                | expT | 100组exp    | pred1  | pred2  | pred3  | 1000组exp   | pred1  | pred2  | pred3  |
| -------------- | ---- | ---------- | ------ | ------ | ------ | ---------- | ------ | ------ | ------ |
| $\mu_E$        | 7    | **6.9781** | 6.9613 | 6.9696 | 6.9764 | **6.9981** | 6.9762 | 6.9833 | 6.9874 |
| $\mu_{T_1}$    | 1    | **1.0415** | 1.0320 | 1.0368 | 1.0120 | **1.0061** | 0.9951 | 1.0041 | 1.0197 |
| $\mu_{T_2}$    | 2    | **2.0619** | 2.0641 | 2.0557 | 2.0562 | **2.0008** | 2.0005 | 1.9978 | 1.9730 |
| $\mu_{T_3}$    | 1    | **1.0046** | 1.0055 | 1.0031 | 1.0062 | **0.9965** | 0.9968 | 0.9941 | 0.9940 |
| $\sigma_{E}$   | 0.3  | **0.3235** | 0.3385 | 0.3333 | 0.3436 | **0.2940** | 0.3263 | 0.3161 | 0.3219 |
| $\sigma_{T_1}$ | 0.2  | **0.1961** | 0.1935 | 0.1899 | 0.1731 | **0.1905** | 0.1942 | 0.1884 | 0.1861 |
| $\sigma_{T_3}$ | 0.4  | **0.3903** | 0.3965 | 0.3904 | 0.3790 | **0.3828** | 0.3918 | 0.3858 | 0.3789 |
| $\sigma_{T_3}$ | 0.2  | **0.1954** | 0.1959 | 0.1928 | 0.1916 | **0.1932** | 0.1928 | 0.1912 | 0.1899 |
| ER_T(%)        | 0    | 2.82       | 3.31   | 3.67   | 5.30   | 1.93       | 2.31   | 2.56   | 3.58   |
| ER(%)          |      | 0          | 1.14   | 1.07   | 3.26   | 0          | 2.12   | 1.40   | 2.21   |

说明
- pred1：归一化处理FR数据、500epoch训练结果
- pred2：归一化处理FR数据、1000epoch训练结果
- pred3：不归一化，500epoch训练结果
- ER\_T(%) = $\frac{1}{8} \sum\limits_{i=1}^8 \frac{|pred_i-expT_i|}{expT_i}$ x100 (%)，**论文中关注的是这个指标**
- ER(%) = $\frac{1}{8} \sum \limits_{i=1}^8 \frac{|pred_i-exp_i|}{exp_i}$ x100 (%)，**实际应该是这个指标更准确一点**

由平均误差，可以看出：
1. **归一化处理**pred1比没有归一化处理pred3，训练的网络精度高~~（主要是方差精度，excel可以看出）~~
2. **epoch** 越多，ER越低(这是正常的)，但是ER_T会更高，这是由于ER_T是(pred)与生成分布时地均值和标准差(expT)对比的，exp与expT的误差与pred与exp的误差累积了(两个随机相互影响)
3. **数据量m**越多，ER_T更低，但是ER反而会更高(未归一化pred3反而更低)，**此外数据量多了还有一个问题**：

这是训练集 label（这副图的exp和updated是同一个变量，两者都是label）
![image.png|666](https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20240308143958.png)

使用测试集测试网络训练的精度（均匀分布生成的测试集）
![image.png|666](https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20240308144116.png)

实验数据得到修正结果(m=1000)（正态分布）
![image.png|666](https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20240308144229.png)

**问题**：$T_3$预测的分布规律奇怪，虽然也是正态分布，但是大多数值集中在了1.0、1.1等间隔0.1的位置
**分析**：神经网络对$T_3$不敏感，网络预测将$T_3$小数点后两位的数省略了（只识别出了1.0、1.1mm等规律的值），且这一现象与**是否对FR归一化**无关，没有归一化的预测也有这个现象：

![image.png|666](https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20240308165855.png)


实验数据(m=100)，数据量少的时候，这种特征还不明显
![image.png|666](https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20240308144522.png)

