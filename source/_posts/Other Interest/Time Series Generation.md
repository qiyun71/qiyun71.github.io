---
title: Time Series Generation (Uncertainty)
date: 2024-09-20 22:33:08
tags: 
categories: Other Interest
---

[Time Series Generation | Papers With Code](https://paperswithcode.com/task/time-series-generation/latest)
- ç”Ÿæˆæ ·æœ¬ï¼Œè§£å†³æ ·æœ¬ä¸è¶³çš„é—®é¢˜

<!-- more -->

# Review

## [GAN](https://dl.acm.org/doi/pdf/10.1145/3559540)

>[Generative Adversarial Networks in Time Series: A Systematic Literature Review](https://dl.acm.org/doi/pdf/10.1145/3559540)

- Autoregressive (AR) to forecast data point of time seriesï¼š$x_{t+1} = c + \theta_1x_t + \theta_2x_{t-1} + \epsilon$ã€‚ç„¶è€Œå…¶å†…åœ¨æ˜¯ç¡®å®šæ€§çš„ç”±äºæ²¡æœ‰åœ¨æœªæ¥ç³»ç»ŸçŠ¶æ€çš„è®¡ç®—ä¸­å¼•å…¥éšæœºæ€§
- Generative Methodsï¼š
  - Autoencoder (AE)
  - variational autoencoders (VAEs)
  - recurrent neural network (RNN)
  - GAN is inherent instability, suffer from issues: 
    - non-convergence, A non-converging model does not stabilize and continuously oscillates, causing it to diverge. 
    - diminishing/vanishing gradients, Diminishing gradients prevent the generator from learning anything, as the discriminator becomes too successful. 
    - mode collapse. Mode collapse is when the generator collapses, producing only uniform samples with little to no variety.
    - æ²¡æœ‰æ¯”è¾ƒå¥½çš„è¯„ä»·æŒ‡æ ‡

GAN Model task: ç”Ÿæˆå™¨Gè¦æœ€å¤§åŒ–åˆ¤åˆ«å™¨Dçš„é”™è¯¯ç‡ï¼Œè€Œåˆ¤åˆ«å™¨Dåˆ™æ˜¯è¦æœ€å°åŒ–å…¶é”™è¯¯ç‡
$$\min_{G}\max_{D}V(G,D)=\mathbb{E}_{x\sim p_{data}(x)}[logD(\mathbf{x})]+\mathbb{E}_{z\sim p_{z}(z)}[log(1-D(G(\mathbf{z})))]$$

![image.png|666](https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240924163352.png)

åº”ç”¨ï¼š
- Data Augumentation
- Imputation
- Denoising
- Anomaly Detectionå¼‚å¸¸æ£€æµ‹

# Diffusion

## [Diffusion TS](https://openreview.net/pdf?id=4h1apFjO99) 2024

Diffusion + Transformer

UNCONDITIONAL TIME SERIES GENERATIONï¼Œè¾“å…¥çš„æ˜¯å™ªå£°æ•°æ® `img = torch.randn(shape, device=device)`
CONDITIONAL TIME SERIES GENERATIONï¼šè¿™é‡Œçš„æ¡ä»¶ä»£è¡¨çš„ä¹Ÿæ˜¯time series(ç¼ºå¤±éƒ¨åˆ†æ•°æ®)
- Imputation è¡¥å…¨
- Forecasting é¢„æµ‹

>[Y-debug-sys/Diffusion-TS: [ICLR 2024] Official Implementation of "Diffusion-TS: Interpretable Diffusion for General Time Series Generation"]( https://github.com/y-debug-sys/diffusion-ts ) code

æ—¶é—´åºåˆ—æ•°æ®å¯åˆ†ä¸º: 
- è¶‹åŠ¿é¡¹ Trend+å‘¨æœŸé¡¹ Seasonality+è¯¯å·®é¡¹ Error
- $x_j=\zeta_j+\sum_{i=1}^ms_{i,j}+e_j,\quad j=0,1,\ldots,\tau-1,$
- $\hat{x}_0(x_t,t,\theta)=V_{tr}^t+\sum_{i=1}^DS_{i,t}+R$

Trend: $V_{tr}^t=\sum_{i=1}^D(\boldsymbol{C}\cdot\mathrm{Linear}(w_{tr}^{i,t})+\mathcal{X}_{tr}^{i,t}),\quad\boldsymbol{C}=[1,c,\ldots,c^p]$
- D ä»£è¡¨ç”± D ä¸ª Decoder block
- $\mathcal{X}_{tr}^{i,t}$ æ˜¯ i-th ä¸ª Decoder block è¾“å‡ºçš„å‡å€¼ï¼Œ*è¶‹åŠ¿é¡¹åŠ ä¸Šè¿™ä¸ªå¯ä»¥è®©å…¶åœ¨yè½´ä¸Šä¸‹ç§»åŠ¨*ï¼Œè¯¥é¡¹çš„ç´¯åŠ åœ¨ä»£ç ä¸­å¹¶ä¸æ˜¯ç®€å•çš„æ±‚å’Œï¼Œ è€Œæ˜¯é€šè¿‡ä¸€ä¸ªconv1dæ¥åŠ¨æ€è°ƒæ•´æ±‚å’Œæ—¶çš„æƒé‡ï¼Œæ­¤å¤–è¿˜ä¼šåŠ ä¸Šæœ€åä¸€ä¸ªdecoder blockè¾“å‡ºçš„å‡å€¼
- C is the matrix of powers of vector $c=\frac{[0,1,2,\dots,\tau-2,\tau-1]^{T}}{\tau}$ $\tau$ is the time series length
  - $y=a_{0}+a_{1}x+a_{2}x^{2}+a_{3}x^{3}+\dots+a_{p}x^{p}$ , 
    - ç³»æ•°aå³ç½‘ç»œçš„è¾“å‡º$\mathrm{Linear}(w_{tr}^{i,t})$
    -  $x,x^{2},x^{3}\dots,x^{p}$  **æœ¬è´¨ä¸Šæ˜¯é€šè¿‡Cæ¥è¡¨ç¤º**
- P is a small degree (p=3) to model low frequency behavior  p=3ä»£è¡¨ç”¨3é˜¶æ¥æ‹Ÿåˆè¶‹åŠ¿é¡¹å·²ç»è¶³å¤Ÿ

TrendBlock:
- Input: input $w_{tr}^{i,t}$ 
- Output: trend_vals $\boldsymbol{C}\cdot\mathrm{Linear}(w_{tr}^{i,t})$

```python
###### TrendBlock ######
# forward:
b, c, h = input.shape # (batch_size, seq_len, d_model)
x = self.trend(input).transpose(1, 2) # (batch_size, trend_poly, out_feat)
trend_vals = torch.matmul(x.transpose(1, 2), self.poly_space.to(x.device))
trend_vals = trend_vals.transpose(1, 2) # (batch_size, seq_len, out_feat)

# __init__: 
trend_poly = 3
self.trend = nn.Sequential(
    nn.Conv1d(in_channels=in_dim, out_channels=trend_poly, kernel_size=3, padding=1),
    act,
    Transpose(shape=(1, 2)),
    nn.Conv1d(in_feat, out_feat, 3, stride=1, padding=1)
)
lin_space = torch.arange(1, out_dim + 1, 1) / (out_dim + 1) # out_dim = seq_len = time series length
self.poly_space = torch.stack([lin_space ** float(p + 1) for p in range(trend_poly)], dim=0) # trend_poly, out_dim
```

Seasonality: $S_{i,t}=\sum_{k=1}^{K}A_{i,t}^{\kappa_{i,t}^{(k)}}\left[\cos(2\pi f_{\kappa_{i,t}^{(k)}}\tau c+\Phi_{i,t}^{\kappa_{i,t}^{(k)}})+\cos(2\pi\bar{f}_{\kappa_{i,t}^{(k)}}\tau c+\bar{\Phi}_{i,t}^{\kappa_{i,t}^{(k)}})\right],$  
- Amplitude $A_{i,t}^{(k)}=\left|\mathcal{F}(w_{seas}^{i,t})_{k}\right|$
- Phase $\Phi_{i,t}^{(k)}=\phi\left(\mathcal{F}(w_{seas}^{i,t})_{k}\right)$
- $\mathcal{F}$ is the discrete Fourier transform
- $\kappa_{i,t}^{(1)},\cdots,\kappa_{i,t}^{(K)}=\arg\text{TopK}\\k\in\{1,\cdots,\lfloor\tau/2\rfloor+1\}$ é€‰æ‹© top K çš„å¹…å€¼å’Œç›¸ä½ï¼ŒK is a hyperparameter
- $f_{k}$ represents the Fourier frequency of the corresponding index k, $\bar{f}_{k}$ ä¸º $f_{k}$ çš„å…±è½­
- $\tau c=\tau \cdot\frac{[0,1,2,\dots,\tau-2,\tau-1]^{T}}{\tau}=[0,1,2,\dots,\tau-2,\tau-1]^{T}$

FourierLayer:
- Input: x $w_{seas}^{i,t}$ 
- Output:  x_time $S_{i,t}$ 
  - `x_freq, x_freq.conj()` æ˜¯$\mathcal{F}(w_{seas}^{i,t})_{k}$ å’Œå…¶å…±è½­ï¼Œé€šè¿‡abs å’Œ angle å¾—åˆ°å¹…å€¼å’Œç›¸ä½
  - `f, -f` is $f_{k}$ and $\bar{f}_{k}$

```python
###### FourierLayer ######
from einops import rearrange, reduce, repeat

# forward:
b, t, d = x.shape
x_freq = torch.fft.rfft(x, dim=1)  # (b, t, d) -> (b, t//2+1, d)

if t % 2 == 0:
    x_freq = x_freq[:, self.low_freq:-1]
    f = torch.fft.rfftfreq(t)[self.low_freq:-1]
else:
    x_freq = x_freq[:, self.low_freq:]
    f = torch.fft.rfftfreq(t)[self.low_freq:]
# print(x_freq.shape) # (b, t//2 - sel.low_freq, d)
# print(f.shape) # (t//2 - sel.low_freq)
x_freq, index_tuple = self.topk_freq(x_freq) # (b, top_k, d)
f = repeat(f, 'f -> b f d', b=x_freq.size(0), d=x_freq.size(2)).to(x_freq.device) # (b, t//2 - sel.low_freq, d)
f = rearrange(f[index_tuple], 'b f d -> b f () d').to(x_freq.device) # (b, top_k, 1, d)
x_freq = torch.cat([x_freq, x_freq.conj()], dim=1)
f = torch.cat([f, -f], dim=1)
t = rearrange(torch.arange(t, dtype=torch.float),
              't -> () () t ()').to(x_freq.device)
amp = rearrange(x_freq.abs(), 'b f d -> b f () d')
phase = rearrange(x_freq.angle(), 'b f d -> b f () d')
x_time = amp * torch.cos(2 * math.pi * f * t + phase)
return reduce(x_time, 'b f t d -> b t d', 'sum')

# __init__ and function:
self.d_model = d_model
self.factor = factor
self.low_freq = low_freq

def topk_freq(self, x_freq):
  length = x_freq.shape[1]
  top_k = int(self.factor * math.log(length))
  # print(top_k)
  values, indices = torch.topk(x_freq.abs(), top_k, dim=1, largest=True, sorted=True) # (b, top_k, d)
  # print(values.shape, indices.shape); print(values); print(indices)
  mesh_a, mesh_b = torch.meshgrid(torch.arange(x_freq.size(0)), torch.arange(x_freq.size(2)), indexing='ij') # (b, d)
  index_tuple = (mesh_a.unsqueeze(1), indices, mesh_b.unsqueeze(1)) # (b, 1, d) (b, top_k, d) (b, 1, d)
  x_freq = x_freq[index_tuple] # (b, top_k, d) ğŸ¤”é«˜çº§ç´¢å¼•æ–¹æ³•(å…ƒç»„)
  return x_freq, index_tuple
```

Error: R is the output of the last decoder block, which can be regarded as the sum of residual
periodicity and other noise. ä»£ç ä¸­çš„Rä¸ºæœ€åä¸€ä¸ªdecoder blockè¾“å‡ºå‡å»å…¶å¹³å‡å€¼ï¼Œå¹¶å°†å¹³å‡å€¼åŠ åˆ°è¶‹åŠ¿é¡¹ä¸­ï¼Œè®©å‘¨æœŸé¡¹ä¸åŒ…å«ä»»ä½•çš„yè½´æ–¹å‘ä¿¡æ¯

æ—¶é—´åºåˆ—æ•°æ®è¢«è¡¨ç¤ºä¸º $\hat{x}_0(x_t,t,\theta)=V_{tr}^t+\sum_{i=1}^DS_{i,t}+R$ï¼Œç„¶åé€šè¿‡DDPMæ¥ç›´æ¥é¢„æµ‹åŸå§‹æ ·æœ¬ï¼Œåå‘ç”Ÿæˆè¿‡ç¨‹è¢«è¡¨ç¤ºä¸ºï¼š$x_{t-1}=\frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}\hat{x}_0(x_t,t,\theta)+\frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}x_t+\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\beta_tz_t,$ 
- $z_t\sim\mathcal{N}(0,\mathbf{I}), \alpha_t=1-\beta_t\text{ and }\bar{\alpha}_t=\prod_{s=1}^t\alpha_s$

æŸå¤±å‡½æ•°ï¼š
æ—¶åŸŸ+FFTé¢‘åŸŸç›‘ç£ï¼š$\mathcal{L}_\theta=\mathbb{E}_{t,x_0}\left[w_t\left[\lambda_1\|x_0-\hat{x}_0(x_t,t,\theta)\|^2+\lambda_2\|\mathcal{F}\mathcal{FT}(x_0)-\mathcal{FFT}(\hat{x}_0(x_t,t,\theta))\|^2\right]\right]$
- $\mathcal{L}_{simple}=\mathbb{E}_{t,x_{0}}\left[w_{t}\|x_{0}-\hat{x}_{0}(x_{t},t,\theta)\|^{2}\right],\quad w_{t}=\frac{\lambda\alpha_{t}(1-\bar{\alpha}_{t})}{\beta_{t}^{2}}$
  - å…¶ä¸­æƒé‡è¢«è®¾ç½®ä¸ºå½“åœ¨ small t æ—¶æƒé‡å˜å°ï¼Œè®©ç½‘ç»œé›†ä¸­åœ¨æ›´å¤§çš„ diffusion step t(å™ªå£°è¾ƒå¤šçš„æ—¶å€™)
  - ç”± $x_t=\sqrt{\bar{\alpha}_t}x_0+\sqrt{1-\bar{\alpha}_t}\epsilon.$ï¼Œéšç€tçš„å¢å¤§ï¼Œ$\alpha_{t}$ åœ¨é€æ¸å˜å°

ä¸Šè¿°è¿‡ç¨‹ä¸ºæ— æ¡ä»¶ time series generationï¼Œæœ¬æ–‡è¿˜æè¿°äº†conditional extensions of Diffusion-TSï¼Œå³the modeled $x_{0}$ ä»¥ targets y ä¸ºæ¡ä»¶ã€‚

![image.png|666](https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240923180228.png)
![image.png|666](https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240920223417.png)
![image.png|666](https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240921202408.png)


```bash
# ç¯å¢ƒé…ç½®
conda create -n Diffusion-TS
conda activate Diffusion-TS

pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118
pip install -r requirements.txt
```

```bash
# train with stocks dataset with gpu 0
python main.py --name stocks_exp1 --config_file ./Config/stocks.yaml --gpu 0 --train
```

# GANs

## [RGANs](https://arxiv.org/pdf/1706.02633v2) Mostâ­2017

> [ratschlab/RGAN: Recurrent (conditional) generative adversarial networks for generating real-valued time series data.](https://github.com/ratschlab/RGAN) code

![image.png|666](https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240920224613.png)



## [SigCGANs](https://arxiv.org/pdf/2006.05421v2)

> [SigCGANs/Conditional-Sig-Wasserstein-GANs](https://github.com/SigCGANs/Conditional-Sig-Wasserstein-GANs) code


## [TimeGAN](https://papers.nips.cc/paper/2019/file/c9efe5f26cd17ba6216bbe2a7d26d490-Paper.pdf)

![image.png|666](https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240923145250.png)

# VAE

## [TimeVAE](https://arxiv.org/pdf/2111.08095v3)

> [abudesai/timeVAE: TimeVAE implementation in keras/tensorflow](https://github.com/abudesai/timeVAE)
> [abudesai/syntheticdatagen: synthetic data generation of time-series data](https://github.com/abudesai/syntheticdatagen)


![image.png|666](https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240920224735.png)

![image.png|666](https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240920224814.png)
