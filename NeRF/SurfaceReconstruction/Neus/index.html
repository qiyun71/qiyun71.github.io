<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/blog.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/blog.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/yqq/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":true},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Title NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction     Author Peng Wang    Lingjie Liu    Yuan Liu    Christian Theobalt    Taku Komura    Wenping Wang">
<meta property="og:type" content="article">
<meta property="og:title" content="Neus">
<meta property="og:url" content="http://example.com/NeRF/SurfaceReconstruction/Neus/index.html">
<meta property="og:site_name" content="YunQi">
<meta property="og:description" content="Title NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction     Author Peng Wang    Lingjie Liu    Yuan Liu    Christian Theobalt    Taku Komura    Wenping Wang">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/20230629135016.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yq010105/Blog_images/main/Pasted%20image%2020230531185214.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/20230703144039.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yq010105/Blog_images/main/Pasted%20image%2020230606154119.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yq010105/Blog_images/main/Pasted%20image%2020230601130943.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yq010105/Blog_images/main/Pasted%20image%2020230601131053.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yq010105/Blog_images/main/Pasted%20image%2020230602165940.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yq010105/Blog_images/main/Pasted%20image%2020230601211543.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yq010105/Blog_images/main/Pasted%20image%2020230601211823.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yq010105/Blog_images/main/Pasted%20image%2020230601211901.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/Pasted%20image%2020230601211955.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/20230630141311.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/00300000_0_38.gif">
<meta property="og:image" content="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/00300000_1_2.gif">
<meta property="og:image" content="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/001.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/002.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/Pasted%20image%2020230531192515.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/Pasted%20image%2020230531191938.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/Pasted%20image%2020230531192204.png">
<meta property="article:published_time" content="2023-06-14T14:14:49.000Z">
<meta property="article:modified_time" content="2023-11-13T05:03:48.880Z">
<meta property="article:author" content="Qi Yun">
<meta property="article:tag" content="SurfaceReconstruction">
<meta property="article:tag" content="Neus">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/20230629135016.png">

<link rel="canonical" href="http://example.com/NeRF/SurfaceReconstruction/Neus/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Neus | YunQi</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">YunQi</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Note</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/NeRF/SurfaceReconstruction/Neus/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpeg">
      <meta itemprop="name" content="Qi Yun">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YunQi">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Neus
        </h1>

        <div class="post-meta">
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-06-14 22:14:49" itemprop="dateCreated datePublished" datetime="2023-06-14T22:14:49+08:00">2023-06-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-11-13 13:03:48" itemprop="dateModified" datetime="2023-11-13T13:03:48+08:00">2023-11-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NeRF-SurfaceReconstruction/" itemprop="url" rel="index"><span itemprop="name">NeRF/SurfaceReconstruction</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>4.7k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>17 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <div class="table-container">
<table>
<thead>
<tr>
<th>Title</th>
<th>NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction</th>
</tr>
</thead>
<tbody>
<tr>
<td>Author</td>
<td><a target="_blank" rel="noopener" href="https://totoro97.github.io/about.html">Peng Wang</a>    <a target="_blank" rel="noopener" href="https://lingjie0206.github.io/">Lingjie Liu</a>    <a target="_blank" rel="noopener" href="https://liuyuan-pal.github.io/">Yuan Liu</a>    <a target="_blank" rel="noopener" href="http://people.mpi-inf.mpg.de/~theobalt/">Christian Theobalt</a>    <a target="_blank" rel="noopener" href="https://www.cs.hku.hk/index.php/people/academic-staff/taku">Taku Komura</a>    <a target="_blank" rel="noopener" href="https://www.cs.hku.hk/people/academic-staff/wenping">Wenping Wang</a></td>
</tr>
<tr>
<td>Conf/Jour</td>
<td>NeurIPS 2021 (Spotlight)</td>
</tr>
<tr>
<td>Year</td>
<td>2021</td>
</tr>
<tr>
<td>Project</td>
<td><a target="_blank" rel="noopener" href="https://lingjie0206.github.io/papers/NeuS/">NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction (lingjie0206.github.io)</a></td>
</tr>
<tr>
<td>Paper</td>
<td><a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=4718711588576575489&amp;noteId=1791151226962648064">NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction (readpaper.com)</a></td>
</tr>
</tbody>
</table>
</div>
<p>实现了三维重建：从多视角图片中重建出了 mesh 模型</p>
<span id="more"></span>
<p><a target="_blank" rel="noopener" href="https://github.com/Totoro97/NeuS">Code: Totoro97/NeuS: Code release for NeuS (github.com)</a><br><a target="_blank" rel="noopener" href="https://lingjie0206.github.io/papers/NeuS/">Project Page</a></p>
<p>Neus 的总目标是实现从 2D 图像输入中以高保真度重建对象和场景。<br>现有的神经表面重建方法，如 DVR[Niemeyer 等人，2020]和 IDR[Yariv 等人，2020]，需要前景掩码作为监督，很容易陷入局部最小值，因此在对具有严重自遮挡或薄结构的对象进行重建时面临困难。<br>最近的新视角合成神经方法，如 NeRF[Mildenhall 等人，2020]及其变体，使用体积渲染来产生具有优化鲁棒性的神经场景表示，即使对于非常复杂的对象也是如此。<strong>然而，从这种学习的隐式表示中提取高质量的表面是困难的，因为在表示中没有足够的表面约束。</strong><br>在 NeuS 中，我们提出将表面表示为有符号距离函数（SDF）的零水平集，并开发了一种新的体积渲染方法来训练神经 SDF 表示。我们观察到，传统的体积渲染方法会导致固有的几何误差（即偏差）对于表面重建，因此提出了一个新的公式，它在一阶近似中没有偏差，从而即使在没有掩码监督的情况下也能实现更准确的表面重建。<br>在 DTU 数据集和 BlendedMVS 数据集上的实验证明，NeuS 在高质量表面重建方面优于现有技术，尤其是对于具有复杂结构和自遮挡的对象和场景。</p>
<h1 id="优点-amp-不足之处"><a href="#优点-amp-不足之处" class="headerlink" title="优点&amp;不足之处"></a>优点&amp;不足之处</h1><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ul>
<li>通过手动在 meshlab 中 clean 稀疏点云 ply 中其他噪音位置的点云，构建了一个精确的 bounds，可以将模型不包括背景且几乎没有噪声的生成出来</li>
<li>通过构建 SDF 场，其零水平集相比 NeRF 的密度场水平集(Threshold = 25)，生成的 mesh 更加精细，或者说更加平滑<ul>
<li>对图片中深度突然变化的部分，sdf 也可以很好的重建出来</li>
</ul>
</li>
</ul>
<h2 id="不足"><a href="#不足" class="headerlink" title="不足"></a>不足</h2><ul>
<li>对于无纹理物体(例如反光和阴影区域)的重建效果并不理想</li>
<li>需要手动在 meshlab 中 clean 稀疏点云 ply 中其他噪音位置的点云，这也是本文所说不需 mask 监督的方法</li>
<li>(in paper:)一个有趣的未来研究方向是根据不同的局部几何特征，对不同空间位置具有不同方差的概率以及场景表示的优化进行建模</li>
</ul>
<p><a href="#Neus与NeRF对比">Neus 与 NeRF 对比</a></p>
<h1 id="引言-相关工作"><a href="#引言-相关工作" class="headerlink" title="引言+相关工作"></a>引言+相关工作</h1><h2 id="SDF-简单理解"><a href="#SDF-简单理解" class="headerlink" title="SDF 简单理解"></a>SDF 简单理解</h2><p>SDF：输入一个空间中的点，输出为该点到某个表面（可以是曲面）最近的距离，符号在表面外部为正，内部为负。<br>给定一个物体的平面，我们定义 SDF 为空间某点到该平面距离为 0 的位置的点的集合（也就是物体表面的点）。如果空间中某点在物体表面之外，那么 SDF&gt;0；反之如果空间中某点在物体表面之内，那么 SDF&lt;0。这样子就可以找到物体表面在三维空间中的位置，自然而然的生成三维表面。</p>
<p><img src="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/20230629135016.png" alt="image.png"></p>
<ol>
<li>mesh 是一种由图表示的数据结构，基于顶点、边、面共同组成的多面体。它可以十分灵活的表示复杂物体的表面，在计算机图形学中有着广泛的应用。从 nerf 输出的物理意义就可以想到，density 可以用来表示空间中沿光线照射方向的密度，<strong>那么我们可以通过基于密度的阈值来控制得到的 mesh</strong>。这种方法的好处是，训练好一个 nerf 的模型就可以得到一个 mesh 了。但是这种方式也有很大的缺点：一是训练结果会有很多噪音而且生成的 mesh 会有很多的空洞，二是很难控制一个合理的阈值。</li>
<li>这里我们可以考虑使用有向距离场（Signed distance function 简称 SDF）来取代 nerf 建模。使用 SDF 的一大好处是，SDF 函数本身在空间是连续的，这样子就不需要考虑离散化的问题。我们之后使用 Marching cubes 方法来生成 mesh。</li>
<li>NeRF 生成一个带有密度和颜色信息的模型，通过使用 SDF 来代替密度，在密度大的地方表示为物体的表面，就可以生成一个 mesh 模型。</li>
</ol>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/553474332">旷视 3d CV master 系列训练营二： 基于 NeRF 和 SDF 的三维重建与实践 - 知乎 (zhihu.com)</a></p>
</blockquote>
<h2 id="相较于以往的工作："><a href="#相较于以往的工作：" class="headerlink" title="相较于以往的工作："></a>相较于以往的工作：</h2><p><img src="https://raw.githubusercontent.com/yq010105/Blog_images/main/Pasted%20image%2020230531185214.png" alt="Pasted image 20230531185214.png"></p>
<p>IDR 无法应对图片中深度突然变化的部分，这是因为它对每条光线只进行一次表面碰撞（上图（a）上），于是梯度也到此为止，这对于反向传播来说过于局部了，于是困于局部最小值，如下图 IDR 无法处理好突然加深的坑。</p>
<p>NeRF 的体积渲染方法提出沿着每条光线进行多次采样（上图（a）下）然后进行 α 合并，可以应对突然的深度变化但 NeRF 是专注于生成新视点图像而不是表面重建所以有明显噪声。</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/496752239">NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction - 知乎 (zhihu.com)</a></p>
</blockquote>
<p>新的体积渲染方案：Neus，使用 SDF 进行表面表示，并使用一种新的体积渲染方案来学习神经 SDF 表示。</p>
<h2 id="本文方法"><a href="#本文方法" class="headerlink" title="本文方法"></a>本文方法</h2><p>本文集中在通过经典的绘制技术从 2D 图像中学习编码 3D 空间中的几何和外观的隐式神经表示，限制在此范围内，相关工作可以大致分为基于表面渲染的方法和基于体积渲染的方法</p>
<ul>
<li>基于表面渲染：假设光线的颜色仅依赖于光线与场景几何的交点的颜色，这使得梯度仅反向传播到交点附近的局部区域，很难重建具有严重自遮挡和突然深度变化的复杂物体，因此需要物体 mask 来进行监督</li>
<li>基于体积渲染：eg_NeRF，通过沿每条射线的采样点的 α-合成颜色来渲染图像。正如在介绍中所解释的，它可以处理突然的深度变化并合成高质量的图像。提取学习到的隐式场的高保真表面是困难的，因为基于密度的场景表示对其等值集缺乏足够的约束。<br>相比之下，我们的方法结合了基于表面渲染和基于体积渲染的方法的优点，通过将场景空间约束为带符号距离函数 SDF，但使用体积渲染来训练具有鲁棒性的 representation。</li>
<li>同时 UNISURF 也通过体积渲染学习隐式曲面。在优化过程中，通过缩小体积渲染的样本区域来提高重建质量。<br><strong>UNISURF 用占用值来表示表面，而我们的方法用 SDF 来表示场景</strong>，(因此可以自然地提取表面作为场景的零水平集，产生比 UNISURF 更好的重建精度。)</li>
</ul>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><div class="note info">
            <p>构建了一个无偏，且 collusion-aware 的权重函数 w(t) = T(t)ρ(t) </p>
          </div>
<p>给定一组三维物体的 pose 图像，目标是重建该物体的表面，该表面由神经隐式 SDF 的零水平集表示。<br>为了学习神经网络的权重，开发了一种<strong>新的体积渲染方法</strong>来渲染隐式 SDF 的图像，并最小化渲染图像与输入图像之间的差异。确保了 Neus 在重建复杂结构物体时的鲁棒性优化。</p>
<h2 id="渲染步骤"><a href="#渲染步骤" class="headerlink" title="渲染步骤"></a>渲染步骤</h2><h3 id="场景表示"><a href="#场景表示" class="headerlink" title="场景表示"></a>场景表示</h3><p>被重构物体的场景表示为两个函数：</p>
<ul>
<li>f：将空间点的空间坐标映射为该点到物体的符号距离</li>
<li>c：编码与点 x 和观察方向 v 相关联的颜色<br>这两个函数都被 MLP 编码，物体的表面有 SDF 的零水平集表示 $\mathcal{S}=\left\{\mathbf{x}\in\mathbb{R}^3|f(\mathbf{x})=0\right\}.$</li>
</ul>
<p>定义概率密度函数 $\phi_s(x) =\frac{se^{-sx}}{(1+e^{-sx})^{2}}$</p>
<p>其为 sigmoid 函数的导数 $\Phi_s(x)=(1+e^{-sx})^{-1},\text{i.e.,}\phi_s(x)=\Phi_s’(x)$</p>
<h3 id="Neus-与-NeRF-对比"><a href="#Neus-与-NeRF-对比" class="headerlink" title="Neus 与 NeRF 对比"></a>Neus 与 NeRF 对比</h3><p>相同点：</p>
<ul>
<li>使用 NeRF 提出的频率编码方式进行位置编码</li>
<li>使用了从像素坐标到世界坐标系转换的方式来生成光线(o,d)</li>
</ul>
<p>不同点之一——使用了不同的相机坐标变换：</p>
<p><img src="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/20230703144039.png" alt="image.png"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Method</th>
<th>Pixel to Camera coordinate</th>
</tr>
</thead>
<tbody>
<tr>
<td>NeRF</td>
<td>$\vec d = \begin{pmatrix} \frac{i-\frac{W}{2}}{f} \\ -\frac{j-\frac{H}{2}}{f} \\ -1 \\ \end{pmatrix}$ , $intrinsics = K = \begin{bmatrix} f &amp; 0 &amp; \frac{W}{2}  \\ 0 &amp; f &amp; \frac{H}{2}  \\ 0 &amp; 0 &amp; 1 \\ \end{bmatrix}$</td>
</tr>
<tr>
<td>Neus</td>
<td>$\vec d = intrinsics^{-1} \times  pixel = \begin{bmatrix} \frac{1}{f} &amp; 0 &amp; -\frac{W}{2 \cdot f}  \\ 0 &amp; \frac{1}{f} &amp; -\frac{H}{2 \cdot f} \\ 0 &amp; 0 &amp; 1 \\ \end{bmatrix} \begin{pmatrix} i \\ j \\ 1 \\ \end{pmatrix} = \begin{pmatrix} \frac{i-\frac{W}{2}}{f} \\ \frac{j-\frac{H}{2}}{f} \\ 1 \\ \end{pmatrix}$</td>
</tr>
</tbody>
</table>
</div>
<p>不同点：</p>
<p>体渲染、采样方式、训练出来的网络模型以及 near、far 计算方式</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Project</th>
<th>Neus</th>
<th>NeRF</th>
</tr>
</thead>
<tbody>
<tr>
<td>渲染函数</td>
<td>$C(\mathbf{o},\mathbf{v})=\int_{0}^{+\infty}w(t)c(\mathbf{p}(t),\mathbf{v})\mathrm{d}t$</td>
<td>$\mathrm{C}(r)=\int_{\mathrm{t}_{\mathrm{n}}}^{\mathrm{t}_{\mathrm{f}}} \mathrm{T}(\mathrm{t}) \sigma(\mathrm{r}(\mathrm{t})) \mathrm{c}(\mathrm{r}(\mathrm{t}), \mathrm{d}) \mathrm{dt}$</td>
</tr>
<tr>
<td>权重</td>
<td>$w(t)=T(t)\rho(t),\text{where}T(t)=\exp\left(-\int_0^t\rho(u)\mathrm{d}u\right)$ <strong>无偏、且遮挡</strong></td>
<td>$w(t)=T(t)\sigma(t) , \text { where } \mathrm{T}(\mathrm{t})=\exp \left(-\int_{\mathrm{t}_{\mathrm{n}}}^{\mathrm{t}} \sigma(\mathrm{r}(\mathrm{s})) \mathrm{ds}\right)$ <strong>遮挡但有偏</strong></td>
</tr>
<tr>
<td>不透明度密度函数</td>
<td>$\rho(t)=\max\left(\frac{-\frac{\mathrm{d}\Phi_s}{\mathrm{d}t}(f(\mathbf{p}(t)))}{\Phi_s(f(\mathbf{p}(t)))},0\right)$</td>
<td>$\sigma(t) = \sigma_{i}=raw2alpha(raw[…,3] + noise, dists)$</td>
</tr>
<tr>
<td>离散化</td>
<td>$\hat{C}=\sum_{i=1}^n T_i\alpha_i c_i$ $T_i=\prod_{j=1}^{i-1}(1-\alpha_j)$ $\alpha_i=\max\left(\frac{\Phi_s(f(\mathbf{p}(t_i))))-\Phi_s(f(\mathbf{p}(t_{i+1})))}{\Phi_s(f(\mathbf{p}(t_i)))},0\right)$</td>
<td>$\hat{C}(\mathbf{r})=\sum_{i=1}^{N} T_{i}\alpha_{i}\mathbf{c}_{i}$ $\hat{C}(\mathbf{r})=\sum_{i=1}^{N} T_{i}\left(1-\exp \left(-\sigma_{i} \delta_{i}\right)\right) \mathbf{c}_{i}$ $T_{i}=\exp \left(-\sum_{j=1}^{i-1} \sigma_{j} \delta_{j}\right)$</td>
</tr>
<tr>
<td>精采样</td>
<td>使用 sdf_network 得到的 sdf 求出 cos，并得到估计的 sdf，求出$\alpha$和 weight，用权重逆变换采样</td>
<td>经过 MLP 得到$\sigma$，求出$\alpha$和 weight，用权重逆变换采样</td>
</tr>
<tr>
<td>网络模型</td>
<td>隐式 SDF 场</td>
<td>隐式密度点云场</td>
</tr>
<tr>
<td>near_far</td>
<td>根据光线的原点和方向向量计算</td>
<td>不同的数据集有不同的计算方式</td>
</tr>
</tbody>
</table>
</div>
<p>权重函数，Neus(右)，NeRF(左)<br><img src="https://raw.githubusercontent.com/yq010105/Blog_images/main/Pasted%20image%2020230606154119.png" alt="Pasted image 20230606154119.png"></p>
<h2 id="训练损失函数"><a href="#训练损失函数" class="headerlink" title="训练损失函数"></a>训练损失函数</h2><p>loss 函数：</p>
<script type="math/tex; mode=display">\mathcal L=\mathcal L_{color}+\lambda\mathcal L_{reg}+\beta\mathcal L_{mask}.</script><p>颜色损失：$\mathcal{L}_{color}=\frac{1}{m}\sum_k\mathcal{R}(\hat{C}_k,C_k).$<br>Eikonal term,类似<a target="_blank" rel="noopener" href="https://lioryariv.github.io/idr/">IDR</a>:$\mathcal{L}_{r e g}=\frac{1}{n m}\sum_{k,i}(|\nabla f(\hat{\mathbf{p}}_{k,i})|_{2}-1)^{2}.$<br><a target="_blank" rel="noopener" href="https://github.com/amosgropp/IGR">IGR</a>：$\mathcal{L}_{mask}=\mathrm{BCE}(M_k,\hat{O}_k)$</p>
<ul>
<li>沿着相机 ray 的权重之和：$\hat{O}_k=\sum_{i=1}^n T_{k,i}\alpha_{k,i}$</li>
<li>是否使用 mask 监督: (BCE 是二值交叉熵损失)：$M_{k} ∈ {0, 1}$</li>
</ul>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><h2 id="Dataset：DTU-amp-BlendedMVS"><a href="#Dataset：DTU-amp-BlendedMVS" class="headerlink" title="Dataset：DTU&amp;BlendedMVS"></a>Dataset：DTU&amp;BlendedMVS</h2><p>DTU: 15 个场景、1600 × 1200 像素<br>BlendedMVS：7 个场景、768 × 576 像素</p>
<h2 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a>Baseline</h2><p>表面重建方法：</p>
<ul>
<li>IDR：高质量表面重建，但需要前景 mask 监督</li>
<li>DVR，没有比较<br>体积渲染方法：</li>
<li>NeRF：我们使用 25 的 threshold 从学习的密度场中提取网格（在补充材料中验证了为什么用 25 做阈值）<br>广泛使用的经典 MVS 方法：（MVS：Multi-View Stereo Reconstruction 多视点立体重建）</li>
<li>colmap：从 colmap 的输出点云中，使用 Screened Poisson Surface Reconstruction 重建 mesh</li>
</ul>
<p>UNISURF：将表面渲染与以占用场做场景表示的体积渲染统一起来</p>
<h2 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h2><p>设感兴趣的物体在单位球体内，每批采样 512 条光线，单个 RTX2080Ti：14h（with mask），16h（without mask）<br>对于 w/o mask ，使用 NeRF++对背景进行建模，网络架构和初始化方案与 IDR 相似</p>
<h2 id="环境配置："><a href="#环境配置：" class="headerlink" title="环境配置："></a>环境配置：</h2><p>autodl 镜像：<br>Miniconda  conda3<br>Python  3.8(ubuntu20.04)<br>Cuda  11.8<br><code>conda create -n neus python=3.8</code><br><code>pip install -r requirements.txt</code><br><code>pip --default-timeout=1000 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html</code></p>
<h2 id="命令行运行程序："><a href="#命令行运行程序：" class="headerlink" title="命令行运行程序："></a>命令行运行程序：</h2><p><code>python exp_runner.py --mode train --conf ./confs/wmask.conf --case &lt;case_name&gt;</code> # 带 mask 监督<br><code>python exp_runner.py --mode train --conf ./confs/womask.conf --case &lt;case_name&gt;</code> # 不带 mask 监督<br>case_name 是所选物体数据集文件夹的名称<br>如果训练过程中中断，可以设置<code>--is_continue</code> 来进行加载最后的 ckpt 继续训练：<br><code>python exp_runner.py --mode train --conf ./confs/wmask.conf --case &lt;case_name&gt; --is_continue</code></p>
<p>训练生成的结果会保存在根目录下 exp 文件夹下，可以看到 meshes 文件夹中保存了训练过程中的 mesh 模型，但面片较少。需要比较精细的 mesh 模型需要运行<br><code>python exp_runner.py --mode validate_mesh --conf &lt;config_file&gt; --case &lt;case_name&gt; --is_continue # use latest checkpoint</code><br>多视角渲染<br><code>python exp_runner.py --mode interpolate_&lt;img_idx_0&gt;_&lt;img_idx_1&gt; --conf &lt;config_file&gt; --case &lt;case_name&gt; --is_continue # use latest checkpoint</code></p>
<h3 id="eg1-clock-wmask"><a href="#eg1-clock-wmask" class="headerlink" title="eg1: clock_wmask"></a>eg1: clock_wmask</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">python exp_runner.py --mode train --conf ./confs/wmask.conf --case bmvs_clock #带mask</span><br><span class="line">中断后继续训练</span><br><span class="line">python exp_runner.py --mode train --conf ./confs/wmask.conf --case bmvs_clock --is_continue</span><br><span class="line">将mesh模型精细化</span><br><span class="line">python exp_runner.py --mode validate_mesh --conf ./confs/wmask.conf --case bmvs_clock --is_continue</span><br><span class="line">插值多视角渲染成mp4(0~1之间新视角生成)</span><br><span class="line">python exp_runner.py --mode interpolate_000_001 --conf ./confs/wmask.conf --case bmvs_clock --is_continue</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/yq010105/Blog_images/main/Pasted%20image%2020230601130943.png" alt="Pasted image 20230601130943.png"></p>
<p>除了主体模型外还有一些噪音<br><img src="https://raw.githubusercontent.com/yq010105/Blog_images/main/Pasted%20image%2020230601131053.png" alt="Pasted image 20230601131053.png"></p>
<p>Neus： (结果与 resolution 无关)</p>
<ul>
<li>使用 Neus 时，精细化模型参数设置为 <code>resolution=512</code> 可能与此有关</li>
<li>改为<code>resolution=1024</code> 运行一下 validate_mesh<br><img src="https://raw.githubusercontent.com/yq010105/Blog_images/main/Pasted%20image%2020230602165940.png" alt="Pasted image 20230602165940.png"></li>
</ul>
<p>虽然运行后，面数更多了，但是细节处依然不清楚，可能需要继续增加训练的步数</p>
<ul>
<li>看代码后：resolution 可以增加 object 的分辨率，再缩放到物体实际大小<ul>
<li>可以看到 vertices 和 faces 都增加了，但由于 sdf 生成的相同，因此表面变得更精细，但细节处不清楚的地方依然不清楚</li>
</ul>
</li>
</ul>
<h3 id="eg2-bear-womask"><a href="#eg2-bear-womask" class="headerlink" title="eg2: bear_womask"></a>eg2: bear_womask</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python exp_runner.py --mode train --conf ./confs/womask.conf --case bmvs_bear  #没有mask</span><br><span class="line">python exp_runner.py --mode train --conf ./confs/womask.conf --case bmvs_bear  --is_continue</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/yq010105/Blog_images/main/Pasted%20image%2020230601211543.png" alt="Pasted image 20230601211543.png"></p>
<p><img src="https://raw.githubusercontent.com/yq010105/Blog_images/main/Pasted%20image%2020230601211823.png" alt="Pasted image 20230601211823.png"></p>
<p>运行后，mesh 模型的面很少</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">将mesh模型精细化</span><br><span class="line">python exp_runner.py --mode validate_mesh --conf ./confs/womask.conf --case bmvs_bear --is_continue</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/yq010105/Blog_images/main/Pasted%20image%2020230601211901.png" alt="Pasted image 20230601211901.png"></p>
<p><img src="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/Pasted%20image%2020230601211955.png" alt="Pasted image 20230601211955.png"></p>
<h3 id="eg3-Miku"><a href="#eg3-Miku" class="headerlink" title="eg3: Miku"></a>eg3: Miku</h3><p>模型不够理想</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">python exp_runner.py --mode train --conf ./confs/womask.conf --case Miku</span><br><span class="line">python exp_runner.py --mode validate_mesh --conf ./confs/womask.conf --case Miku --is_continue</span><br><span class="line"></span><br><span class="line">python exp_runner.py --mode interpolate_0_38 --conf ./confs/womask.conf --case Miku --is_continue</span><br></pre></td></tr></table></figure>
<p>效果：</p>
<p><img src="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/20230630141311.png" alt="image.png"></p>
<ul>
<li>底下的圆盘在 sparse_points.ply 中没有剔除干净，所以会出现额外的突出</li>
<li>面部表情、裙子装饰等细小部位不够细致，腿部也不够细致</li>
<li>头发部位 and 鞋子也由于在点云中没有完全去除噪点，因此会有额外的噪声被建模出来</li>
</ul>
<p>0 to 38 render video：</p>
<p><img src="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/00300000_0_38.gif" alt="00300000_0_38.gif"></p>
<h2 id="Neus-如何给模型加纹理："><a href="#Neus-如何给模型加纹理：" class="headerlink" title="Neus 如何给模型加纹理："></a>Neus 如何给模型加纹理：</h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/Totoro97/NeuS/issues/48">How to reconstruct texture after generating mesh ? · Issue #48 · Totoro97/NeuS (github.com)</a></p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"># get texture or say color</span><br><span class="line">def validate_mesh_vertex_color(self, world_space=False, resolution=64, threshold=0.0, name=None):</span><br><span class="line">    print(&#x27;Start exporting textured mesh&#x27;)</span><br><span class="line"></span><br><span class="line">    bound_min = torch.tensor(self.dataset.object_bbox_min, dtype=torch.float32)</span><br><span class="line">    bound_max = torch.tensor(self.dataset.object_bbox_max, dtype=torch.float32)</span><br><span class="line">    vertices, triangles = self.renderer.extract_geometry(bound_min, bound_max, resolution=resolution,</span><br><span class="line">                                                        threshold=threshold)</span><br><span class="line">    print(f&#x27;Vertices count: &#123;vertices.shape[0]&#125;&#x27;)</span><br><span class="line"></span><br><span class="line">    vertices = torch.tensor(vertices, dtype=torch.float32) # n_t x 3</span><br><span class="line">    vertices_batch = vertices.split(self.batch_size) # n_t / batch_size x batch_size x 3</span><br><span class="line">    render_iter = len(vertices_batch) # n_t / batch_size</span><br><span class="line"></span><br><span class="line">    vertex_colors = []</span><br><span class="line">    for iter in tqdm(range(render_iter)):</span><br><span class="line">        feature_vector = self.sdf_network.sdf_hidden_appearance(vertices_batch[iter])[ : ,1:]</span><br><span class="line">        gradients = self.sdf_network.gradient(vertices_batch[iter]).squeeze()</span><br><span class="line">        dirs = -gradients</span><br><span class="line">        vertex_color = self.color_network(vertices_batch[iter], gradients, dirs,</span><br><span class="line">                                            feature_vector).detach().cpu().numpy()[..., ::-1]  # BGR to RGB</span><br><span class="line">        # .detach() ：将变量从网络中隔离开，不参与参数更新</span><br><span class="line">        vertex_colors.append(vertex_color)</span><br><span class="line">    vertex_colors = np.concatenate(vertex_colors)</span><br><span class="line">    print(f&#x27;validate point count: &#123;vertex_colors.shape[0]&#125;&#x27;)</span><br><span class="line">    vertices = vertices.detach().cpu().numpy()</span><br><span class="line"></span><br><span class="line">    if world_space:</span><br><span class="line">        vertices = vertices * self.dataset.scale_mats_np[0][0, 0] + self.dataset.scale_mats_np[0][:3, 3][None]</span><br><span class="line"></span><br><span class="line">    os.makedirs(os.path.join(self.base_exp_dir, &#x27;meshes&#x27;), exist_ok=True)</span><br><span class="line">    mesh = trimesh.Trimesh(vertices, triangles, vertex_colors=vertex_colors)</span><br><span class="line">    if name is not None:</span><br><span class="line">        mesh.export(os.path.join(self.base_exp_dir, &#x27;meshes&#x27;, f&#x27;&#123;name&#125;.ply&#x27;))</span><br><span class="line">    else:</span><br><span class="line">        mesh.export(os.path.join(self.base_exp_dir, &#x27;meshes&#x27;, &#x27;&#123;:0&gt;8d&#125;_vertex_color.ply&#x27;.format(self.iter_step)))</span><br><span class="line"></span><br><span class="line">    logging.info(&#x27;End&#x27;)</span><br></pre></td></tr></table></figure>
<ul>
<li>这里采用了<code>dirs = -gradients</code> 来做渲染网络输入的观察方向，渲染网络输出的 color 值不是很准确<ul>
<li>由于 Miku 的表面较为复杂，训练时其表面法向与观察方向并不在一条直线上，因此在推理过程中这样设置的话生成的 color 值不准</li>
</ul>
</li>
</ul>
<h2 id="渲染自定义视角的视频"><a href="#渲染自定义视角的视频" class="headerlink" title="渲染自定义视角的视频"></a>渲染自定义视角的视频</h2><p>根据中间两个 img 进行插值，中间插入生成的新视图图片</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python exp_runner.py --mode interpolate_&lt;img_idx_0&gt;_&lt;img_idx_1&gt; --conf &lt;config_file&gt; --case &lt;case_name&gt; --is_continue # use latest checkpoint</span><br><span class="line"></span><br><span class="line">eg:</span><br><span class="line">python exp_runner.py --mode train --conf ./confs/womask.conf --case bmvs_bear</span><br><span class="line">python exp_runner.py --mode interpolate_1_2 --conf ./confs/womask.conf --case bmvs_bear --is_continue # use latest checkpoint</span><br></pre></td></tr></table></figure>
<p>eg: 1 to 2<br><img src="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/00300000_1_2.gif" alt="00300000_1_2.gif"></p>
<div style="display: flex; justify-content: center;"> <img src="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/001.png" alt="Image 1" style="width: 50%; height: auto; margin: 10px;"> to <img src="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/002.png" alt="Image 2" style="width: 50%; height: auto; margin: 10px;"> </div>

<h1 id="Neus-使用自制数据集"><a href="#Neus-使用自制数据集" class="headerlink" title="Neus 使用自制数据集"></a>Neus 使用自制数据集</h1><h2 id="自定义数据集-colmap-操作"><a href="#自定义数据集-colmap-操作" class="headerlink" title="自定义数据集 colmap 操作"></a>自定义数据集 colmap 操作</h2><p>自己拍一组照片: <strong>手机或者相机 绕 物体拍一周，每张的角度不要超过 30°（保证有 overlap 区域）</strong></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/397760339">colmap 简介及入门级使用 - 知乎 (zhihu.com)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/Pasted%20image%2020230531192515.png" alt="Pasted image 20230531192515.png"></p>
<p>打开 colmap.bat 进入 gui 界面，点击<strong>Reconstruction</strong>，再点击<strong>Automatic reconstruction</strong></p>
<p><strong>workspace folder：选择 workspace 文件夹，注意不支持中文路径</strong><br><strong>Image folder：选择存放多视角图像的数据文件夹，注意不支持中文路径</strong><br><strong>Data type：选择 Individual images</strong><br><strong>Quality：看需要选择，选择 High 重建花费的时间最长，重建的质量不一定最好；</strong></p>
<p>在 COLMAP 中看生成的稀疏点云<br><img src="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/Pasted%20image%2020230531191938.png" alt="Pasted image 20230531191938.png"></p>
<p>在 workspace folder 文件夹-&gt;dense-&gt;0 文件夹下找到 fused.ply 数据，用 meshlab 中打开可以看到稠密的三维重建的结果。<br>在 Meshlab 中查看生成的稠密点云</p>
<p><img src="https://raw.githubusercontent.com/yq010105/Blog_images/main/pictures/Pasted%20image%2020230531192204.png" alt="Pasted image 20230531192204.png"></p>
<h2 id="Neus-命令操作"><a href="#Neus-命令操作" class="headerlink" title="Neus 命令操作"></a>Neus 命令操作</h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/mockbird123/article/details/129934066">(18 条消息) 基于 Nerf 的三维重建算法 Neus 初探_Alpha 狗蛋的博客-CSDN 博客</a></p>
</blockquote>
<p>两个文件夹：image 和 mask，一个文件<br>image 文件夹就是 rgb 图片数据，算法默认支持 png 格式。<br>mask 文件夹包含的是模型的前景图像，前景和后景以黑色和白色区分，如果配置文件选择 withou mask，其实这个文件夹的数据是没有意义的。但必须有文件，且名称、图像像素要和 image 的图像一一对应。<br>最后是 cameras_sphere.npz 文件，它包括了相机的属性和图像的位姿信息等，这个是需要我们自己计算的。官方给出了两种计算方案，第二种是用 colmap 计算 npz 文件。</p>
<h3 id="使用-Colmap-生成-npz-文件"><a href="#使用-Colmap-生成-npz-文件" class="headerlink" title="使用 Colmap 生成 npz 文件"></a>使用 Colmap 生成 npz 文件</h3><p>可以提前通过 colmap 运行得到 sparse/0/中的文件，或者通过 img2poses 中的 run_colmap()生成，然后再得到 sparse_points.ply</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd colmap_preprocess</span><br><span class="line">python imgs2poses.py $&#123;data_dir&#125;</span><br></pre></td></tr></table></figure>
<p>将会生成：<code>$&#123;data_dir&#125;/sparse_points.ply</code>，在 meshlab 中选择多余部分的 Vertices，并删除，然后保存为<code>$&#123;data_dir&#125;/sparse_points_interest.ply</code>.</p>
<p>然后</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python gen_cameras.py $&#123;data_dir&#125;</span><br></pre></td></tr></table></figure>
<p>就会在 ${data_dir}下生成 preprocessed，包括 image、mask 和 cameras_sphere.npz</p>

    </div>

    
    
    
        

  <div class="followme">
    <p>Welcome to my other publishing channels</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="https://t.me/+1ZnNxFWnEbk5YzRl">
            <span class="icon">
              <i class="fab fa-telegram"></i>
            </span>

            <span class="label">Telegram</span>
          </a>
        </div>
    </div>
  </div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/SurfaceReconstruction/" rel="tag"><i class="fa fa-tag"></i> SurfaceReconstruction</a>
              <a href="/tags/Neus/" rel="tag"><i class="fa fa-tag"></i> Neus</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/NeRF/NeRF-Principle/" rel="prev" title="NeRF原理">
      <i class="fa fa-chevron-left"></i> NeRF原理
    </a></div>
      <div class="post-nav-item">
    <a href="/NeRF/SurfaceReconstruction/Neus-Instant-nsr-pl/" rel="next" title="Instant-nsr-pl">
      Instant-nsr-pl <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BC%98%E7%82%B9-amp-%E4%B8%8D%E8%B6%B3%E4%B9%8B%E5%A4%84"><span class="nav-text">优点&amp;不足之处</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BC%98%E7%82%B9"><span class="nav-text">优点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%8D%E8%B6%B3"><span class="nav-text">不足</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%BC%95%E8%A8%80-%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C"><span class="nav-text">引言+相关工作</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#SDF-%E7%AE%80%E5%8D%95%E7%90%86%E8%A7%A3"><span class="nav-text">SDF 简单理解</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9B%B8%E8%BE%83%E4%BA%8E%E4%BB%A5%E5%BE%80%E7%9A%84%E5%B7%A5%E4%BD%9C%EF%BC%9A"><span class="nav-text">相较于以往的工作：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%AC%E6%96%87%E6%96%B9%E6%B3%95"><span class="nav-text">本文方法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%96%B9%E6%B3%95"><span class="nav-text">方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B8%B2%E6%9F%93%E6%AD%A5%E9%AA%A4"><span class="nav-text">渲染步骤</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%BA%E6%99%AF%E8%A1%A8%E7%A4%BA"><span class="nav-text">场景表示</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Neus-%E4%B8%8E-NeRF-%E5%AF%B9%E6%AF%94"><span class="nav-text">Neus 与 NeRF 对比</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-text">训练损失函数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C"><span class="nav-text">实验</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Dataset%EF%BC%9ADTU-amp-BlendedMVS"><span class="nav-text">Dataset：DTU&amp;BlendedMVS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Baseline"><span class="nav-text">Baseline</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82"><span class="nav-text">实现细节</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%EF%BC%9A"><span class="nav-text">环境配置：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%BF%90%E8%A1%8C%E7%A8%8B%E5%BA%8F%EF%BC%9A"><span class="nav-text">命令行运行程序：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#eg1-clock-wmask"><span class="nav-text">eg1: clock_wmask</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#eg2-bear-womask"><span class="nav-text">eg2: bear_womask</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#eg3-Miku"><span class="nav-text">eg3: Miku</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Neus-%E5%A6%82%E4%BD%95%E7%BB%99%E6%A8%A1%E5%9E%8B%E5%8A%A0%E7%BA%B9%E7%90%86%EF%BC%9A"><span class="nav-text">Neus 如何给模型加纹理：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B8%B2%E6%9F%93%E8%87%AA%E5%AE%9A%E4%B9%89%E8%A7%86%E8%A7%92%E7%9A%84%E8%A7%86%E9%A2%91"><span class="nav-text">渲染自定义视角的视频</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Neus-%E4%BD%BF%E7%94%A8%E8%87%AA%E5%88%B6%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-text">Neus 使用自制数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86-colmap-%E6%93%8D%E4%BD%9C"><span class="nav-text">自定义数据集 colmap 操作</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Neus-%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C"><span class="nav-text">Neus 命令操作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8-Colmap-%E7%94%9F%E6%88%90-npz-%E6%96%87%E4%BB%B6"><span class="nav-text">使用 Colmap 生成 npz 文件</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Qi Yun"
      src="/images/avatar.jpeg">
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">116</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">21</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">58</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/qiyun71" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;qiyun71" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://space.bilibili.com/29010355" title="Bilibili → https:&#x2F;&#x2F;space.bilibili.com&#x2F;29010355" rel="noopener" target="_blank"><i class="fa fa-star fa-fw"></i>Bilibili</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2020 – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Qi Yun</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="Symbols count total">432k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">26:12</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/yqq/anime.min.js"></script>
  <script src="/yqq/velocity/velocity.min.js"></script>
  <script src="/yqq/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="//cdn.jsdelivr.net/gh/theme-next/theme-next-three@1/three.min.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
