<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/blog.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/blog.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/yqq/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":true},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Accuracy é‡å»ºçš„æ¨¡å‹ç²¾åº¦ä¸å¥½ï¼Œå½±å“å› ç´ ï¼š æ•°æ®é›†è´¨é‡ï¼šç…§ç‰‡æ‹æ‘„è´¨é‡(è®¾å¤‡)ã€ç›¸æœºä½å§¿ä¼°è®¡ç²¾åº¦(COLMAP) ç…§ç‰‡è´¨é‡é—®é¢˜ï¼šæ··å ã€æ¨¡ç³Šã€æ»šåŠ¨å¿«é—¨ (RS) æ•ˆåº”ã€HDR&#x2F;LDRã€è¿åŠ¨æ¨¡ç³Šã€ä½å…‰ç…§ ç›¸æœºä½å§¿è¯¯å·®ï¼šSFMä½å§¿ä¼°è®¡æ—¶çš„è¯¯å·®   NeuSæ–¹æ³•çš„é—®é¢˜ï¼šä½“æ¸²æŸ“å…¬å¼çš„è¿‡åº¦ç®€åŒ–ã€è¡¨é¢å‡ ä½•ä¸é¢œè‰²çš„åå·®ã€ç¼ºå°‘å‡ ä½•çº¦æŸ(æ·±åº¦oræ³•å‘é‡) ç½‘æ ¼æå–æ–¹æ³•(Marching Cube)ï¼šåˆ†è¾¨ç‡å¤ªä½">
<meta property="og:type" content="article">
<meta property="og:title" content="Multi-view 3D Reconstruction based on SDF and volume rendering">
<meta property="og:url" content="http://example.com/3DReconstruction/NeuS-based%203D%20Reconstruction/index.html">
<meta property="og:site_name" content="QiYun">
<meta property="og:description" content="Accuracy é‡å»ºçš„æ¨¡å‹ç²¾åº¦ä¸å¥½ï¼Œå½±å“å› ç´ ï¼š æ•°æ®é›†è´¨é‡ï¼šç…§ç‰‡æ‹æ‘„è´¨é‡(è®¾å¤‡)ã€ç›¸æœºä½å§¿ä¼°è®¡ç²¾åº¦(COLMAP) ç…§ç‰‡è´¨é‡é—®é¢˜ï¼šæ··å ã€æ¨¡ç³Šã€æ»šåŠ¨å¿«é—¨ (RS) æ•ˆåº”ã€HDR&#x2F;LDRã€è¿åŠ¨æ¨¡ç³Šã€ä½å…‰ç…§ ç›¸æœºä½å§¿è¯¯å·®ï¼šSFMä½å§¿ä¼°è®¡æ—¶çš„è¯¯å·®   NeuSæ–¹æ³•çš„é—®é¢˜ï¼šä½“æ¸²æŸ“å…¬å¼çš„è¿‡åº¦ç®€åŒ–ã€è¡¨é¢å‡ ä½•ä¸é¢œè‰²çš„åå·®ã€ç¼ºå°‘å‡ ä½•çº¦æŸ(æ·±åº¦oræ³•å‘é‡) ç½‘æ ¼æå–æ–¹æ³•(Marching Cube)ï¼šåˆ†è¾¨ç‡å¤ªä½">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20241010195323.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240902141345.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240902132257.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231109094904.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240806202919.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240718142648.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240718142838.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240823163840.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240708102314.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240620160134.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240620170649.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240620151248.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240928172853.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240928172804.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20250313134457.png">
<meta property="article:published_time" content="2024-06-17T09:11:22.000Z">
<meta property="article:modified_time" content="2025-03-19T04:53:13.129Z">
<meta property="article:author" content="Qi Yun">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20241010195323.png">

<link rel="canonical" href="http://example.com/3DReconstruction/NeuS-based%203D%20Reconstruction/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Multi-view 3D Reconstruction based on SDF and volume rendering | QiYun</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">QiYun</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Note</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/3DReconstruction/NeuS-based%203D%20Reconstruction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpeg">
      <meta itemprop="name" content="Qi Yun">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="QiYun">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Multi-view 3D Reconstruction based on SDF and volume rendering
        </h1>

        <div class="post-meta">
          
              <i class="fa fa-thumb-tack" aria-hidden="true"></i> 
              <font color="GREEN">ç½®é¡¶</font>
              <span class="post-meta-divider">|</span>
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-06-17 17:11:22" itemprop="dateCreated datePublished" datetime="2024-06-17T17:11:22+08:00">2024-06-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-03-19 12:53:13" itemprop="dateModified" datetime="2025-03-19T12:53:13+08:00">2025-03-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/3DReconstruction-Multi-view/" itemprop="url" rel="index"><span itemprop="name">3DReconstruction/Multi-view</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>8.6k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>31 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <ul>
<li><strong>Accuracy</strong> é‡å»ºçš„æ¨¡å‹ç²¾åº¦ä¸å¥½ï¼Œå½±å“å› ç´ ï¼š<ul>
<li>æ•°æ®é›†è´¨é‡ï¼šç…§ç‰‡æ‹æ‘„è´¨é‡(è®¾å¤‡)ã€ç›¸æœºä½å§¿ä¼°è®¡ç²¾åº¦(COLMAP)<ul>
<li>ç…§ç‰‡è´¨é‡é—®é¢˜ï¼šæ··å ã€æ¨¡ç³Šã€æ»šåŠ¨å¿«é—¨ (RS) æ•ˆåº”ã€HDR/LDRã€è¿åŠ¨æ¨¡ç³Šã€ä½å…‰ç…§</li>
<li>ç›¸æœºä½å§¿è¯¯å·®ï¼šSFMä½å§¿ä¼°è®¡æ—¶çš„è¯¯å·®</li>
</ul>
</li>
<li>NeuSæ–¹æ³•çš„é—®é¢˜ï¼šä½“æ¸²æŸ“å…¬å¼çš„è¿‡åº¦ç®€åŒ–ã€è¡¨é¢å‡ ä½•ä¸é¢œè‰²çš„åå·®ã€ç¼ºå°‘å‡ ä½•çº¦æŸ(<em>æ·±åº¦oræ³•å‘é‡</em>)</li>
<li>ç½‘æ ¼æå–æ–¹æ³•(Marching Cube)ï¼šåˆ†è¾¨ç‡å¤ªä½</li>
</ul>
</li>
<li><strong>Efficiency</strong> è®­ç»ƒ/æ¸²æŸ“çš„é€Ÿåº¦å¤ªæ…¢ï¼Œå½±å“å› ç´ ï¼š<ul>
<li>MLPè®¡ç®—æ¬¡æ•°å¤š â€”&gt; MIMO MLPã€NGP-RTã€</li>
<li>MLPå±‚æ•°å¤šè®¡ç®—æ…¢â€”&gt; InstantNGP</li>
</ul>
</li>
</ul>
<span id="more"></span>
<p><em>Other link about 3D Reconstruction: (need to add â€œ ../ â€œ in obsidian)</em></p>
<ul>
<li><a href="../Paper%20About%203D%20Reconstruction">Paper About 3D Reconstruction</a> <a href="../Multi-view/Implicit%20Function/NeRF-based/NeRF%20Other%20Research/NeRF-review">NeRF-review</a><ul>
<li><a href="../Practical/Finite%20Element%20Model%203D%20Reconstruction">Finite Element Model 3D Reconstruction</a> ä¸‰ç»´é‡å»ºå‡ºæœ‰é™å…ƒæ¨¡å‹ (åŒ»å­¦é¢†åŸŸè¾ƒå¤šç ”ç©¶, å·¥ä¸šé¢†åŸŸç›®å‰ç ”ç©¶æ¯”è¾ƒå°‘âœŠ)</li>
<li><a href="../Practical/Anime%20Image%203D%20Reconstruction">Anime Image 3D Reconstruction</a> æ ¹æ®åŠ¨æ¼«å›¾åƒé‡å»ºä¸‰ç»´æ¨¡å‹ (ç»“åˆ3Då½©è‰²æ‰“å°å®ç°æ‰‹åŠè‡ªç”±ğŸ˜Š)</li>
<li><a href="../Practical/Multi-view%20Human%20Body%20Reconstruction">Multi-view Human Body Reconstruction</a> é‡å»ºä¸‰ç»´äººä½“æ¨¡å‹ (æ•°å­—äººç›´æ’­, çœŸäººæ‰‹åŠğŸ˜Š)</li>
</ul>
</li>
<li><a href="../3D%20Model">3D Model</a> ä¸‰ç»´æ¨¡å‹çš„å„ç§å½¢å¼</li>
<li><a href="../Basics%20about%203D%20Reconstruction">Basics about 3D Reconstruction</a> ä¸‰ç»´é‡å»ºåŸºç¡€</li>
<li><a href="../Datasets">Datasets</a> ç›¸å…³æ•°æ®é›†</li>
<li><a href="../Code%20of%20Multi-view%203D%20Reconstruction%20based%20on%20SDF%20and%20volume%20rendering">Code of Multi-view 3D Reconstruction based on SDF and volume rendering</a> ä¸€äº›ç¯å¢ƒé…ç½®è®°å½•</li>
<li>Other<ul>
<li><a href="../Practical/Dimensions%20%20Measurement">Dimensions  Measurement</a> çœŸå®çš„å°ºå¯¸ä¿¡æ¯</li>
</ul>
</li>
</ul>
<p><a href="../../Blog&amp;Book&amp;Paper/Write/Write%20Paper/3D%20Reconstruction/Master%20Paper">Master Paper</a> ç¡•è®ºæ€è·¯ï¼Œæ‰“ç®—æ²¿ç€NeuSçš„è·¯çº¿è¿›è¡Œç›¸å…³æ”¹è¿›</p>
<p><strong>å¤šè§†å›¾ä¸‰ç»´é‡å»ºæ–¹æ³•çš„å…³é”®åœ¨äº</strong>:</p>
<ol>
<li>å¦‚ä½•è¡¨ç¤º3D model: mesh, voxel, pointcloud, RGBD, occupancy function,  Implicit Density Field, SDF or Other Primitive(é«˜æ–¯ä½“, æ¤­åœ†ä½“, çƒ)</li>
<li>å¦‚ä½•å°†3D model å¯å¾®åœ°æ¸²æŸ“æˆ2Då›¾åƒ: Volume Rendering or Rasterization?</li>
</ol>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20241010195323.png" alt="image.png|555"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Method</th>
<th>3D represent</th>
<th>Rendering method</th>
</tr>
</thead>
<tbody>
<tr>
<td>NeRF</td>
<td>Implicit Density Field (MLP)</td>
<td>Volume Rendering</td>
</tr>
<tr>
<td><strong>NeuS</strong></td>
<td>Implicit SDF (MLP)</td>
<td>Volume Rendering</td>
</tr>
<tr>
<td>3DGS</td>
<td>é«˜æ–¯ä½“<br>å½¢çŠ¶/æ–¹å‘â€”â€”ä¸­å¿ƒç‚¹+åæ–¹å·® <br>é¢œè‰²â€”â€”çƒè°å‡½æ•°, ä¸é€æ˜åº¦</td>
<td>Splatting (Rasterization)</td>
</tr>
<tr>
<td>EVER</td>
<td>æ¤­åœ†ä½“</td>
<td>Volume Rendering</td>
</tr>
</tbody>
</table>
</div>
<h1 id="Accuracy"><a href="#Accuracy" class="headerlink" title="Accuracy"></a>Accuracy</h1><h2 id="Camera-Pose-Estimation"><a href="#Camera-Pose-Estimation" class="headerlink" title="Camera Pose Estimation"></a>Camera Pose Estimation</h2><h2 id="3D-Point-Sampling"><a href="#3D-Point-Sampling" class="headerlink" title="3D Point Sampling"></a>3D Point Sampling</h2><h3 id="NerfAcc"><a href="#NerfAcc" class="headerlink" title="NerfAcc"></a>NerfAcc</h3><p>NerfAccï¼šå æ®+é€†å˜æ¢é‡‡æ · æ··åˆé‡‡æ ·æ–¹å¼<br>å…ˆä½¿ç”¨å æ®ç½‘æ ¼ç¡®å®šå“ªäº›åŒºåŸŸéœ€è¦é‡‡æ ·ï¼Œå†é€šè¿‡ç²—é‡‡æ ·å¾—åˆ°çš„æƒé‡ä½¿ç”¨é€†å˜æ¢é‡‡æ ·è¿›è¡Œç²¾é‡‡æ ·å¾—åˆ°é‡‡æ ·ç‚¹</p>
<h2 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h2><h3 id="S3IM"><a href="#S3IM" class="headerlink" title="S3IM"></a>S3IM</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2308.07032">S3IM: Stochastic Structural SIMilarity and Its Unreasonable Effectiveness for Neural Fields</a></p>
</blockquote>
<p>MSE loss æ˜¯ point-wise çš„ï¼Œæ²¡æœ‰è€ƒè™‘åˆ°ä¸€ç»„pixelçš„ç»“æ„ç‰¹å¾ï¼Œè€ŒSSIMé€šè¿‡ä¸€ä¸ªKxKçš„æ ¸å’Œstrideæ‰«è¿‡æ•´ä¸ªå›¾åƒï¼Œæœ€åæ±‚å¹³å‡MSSIMï¼Œå¯ä»¥è€ƒè™‘å›¾åƒçš„ç»“æ„ä¿¡æ¯ã€‚</p>
<ul>
<li>$\mathrm{SSIM}(a,b)=l(\boldsymbol{a},\boldsymbol{b})c(\boldsymbol{a},\boldsymbol{b})s(\boldsymbol{a},\boldsymbol{b}).$  ä¸€ä¸ªæ ¸è¦†ç›–çš„å›¾åƒï¼Œ$C_{1},C_{2},C_{3}$ æ˜¯å°çš„å¸¸æ•°<ul>
<li>luminanceäº®åº¦ï¼š$l(\boldsymbol{a},\boldsymbol{b})=\frac{2\mu_a\mu_b+C_1}{\mu_a^2+\mu_b^2+C_1},$</li>
<li>contrastå¯¹æ¯”åº¦ï¼š$c(\boldsymbol{a},\boldsymbol{b})=\frac{2\sigma_a\sigma_b+C_2}{\sigma_a^2+\sigma_b^2+C_2},$</li>
<li>structureç»“æ„ï¼š$s(\boldsymbol{a},\boldsymbol{b})=\frac{\sigma_{ab}+C_3}{\sigma_a\sigma_b+C_3}.$<br><em>ä½†æ˜¯åœ¨NeRFè®­ç»ƒè¿‡ç¨‹ä¸­pixelåœ¨ä¸€ä¸ªbatchæ˜¯éšæœºçš„ï¼Œä¸¢å¤±äº†å±€éƒ¨patchçš„åƒç´ ä¸­ä½ç½®ç›¸å…³çš„ä¿¡æ¯</em>ï¼Œæœ¬æ–‡æå‡ºçš„S3IMï¼Œæ˜¯SSIMçš„éšæœºå˜ä½“ã€‚æ¯ä¸ªminibatchæœ‰Bä¸ªåƒç´ ï¼Œæ ¸å¤§å°KxKï¼Œæ­¥é•¿s=K(å› ä¸ºåœ¨minibatchä¸­çš„éšæœºpatchæ˜¯ç‹¬ç«‹çš„ï¼Œè€Œä¸”ä¸éœ€è¦é‡å çš„æƒ…å†µ)</li>
</ul>
</li>
<li>å°†Bä¸ªåƒç´ /å…‰çº¿æ„æˆä¸€ä¸ªrendered patch $\mathcal{P}(\hat{\mathcal{C}})$ï¼ŒåŒæ—¶æœ‰ä¸€ä¸ªgt image patch $\mathcal{P}(\mathcal{C})$</li>
<li>è®¡ç®—renderedå’Œgt patchä¹‹é—´çš„$SSIM(\mathcal{P}(\hat{\mathcal{C}}),\mathcal{P}(\mathcal{C}))$ with kernel si ze KxK and stride size s =K</li>
<li>ç”±äºpatchæ˜¯éšæœºçš„ï¼Œé‡å¤Mæ¬¡ä¸Šè¿°ä¸¤æ­¥ï¼Œå¹¶è®¡ç®—Mæ¬¡SSIMçš„å¹³å‡å€¼</li>
</ul>
<p>$\mathrm{S3IM}(\hat{\mathcal{R}},\mathcal{R})=\frac{1}{M}\sum_{m=1}^{M}\mathrm{SSIM}(\mathcal{P}^{(m)}(\hat{\mathcal{C}}),\mathcal{P}^{(m)}(\mathcal{C}))$</p>
<p>$L_{\mathrm{S3IM}}(\Theta,\mathcal{R})=1-\mathrm{S3IM}(\hat{\mathcal{R}},\mathcal{R}) = =1-\frac1M\sum_{m=1}^M\mathrm{SSIM}(\mathcal{P}^{(m)}(\hat{\mathcal{C}}),\mathcal{P}^{(m)}(\mathcal{C}))$</p>
<h2 id="Volume-Rendering-SDF2Density"><a href="#Volume-Rendering-SDF2Density" class="headerlink" title="Volume Rendering (SDF2Density)"></a>Volume Rendering (SDF2Density)</h2><h3 id="VolSDF"><a href="#VolSDF" class="headerlink" title="VolSDF"></a>VolSDF</h3><p>$\sigma(\mathbf{r}(t))=\Psi_s(f(\mathbf{r}(t)))=\begin{cases}\frac{1}{2s}\exp\left(\frac{-f(\mathbf{r}(t))}{s}\right)&amp;\text{if }f(\mathbf{r}(t))\geq0,\\\frac{1}{s}\left(1-\frac{1}{2}\exp\left(\frac{f(\mathbf{r}(t))}{s}\right)\right)&amp;\text{if }f(\mathbf{r}(t))&lt;0.\end{cases}$</p>
<h3 id="NeuS"><a href="#NeuS" class="headerlink" title="NeuS"></a>NeuS</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2106.10689">NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction</a></p>
</blockquote>
<p>SDFå†…éƒ¨-1ï¼Œå¤–éƒ¨1ï¼Œè¡¨é¢0<br>$f(x)=\left\{\begin{matrix}d(x,\partial\Omega)&amp;\mathrm{if~}x\in\Omega\-d(x,\partial\Omega)&amp;\mathrm{if~}x\not\in\Omega.\end{matrix}\right.$</p>
<p>NeuSæ²¡æœ‰ä¸NeRFä¸€æ ·ç›´æ¥ä½¿ç”¨MLPè¾“å‡ºçš„ä¸é€æ˜åº¦$\sigma$ä½œä¸º$\rho$ï¼Œè€Œæ˜¯ä½¿ç”¨é¢„æµ‹çš„sdfè¿›è¡Œç›¸åº”è®¡ç®—å¾—åˆ°$\rho$ï¼Œä»¥åŠæƒé‡</p>
<ul>
<li>$C(\mathbf{o},\mathbf{v})=\int_{0}^{+\infty}w(t)c(\mathbf{p}(t),\mathbf{v})\mathrm{d}t$  $\omega(t)=T(t)\rho(t),\text{where}T(t)=\exp\left(-\int_0^t\rho(u)\mathrm{d}u\right)$</li>
<li>$\rho(t)=\max\left(\frac{-\frac{\mathrm{d}\Phi_s}{\mathrm{d}t}(f(\mathbf{p}(t)))}{\Phi_s(f(\mathbf{p}(t)))},0\right)$ , MLPé¢„æµ‹çš„sdfå³$f(\mathbf{p}(t))$ </li>
<li>$\phi_s(x) =\frac{se^{-sx}}{(1+e^{-sx})^{2}}$, $\Phi_s(x)=(1+e^{-sx})^{-1},\text{i.e.,}\phi_s(x)=\Phi_sâ€™(x)$</li>
</ul>
<p>ç¦»æ•£åŒ–ï¼š</p>
<ul>
<li>$\hat{C}=\sum_{i=1}^nT_i\alpha_ic_i,$ $\alpha_i=1-\exp\left(-\int_{t_i}^{t_{i+1}}\rho(t)\mathrm{d}t\right),$ $T_i=\prod_{j=1}^{i-1}(1-\alpha_j)$</li>
<li>$\alpha_i=\max\left(\frac{\Phi_s(f(\mathbf{p}(t_i)))-\Phi_s(f(\mathbf{p}(t_{i+1})))}{\Phi_s(f(\mathbf{p}(t_i)))},0\right).$</li>
<li>$\alpha_{i}=max()$</li>
</ul>
<p>é™¤äº†$\mathcal{L}1$å’Œ$\mathcal{L}_{mask}$æŸå¤±ä¹‹å¤–è¿˜ä½¿ç”¨äº†$\mathcal{L}_{r e g}=\frac{1}{n m}\sum_{k,i}(|\nabla f(\hat{\mathbf{p}}_{k,i})|_{2}-1)^{2}.$ (Eikonal term)</p>
<ul>
<li>where m is batch size(ray scalar), n is the point sampling size</li>
</ul>
<h3 id="TUVR"><a href="#TUVR" class="headerlink" title="TUVR"></a>TUVR</h3><p>$\sigma(t)=\begin{cases}\frac{1}{s(t)}\exp\left(\frac{-f(t)}{s(t)|fâ€™(t)|}\right)&amp;\text{if}f(t)\geq0,\\\frac{2}{s(t)}\left(1-\frac{1}{2}\exp\left(\frac{f(t)}{s(t)|fâ€™(t)|}\right)\right)&amp;\text{if}f(t)&lt;0.\end{cases}$</p>
<h3 id="NeuRodin"><a href="#NeuRodin" class="headerlink" title="NeuRodin"></a>NeuRodin</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://open3dvlab.github.io/NeuRodin/">NeuRodin: A Two-stage Framework for High-Fidelity Neural Surface Reconstruction</a><br><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2408.10178">arxiv.org/pdf/2408.10178</a></p>
</blockquote>
<p>å®¤å†…å¤–å¤§åœºæ™¯ï¼Œä¹‹å‰æ–¹æ³•å­˜åœ¨çš„é—®é¢˜ï¼š</p>
<ul>
<li>è¿‡åº¦å‡ ä½•æ­£åˆ™åŒ–a); </li>
<li>æ²¡æœ‰å¯¹å‡ ä½•æ‹“æ‰‘çº¦æŸb); </li>
<li>æœ¬æ–‡Two-stageçš„æƒ³æ³•ï¼šé¦–å…ˆå¯¹SDFä¸è¿›è¡Œçº¦æŸ(ä¸ç”¨$\mathcal{L}_{eik}$ï¼Œç±»ä¼¼densityè¿›è¡Œè®­ç»ƒ)ï¼Œç„¶åä½¿ç”¨å‡ ä½•æ­£åˆ™åŒ–æ¥refineå…‰æ»‘è¡¨é¢</li>
</ul>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240902141345.png" alt="image.png|666"></p>
<p>å…ˆå‰ SDF-based volume rendering æ–¹æ³•çš„ä¸è¶³ï¼š</p>
<ul>
<li>SDFåˆ°å¯†åº¦è½¬æ¢çš„ä¸åˆé€‚å‡è®¾ï¼š$\sigma(\mathbf{r}(t))=\Psi_s(f(\mathbf{r}(t)))=\begin{cases}\frac{1}{2s}\exp\left(\frac{-f(\mathbf{r}(t))}{s}\right)&amp;\text{if }f(\mathbf{r}(t))\geq0,\\\frac{1}{s}\left(1-\frac{1}{2}\exp\left(\frac{f(\mathbf{r}(t))}{s}\right)\right)&amp;\text{if }f(\mathbf{r}(t))&lt;0.\end{cases}$<ul>
<li>SDFå€¼ç›¸åŒçš„åŒºåŸŸå¯†åº¦å€¼ä¹Ÿæ˜¯ç›¸åŒçš„ï¼Œé™åˆ¶äº†å¯†åº¦åœº(derived from SDF)çš„è¡¨è¾¾èƒ½åŠ›ã€‚</li>
<li>åŸå…ˆçš„å¯†åº¦åœºæ–¹æ³•(NeRF)çš„å¯†åº¦å€¼èŒƒå›´å¯ä»¥æ˜¯$[0,+\infty]$ï¼Œè€ŒSDFè®¡ç®—å¾—åˆ°çš„å¯†åº¦èŒƒå›´åœ¨$\left(0,\frac{1}{s} \right]$ <a target="_blank" rel="noopener" href="https://www.desmos.com/calculator/u8gnwtp7jf?lang=zh-CN">Function Desmos</a></li>
</ul>
</li>
<li>å¯†åº¦åå·®(SDF to Densityè¿‡ç¨‹ä¸­)ï¼Œè™½æœ‰å¾ˆå¤šæ”¹è¿›ä½†æ˜¯åå·®ä»å­˜åœ¨ï¼Œ<strong>ä¸”å‡ ä½•æ­£åˆ™åŒ–ä¼šäº§ç”Ÿä¸€äº›ä¸å¥½å½±å“</strong> (exacerbates this bias, complicating model convergence and resulting in the creation of inaccurate surfaces)ï¼Œä¸€äº›æ”¹è¿›çš„æ–¹æ³•ï¼š<ul>
<li><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Towards_Unbiased_Volume_Rendering_of_Neural_Implicit_Surfaces_With_Geometry_CVPR_2023_paper.pdf">TUVR</a>: Towards Unbiased Volume Rendering of Neural Implicit Surfaces with Geometry Priors</li>
<li>Debsdf: Delving into the details and bias of neural indoor scene reconstruction</li>
<li>Recovering fine details for neural implicit surface reconstruction.</li>
</ul>
</li>
<li>å‡ ä½•è¿‡åº¦æ­£åˆ™åŒ–ï¼Œsuch as Eikonal loss or smoothness constraintsï¼Œ<strong>å¯¼è‡´ç¼ºé™·ï¼š</strong><ul>
<li>åœ¨æ‰€æœ‰åŒºåŸŸè¿‡åº¦å…‰æ»‘, both flat and intricate, leading to a loss of fine details)ã€‚</li>
<li>å½“ä¼˜åŒ–Normaläº§ç”Ÿçš„é¢œè‰²å’Œé€šè¿‡å‡ ä½•æ­£åˆ™åŒ–æ˜¾å¼åœ°çº¦æŸSDFæ—¶ï¼Œä¼˜åŒ–è¿‡ç¨‹ä¼šé˜»ç¢æ‹“æ‰‘ç»“æ„çš„äº§ç”Ÿã€‚</li>
</ul>
</li>
</ul>
<p>æœ¬æ–‡è§£å†³æ–¹æ³•ï¼š</p>
<ul>
<li><strong>Uniform SDF, Diverse Densities</strong> <ul>
<li>ç©ºé—´ä¸­æ¯ä¸€ç‚¹éƒ½æœ‰ç‹¬è‡ªçš„ç¼©æ”¾å› å­ï¼šä½¿ç”¨éçº¿æ€§æ˜ å°„æ¥æ ¹æ®ä¸‰ç»´ç©ºé—´ä¸­ä¸€ç‚¹åæ ‡è·å–ç‹¬ä¸€æ— äºŒçš„ç¼©æ”¾å› å­s (local scale $s(t)$)  (ç±»ä¼¼Adaptive shells for efficient neural radiance field rendering.çš„å·¥ä½œï¼Œéœ€è¦ç»“åˆSDFå’Œdensityçš„ç‰¹æ€§)</li>
<li>$(f(\mathbf{r}(t)),s(\mathbf{r}(t)),\mathbf{z}(\mathbf{r}(t)))=\phi_\text{geo}(\mathbf{r}(t)),\quad\sigma(\mathbf{r}(t))=\Psi_{s(\mathbf{r}(t))}\left(f(\mathbf{r}(t))\right).$ è§£é‡Šï¼š<strong>(SDF, s, å‡ ä½•ç‰¹å¾)=éçº¿æ€§æ˜ å°„(ç‚¹åæ ‡)</strong> and <strong>å¯†åº¦=å‡½æ•°(SDF, s)</strong></li>
</ul>
</li>
<li><strong>Explicit Bias Correction</strong> <ul>
<li>å­˜åœ¨çš„åå·® <img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240902132257.png" alt="image.png|333"><ul>
<li>A: maximum probability distance$\hat{D}_{\text{prob}}(\mathbf{r})=\arg\max_{t\in(0,+\infty)}w(t)=\arg\max_{t\in(0,+\infty)}T(t)\sigma(\mathbf{r}(t)).$</li>
<li>B: rendered distance $\hat{D}_{\text{rendered}}(\mathbf{r})=\int_0^{+\infty}T(t)\sigma(\mathbf{r}(t))t \mathrm{d}t.$ ç›¸å½“äºå¯¹æƒé‡æ±‚äº†å‡å€¼</li>
<li>C: SDF zero level set</li>
</ul>
</li>
<li>æœ¬æ–‡è§£å†³æ–¹æ³•:  <script type="math/tex">\mathcal{L}_{\mathrm{bias}}=\frac1m\sum_{\mathbf{r}\in\mathcal{R}}\max\left(f(\mathbf{r}(t^*+\epsilon_{\mathrm{bias}})),0\right),\quad t^{*}=\arg\max_{t\in(0,+\infty)}T(t)\sigma(\mathbf{r}(t))</script> <ul>
<li>é€šè¿‡çº¦æŸæ¯æ¡å…‰çº¿ä¸ŠA($t^*$ with bias correction factor $\epsilon_{\mathrm{bias}}$)ä¸Cçš„å·®å¼‚ï¼Œä¸”ä»…çº¦æŸsdfä¸ºæ­£(å³æ¨¡å‹å¤–éƒ¨)çš„éƒ¨åˆ† </li>
<li><strong><em>ä¸ºä»€ä¹ˆä¸çº¦æŸæ¨¡å‹å†…éƒ¨å‘¢ï¼Ÿï¼šé¼“åŠ±SDFåœ¨Aä½ç½®ä¹‹åå–è´Ÿå€¼ï¼Œç»éªŒæµ‹è¯•å‡ºæ¥çš„(é™„å½•C)ï¼Œä¸”æä¾›äº†<a target="_blank" rel="noopener" href="https://www.desmos.com/calculator/k1jklfvd5y?lang=zh-CN">æ•°å­¦è§£é‡Š</a>:</em></strong> å½“Aåœ¨Cä¹‹å‰æ—¶ï¼Œéšç€$\theta$ çš„å˜åŒ–ACä¹‹é—´å·®å¼‚å˜åŒ–çš„æ›´å¤§ï¼›å½“Aåœ¨Cä¹‹åæ—¶ï¼Œéšç€$\theta$çš„å˜åŒ–ACä¹‹é—´å·®å¼‚å˜åŒ–è¾ƒå° </li>
<li>$\epsilon_{\mathrm{bias}}$ æ˜¯ç”±äºé€‰å–maximumçš„æ–¹æ³•å¯¼è‡´çš„ï¼šç›´æ¥ä½¿ç”¨é‡‡æ ·ç‚¹çš„æœ€å¤§æƒé‡æ¥è¿‘ä¼¼$t^*$</li>
</ul>
</li>
</ul>
</li>
<li><strong>Two-Stage Optimization to Tackle Geometry Over-Regularization</strong><ul>
<li><strong>Stage 1</strong>â€”â€”Geometry Over-Regularization (estimated gradients + local scale s(VolSDF SDF2Density) + $\mathcal{L}_{\mathrm{bias}}$)<ul>
<li>ç›´è§‚è§£æ³•ï¼šæ¶ˆé™¤å‡ ä½•çº¦æŸæˆ–è€…é™ä½æƒé‡ï¼Œä¸”é¿å…conditioné¢œè‰²(predicted normal)ã€‚ ä½†æ˜¯ä¼šäº§ç”Ÿéè‡ªç„¶çš„SDF zero-level set</li>
<li>ç®€å•é«˜æ•ˆçš„è§£æ³•æ˜¯ï¼šä¸ç›´æ¥ä½¿ç”¨æ¢¯åº¦${\nabla f(\mathbf{r}(t))}$è¿›è¡Œå‡ ä½•æ­£åˆ™ï¼Œè€Œæ˜¯ä½¿ç”¨ä¼°è®¡æ¢¯åº¦$\hat{\nabla}f(\mathbf{r}(t))$é€šè¿‡ç‰¹æ®Šè®¾è®¡æ¥å¼•å…¥ä¸ç¡®å®šæ€§ï¼Œ<ul>
<li>xåˆ†é‡çš„ä¼°è®¡æ¢¯åº¦ä¸ºï¼š$\hat{\nabla}_xf(\mathbf{r}(t))=\frac{f\left(\mathbf{r}(t)+\boldsymbol{\epsilon}_x\right)-f\left(\mathbf{r}(t)-\boldsymbol{\epsilon}_x\right)}{2\epsilon},\quad\text{where }\epsilon_x=(\epsilon,0,0)\text{ and }\epsilon\sim U(0,\epsilon_{\max}).$</li>
<li>é€šè¿‡æœ‰é™å·®åˆ†æ³•ä¼°è®¡æ¢¯åº¦çš„step size $\epsilon$æ˜¯ä¸€ä¸ªéšæœºé‡‡æ ·çš„æ•°ï¼Œè¿™æ ·åœ¨æ›´å¤§çš„åœºæ™¯çš„estimated normalä¸­æœ‰å¾ˆå°çš„varianceï¼Œåœ¨fine detailsçš„normalä¸­æœ‰æ›´å¤§çš„varianceã€‚<strong>è¿™æ ·çš„ä¸ç¡®å®šæ€§ç¡®ä¿äº†æ›´å¤§ç‰¹å¾çš„ç¨³å®šæ€§å’Œå¤æ‚ç»†èŠ‚çš„çµæ´»æ€§</strong></li>
</ul>
</li>
<li>æ€»ç»“:<ul>
<li>$\mathcal{L}_{\mathrm{coarse}}=\mathcal{L}_{\mathrm{color}}+\lambda_{\mathrm{eik}}\mathcal{L}_{\mathrm{eik}}(\hat{\nabla}f)+\lambda_{\mathrm{bias}}\mathcal{L}_{\mathrm{bias}}.$</li>
<li>VolSDFçš„SDF-to-densityæ–¹æ³•ï¼š<ul>
<li>$\sigma(\mathbf{r}(t))=\Psi_s(f(\mathbf{r}(t)))=\begin{cases}\frac{1}{2s}\exp\left(\frac{-f(\mathbf{r}(t))}{s}\right)&amp;\text{if }f(\mathbf{r}(t))\geq0,\\\frac{1}{s}\left(1-\frac{1}{2}\exp\left(\frac{f(\mathbf{r}(t))}{s}\right)\right)&amp;\text{if }f(\mathbf{r}(t))&lt;0.\end{cases}$</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>Stage 2</strong>â€”â€”Refinement (estimated gradients + TUVR SDF2Density + $\mathcal{L}_{\mathrm{smooth}}$)<ul>
<li>ä½¿ç”¨PermutoSDFçš„æŸå¤±$\mathcal{L}_{\mathrm{smooth}}=\frac1{mn}\sum_{\mathbf{r},t}\left(\mathbf{n}\left(\mathbf{r}(t)\right)\cdot\mathbf{n}\left(\mathbf{r}(t)+\epsilon_s\boldsymbol{\eta}(\mathbf{r}(t))\right)-1\right)^2,$ æ¥å¢åŠ å±€éƒ¨å…‰æ»‘åº¦ï¼Œ$\boldsymbol{\eta}(\mathbf{r}(t)) = \mathbf{n}(\mathbf{r}(t)) \times \boldsymbol{\tau}$ å…¶ä¸­$\tau$æ˜¯éšæœºå•ä½å‘é‡</li>
<li>æ€»ç»“:<ul>
<li>é‡‡ç”¨TUVRçš„ SDF-to-densityæ–¹æ³•ï¼Œä¿è¯æœ€å°åŒ–biasä¸”ä¿å­˜fineçš„ç‰©ä½“ç»†èŠ‚<ul>
<li>$\sigma(t)=\begin{cases}\frac{1}{s(t)}\exp\left(\frac{-f(t)}{s(t)|fâ€™(t)|}\right)&amp;\text{if}f(t)\geq0,\\\frac{2}{s(t)}\left(1-\frac{1}{2}\exp\left(\frac{f(t)}{s(t)|fâ€™(t)|}\right)\right)&amp;\text{if}f(t)&lt;0.\end{cases}$</li>
</ul>
</li>
<li>$\mathcal{L}_{\mathrm{fine}}=\mathcal{L}_{\mathrm{color}}+\lambda_{\mathrm{eik}}\mathcal{L}_{\mathrm{eik}}(\nabla f)+\lambda_{\mathrm{smooth}}\mathcal{L}_{\mathrm{smooth}}.$</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>é™„å½•çš„ç†è®ºåˆ†æ:</p>
<ol>
<li>æ ¹æ®æƒé‡æœ€å¤§çš„ç‚¹$t^*=\arg\max_{t\in(0,+\infty)}T(t)\sigma(\mathbf{r}(t))$</li>
<li>åœ¨è¯¥ç‚¹åº”è¯¥æ»¡è¶³$\frac{\partial w(t)}{\partial t}\Bigg|_{t=t^*}=0$</li>
<li>å¯ä»¥æ¨å¯¼å‡º<script type="math/tex">\sigma^2(\mathbf{r}(t^*))=\left.\frac{\partial\sigma(\mathbf{r}(t))}{\partial t}\right|_{t=t^*}</script></li>
</ol>
<p>å› æ­¤æ„å»ºçš„SDF-to-densityå‡½æ•°å¿…é¡»æ»¡è¶³ï¼š</p>
<ul>
<li>æ¡ä»¶1 <script type="math/tex">\sigma^2(\mathbf{r}(t^*))=\left.\frac{\partial\sigma(\mathbf{r}(t))}{\partial t}\right|_{t=t^*}</script></li>
<li>æ¡ä»¶2 (SDF=0çš„ç‚¹ï¼ŒåŒæ—¶æƒé‡æœ€å¤§) <script type="math/tex">f(r(t^0))=0</script><br>ç„¶è€Œï¼š</li>
<li>NeuSåªæœ‰åœ¨æ²¿ç€å…‰çº¿çš„SDFåˆ†å¸ƒçš„ä¸€é˜¶è¿‘ä¼¼æ¡ä»¶ä¸‹æ‰æ»¡è¶³æ­¤æ¡ä»¶</li>
<li>TUVRæ‰©å±•åˆ°äº†ä»»æ„åˆ†å¸ƒï¼Œä½†æ˜¯ä»æœ‰é—®é¢˜å°±æ˜¯ä¸ä¸€å®š$t^{0} \neq t^{*}$ï¼Œ(åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œæ²¿ç€å…‰çº¿çš„æƒé‡åˆ†å¸ƒæ˜¯ä¸€ä¸ªå¤æ‚çš„non-convexå‡½æ•°ï¼Œåªèƒ½æ‹…ä¿$t^{0}$æ˜¯åœ¨å±€éƒ¨æœ€å¤§å€¼ä¸Š)</li>
</ul>
<h3 id="ReTR"><a href="#ReTR" class="headerlink" title="ReTR"></a>ReTR</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2305.18832">ReTR: Modeling Rendering Via Transformer for Generalizable Neural Surface Reconstruction</a></p>
</blockquote>
<p><strong>ä½¿ç”¨Transformer ä»£æ›¿æ¸²æŸ“è¿‡ç¨‹ï¼Œå¹¶ä¸”æ·»åŠ äº†æ·±åº¦ç›‘ç£</strong></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231109094904.png" alt="image.png|666"></p>
<h2 id="Mixture-of-Experts-MoE"><a href="#Mixture-of-Experts-MoE" class="headerlink" title="Mixture of Experts (MoE)"></a>Mixture of Experts (MoE)</h2><h3 id="Boost-Your-NeRF"><a href="#Boost-Your-NeRF" class="headerlink" title="Boost Your NeRF"></a>Boost Your NeRF</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.10389#page=20.42">Boost Your NeRF: A Model-Agnostic Mixture of Experts Framework for High Quality and Efficient Rendering</a></p>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/blog/zh/moe#%E4%BB%80%E4%B9%88%E6%98%AF%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%E6%A8%A1%E5%9E%8B">æ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰è¯¦è§£</a> MoE å±‚ç”±ä¸¤ä¸ªæ ¸å¿ƒéƒ¨åˆ†ç»„æˆ: ä¸€ä¸ªé—¨æ§ç½‘ç»œ(ç”¨äºå†³å®šå“ªäº›ä»¤ç‰Œ (token) è¢«å‘é€åˆ°å“ªä¸ªä¸“å®¶)å’Œè‹¥å¹²æ•°é‡çš„ä¸“å®¶(æ¯ä¸ªä¸“å®¶æœ¬èº«æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ç¥ç»ç½‘ç»œ)</p>
</blockquote>
<ul>
<li>é—¨æ§ç½‘ç»œæ¥å†³å®šé‡‡æ ·ç‚¹è¢«è¾“å…¥å“ª Top-Kä¸ªä¸“å®¶ç½‘ç»œ(å¹¶ä¸”åœ¨filtering stepæŠ›å¼ƒlow-densityçš„ç‚¹ï¼Œå¯†åº¦å€¼æ ¹æ®lowest resolution model è¿›è¡Œè®¡ç®—)</li>
<li>æ¯ä¸ªä¸“å®¶ç½‘ç»œä»¥é‡‡æ ·ç‚¹ä½ç½®å’Œæ–¹å‘ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºé¢œè‰²å’Œå¯†åº¦</li>
<li>æ ¹æ®è¯¥ç‚¹åˆ°æ¯ä¸ªä¸“å®¶ç½‘ç»œçš„æƒé‡(æ¦‚ç‡Probability Field)å’Œé¢œè‰²å¯†åº¦å€¼ï¼Œè®¡ç®—è¯¥ç‚¹æœ€ç»ˆçš„é¢œè‰²å’Œå¯†åº¦å€¼ã€‚æœ€åé€šè¿‡ä½“æ¸²æŸ“å¾—åˆ°pixel colorï¼Œå¹¶è”åˆä¼˜åŒ–resolution-weighted auxiliary loss(ç”¨äºé€‰å–ä¸“å®¶ç½‘ç»œ)</li>
</ul>
<p>ä¸»è¦æ€æƒ³æ˜¯åœ¨è®­ç»ƒäº†ä¸€æ‰¹ä¸åŒåˆ†è¾¨ç‡çš„NeRF modelsåï¼Œä¼˜å…ˆä½¿ç”¨low-resolution modelsï¼Œå‡å°‘high-resolution models çš„ä½¿ç”¨</p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240806202919.png" alt="image.png|666"></p>
<h1 id="Efficiency"><a href="#Efficiency" class="headerlink" title="Efficiency"></a>Efficiency</h1><ol>
<li>å®Œå…¨æŠ›å¼ƒMLPï¼Œå­˜å‚¨æ˜¾ç¤ºçš„é¢œè‰²/å¯†åº¦</li>
<li>åŠ é€Ÿæ¸²æŸ“ï¼šå¯¹å‡ ä½•ä»£ç†è¿›è¡Œå…‰æ …åŒ–å¤„ç†</li>
<li>åŠ é€Ÿæ¸²æŸ“ï¼šä½¿ç”¨å‰ä¸€ä¸ªè§†å›¾çš„ä¿¡æ¯æ¥å‡å°‘æ¸²æŸ“åƒç´ çš„æ•°é‡</li>
</ol>
<h2 id="Explicit-Grids"><a href="#Explicit-Grids" class="headerlink" title="Explicit Grids"></a>Explicit Grids</h2><p><strong>Explicit Grids with features(Efficiency of T&amp;R)</strong></p>
<p><strong>(å‡è½»MLPæ¶æ„)</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Explicit Grids</th>
<th>Related Works</th>
</tr>
</thead>
<tbody>
<tr>
<td>Feature grids</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2112.05131">Plenoxels</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2111.11215">DirectVoxGo</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2201.05989">InstantNGP</a></td>
</tr>
<tr>
<td>Tri-planes</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2307.11335">Tri-MipRF</a></td>
</tr>
<tr>
<td>Multi-plane images</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2310.00249">MMPI</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.16109">fMPI</a></td>
</tr>
<tr>
<td>Tensorial vectors</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2203.09517">TensoRF</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2307.13226">Strivec</a></td>
</tr>
</tbody>
</table>
</div>
<h3 id="NGP-RT"><a href="#NGP-RT" class="headerlink" title="NGP-RT"></a>NGP-RT</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.10482">NGP-RT: Fusing Multi-Level Hash Features with Lightweight Attention for Real-Time Novel View Synthesis</a></p>
</blockquote>
<p>InstantNGP è™½ç„¶è®­ç»ƒé€Ÿåº¦(æŸ¥è¯¢ç½‘æ ¼)å¾ˆå¿«ï¼Œä½†æ˜¯æ¸²æŸ“çš„æ—¶å€™ä»ç„¶éœ€è¦å¤§é‡çš„3D PointæŸ¥è¯¢MLPï¼Œè€—è´¹å¤§é‡æ—¶é—´</p>
<p>(<em>Deferred neural rendering</em>) SNeRG [12] å’Œ MERF [32] é€šè¿‡å°†é¢œè‰²å’Œå¯†åº¦å­˜åœ¨æ˜¾ç¤ºç½‘æ ¼ä¸­ï¼Œ<strong>åªå¯¹æ¯æ¡æŠ•å°„å…‰çº¿æ‰§è¡Œä¸€æ¬¡ MLP</strong>ï¼Œä»è€Œå¤§å¤§åŠ å¿«äº†æ¸²æŸ“è¿‡ç¨‹ã€‚ç„¶è€Œï¼Œä»–ä»¬å¯¹æ˜¾å¼ç‰¹å¾çš„å¤„ç†æ˜¾ç¤ºå‡ºæœ‰é™çš„è¡¨è¾¾èƒ½åŠ›ï¼Œä¸é€‚åˆ Instant-NGP çš„å¤šçº§ç‰¹å¾ã€‚<strong>å°†è¿™äº›ç‰¹å¾æ„å»ºæ–¹æ³•ç›´æ¥åº”ç”¨äº Instant-NGP ä¸­çš„å¤šçº§ç‰¹å¾å¯èƒ½ä¼šå¯¼è‡´å…¶è¡¨ç¤ºèƒ½åŠ›å—æŸï¼Œå¹¶å¯¼è‡´æ¸²æŸ“è´¨é‡ä¸‹é™</strong>ã€‚</p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240718142648.png" alt="image.png|666"></p>
<p>æå‡ºäº† NGP-RTï¼Œä¸€ç§åˆ©ç”¨è½»é‡çº§æ³¨æ„åŠ›æœºåˆ¶é«˜æ•ˆæ¸²æŸ“é«˜ä¿çœŸæ–°è§†å›¾çš„æ–°æ–¹æ³•ã€‚NGP-RT çš„æ³¨æ„åŠ›æœºåˆ¶é‡‡ç”¨äº†ç®€å•è€Œæœ‰æ•ˆçš„åŠ æƒå’Œè¿ç®—ï¼Œå¯å­¦ä¹ çš„æ³¨æ„åŠ›å‚æ•°å¯è‡ªé€‚åº”åœ°ä¼˜å…ˆå¤„ç†æ˜¾å¼å¤šçº§å“ˆå¸Œç‰¹å¾</p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240718142838.png" alt="image.png|666"></p>
<h2 id="MIMO-MLP"><a href="#MIMO-MLP" class="headerlink" title="MIMO MLP"></a>MIMO MLP</h2><p><strong>Multi input and Multi output MLP(Efficiency of T&amp;R)</strong></p>
<p><strong>(å‡å°‘MLPè®¡ç®—æ¬¡æ•°)</strong></p>
<h3 id="MIMO-NeRF"><a href="#MIMO-NeRF" class="headerlink" title="MIMO-NeRF"></a>MIMO-NeRF</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2310.01821">MIMO-NeRF: Fast Neural Rendering with Multi-input Multi-output Neural Radiance Fields</a></p>
</blockquote>
<p>å¤šè¾“å…¥å¤šè¾“å‡ºçš„MLPï¼ŒåŒæ—¶è¾“å…¥å¤šä¸ªä¸‰ç»´ç‚¹æ¥è¿›è¡Œè®¡ç®—</p>
<h2 id="Points-Sampling"><a href="#Points-Sampling" class="headerlink" title="Points Sampling"></a>Points Sampling</h2><p><strong>Points Sampling(Efficiency of T&amp;R)</strong></p>
<p><strong>(å‡å°‘é‡‡æ ·ç‚¹æ•°é‡ per ray)</strong></p>
<h3 id="HashPoint"><a href="#HashPoint" class="headerlink" title="HashPoint"></a><a target="_blank" rel="noopener" href="https://jiahao-ma.github.io/hashpoint/">HashPoint</a></h3><p>Primary surface point sampling</p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240823163840.png" alt="image.png|666"></p>
<h2 id="Pixel-Sampling"><a href="#Pixel-Sampling" class="headerlink" title="Pixel Sampling"></a>Pixel Sampling</h2><p><strong>Pixel Sampling (Efficiency of Training)</strong></p>
<p><strong>(å‡å°‘MLPè®¡ç®—æ¬¡æ•°)</strong></p>
<p>ä¹‹å‰æ–¹æ³•å¯¹train_dataä¸­æ‰€æœ‰çš„åƒç´ rgbä¸‰ä¸ªå€¼ï¼Œè¿›è¡Œé¢„æµ‹+l1 loss+åå‘ä¼ æ’­ï¼Œè®­ç»ƒé€Ÿåº¦å¾ˆæ…¢</p>
<h3 id="Uniform-sampling"><a href="#Uniform-sampling" class="headerlink" title="Uniform sampling"></a>Uniform sampling</h3><figure class="highlight python"><figcaption><span>pseudocode</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">  <span class="comment"># æ¯ä¸ªepochå¯¹æ¯å¼ å›¾ç‰‡è¿›è¡Œè®­ç»ƒä¸€è½®ï¼Œæ¯å¼ å›¾ç‰‡æŒ‘é€‰n_raysä¸ªåƒç´ </span></span><br><span class="line">  <span class="keyword">for</span> batch_data <span class="keyword">in</span> dataloader: <span class="comment"># batch_size = n_images</span></span><br><span class="line">    batch_rays = n_images * n_rays <span class="comment"># é€‰å–åƒç´ ä½ç½®ä¸ªæ•°</span></span><br><span class="line">    gt_rgb = Select_rgb(batch_rays) <span class="comment"># æ ¹æ®ä½ç½®è·å¾— gt rgb</span></span><br><span class="line">    render_rgb = F(batch_rays) <span class="comment"># æ ¹æ®ä½ç½®æ¸²æŸ“ render rgb</span></span><br><span class="line">    loss = <span class="built_in">abs</span>(render_rgb, gt_rgb) <span class="comment"># æ±‚loss</span></span><br><span class="line">    backward() <span class="comment"># åå‘ä¼ æ’­</span></span><br></pre></td></tr></table></figure>
<p>é€šè¿‡é‡åŒ–rendering image ä¸ g.t. image ä¹‹é—´çš„å·®å¼‚ï¼Œæ¥æŒ‡å¯¼åœ¨å›¾åƒä¸Šé‡‡æ ·åƒç´ çš„ä½ç½®/æ•°é‡ï¼šæ ¹æ®error map between rendering image and g.t. imageï¼Œæ¶ˆé™¤lossæ¯”è¾ƒå°çš„åŒºåŸŸï¼Œå¯¹losså¤§çš„åŒºåŸŸè¿›è¡Œæ›´å¤šçš„é‡‡æ ·</p>
<p><strong>idea</strong>ï¼š</p>
<ul>
<li>Other sampling method å¦‚æœè¦åŠ é€Ÿè®­ç»ƒçš„è¯ï¼Œå°±è¦ä½¿ç”¨æ›´é«˜æ•ˆçš„é‡‡æ ·æ–¹æ³•<ul>
<li>LHS (Latin hypercube sampling)</li>
</ul>
</li>
<li>è¿™ç§æ–¹æ³•åªèƒ½å¯¹Trainè¿‡ç¨‹è¿›è¡ŒåŠ é€Ÿ</li>
<li>ç”±äºä¼˜åŒ–çš„æ˜¯MLPæ•´ä½“çš„å‚æ•°ï¼Œå› æ­¤å¯èƒ½å‡ºç°å¯¹è¯¯å·®å¤§çš„åƒç´ ä¼˜åŒ–æ—¶ï¼Œé™ä½è¯¯å·®å°çš„åƒç´ çš„é¢„æµ‹ç²¾åº¦ã€‚</li>
<li>å¯èƒ½ä¼šå¯¹errorå¤§ä½†æ˜¯éé‡è¦åŒºåŸŸçš„åƒç´ è¿›è¡Œå¤šæ¬¡é‡‡æ ·</li>
</ul>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/37121528">é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡ç½—ç®—æ³•ï¼ˆMCMCï¼‰ - çŸ¥ä¹</a> Basic<br><a target="_blank" rel="noopener" href="https://coderlemon17.github.io/posts/2022/05-11-mcmc/">è¯¦è§£Markov Chain Monte Carlo (MCMC): ä»æ‹’ç»-æ¥å—é‡‡æ ·åˆ°Gibbs Sampling | Lemonâ€™s Blog</a> <strong>æ›´æ¸…æ¥šä¸€ç‚¹</strong><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/u012290039/article/details/105696097">MCMCè¯¦è§£2â€”â€”MCMCé‡‡æ ·ã€M-Hé‡‡æ ·ã€Gibbsé‡‡æ ·ï¼ˆé™„ä»£ç ï¼‰</a><br><a target="_blank" rel="noopener" href="https://allenwind.github.io/blog/10466/">é‡‡æ ·ï¼ˆä¸‰ï¼‰ï¼šé‡è¦æ€§é‡‡æ ·ä¸æ¥å—æ‹’ç»é‡‡æ · | Erwin Feng Blog</a><br><a target="_blank" rel="noopener" href="https://chi-feng.github.io/mcmc-demo/">The Markov-chain Monte Carlo Interactive Gallery</a> <strong>å¤šç§MCMCé‡‡æ ·æ–¹æ³•</strong></p>
</blockquote>
<p>Monte Carloé‡‡æ ·æ— æ³•å¾—åˆ°å¤æ‚çš„åˆ†å¸ƒ(äºŒç»´åˆ†å¸ƒ)ï¼ŒåŠ å…¥Markov Chainï¼Œé©¬å°”ç§‘å¤«é“¾æ¨¡å‹çš„çŠ¶æ€è½¬ç§»çŸ©é˜µæ”¶æ•›åˆ°çš„ç¨³å®šæ¦‚ç‡åˆ†å¸ƒä¸æˆ‘ä»¬çš„åˆå§‹çŠ¶æ€æ¦‚ç‡åˆ†å¸ƒæ— å…³$\pi(j)=\sum_{i=0}^\infty\pi(i)P_{ij}$(åªä¸çŠ¶æ€è½¬ç§»çŸ©é˜µæœ‰å…³)ï¼Œå¦‚æœå¯ä»¥å¾—åˆ°çŠ¶æ€è½¬ç§»çŸ©é˜µï¼Œå°±å¯ä»¥é‡‡æ ·å¾—åˆ°å¹³ç¨³åˆ†å¸ƒçš„æ ·æœ¬é›†ã€‚å¦‚ä½•å¾—åˆ°çŠ¶æ€è½¬ç§»çŸ©é˜µï¼Ÿ<br>â€”&gt; MCMCæ–¹æ³•(ä¸æ‹’ç»-æ¥å—é‡‡æ ·çš„æ€è·¯ç±»ä¼¼ï¼Œå…¶é€šè¿‡æ‹’ç»-æ¥å—æ¦‚ç‡æ‹Ÿåˆä¸€ä¸ªå¤æ‚åˆ†å¸ƒ, MCMCæ–¹æ³•åˆ™é€šè¿‡æ‹’ç»-æ¥å—æ¦‚ç‡å¾—åˆ°ä¸€ä¸ªæ»¡è¶³ç»†è‡´å¹³ç¨³æ¡ä»¶çš„è½¬ç§»çŸ©é˜µ.)</p>
<ul>
<li>Metropolis-Hastings Samplingï¼šéœ€è¦è®¡ç®—æ¥å—ç‡, åœ¨é«˜ç»´æ—¶è®¡ç®—é‡å¤§, å¹¶ä¸”ç”±äºæ¥å—ç‡çš„åŸå› å¯¼è‡´ç®—æ³•æ”¶æ•›æ—¶é—´å˜é•¿. å¯¹äºé«˜ç»´æ•°æ®, å¾€å¾€æ•°æ®çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒæ˜“å¾—, è€Œè”åˆæ¦‚ç‡åˆ†å¸ƒä¸æ˜“å¾—.</li>
<li>Gibbs Samplingï¼š</li>
</ul>
<h3 id="LMC-sampling"><a href="#LMC-sampling" class="headerlink" title="LMC sampling"></a>LMC sampling</h3><figure class="highlight python"><figcaption><span>pseudocode</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">  <span class="comment"># æ¯ä¸ªepochå¯¹æ¯å¼ å›¾ç‰‡è¿›è¡Œè®­ç»ƒä¸€è½®ï¼Œæ¯å¼ å›¾ç‰‡æŒ‘é€‰n_raysä¸ªåƒç´ </span></span><br><span class="line">  <span class="keyword">for</span> batch_data <span class="keyword">in</span> dataloader: <span class="comment"># batch_size = 1 æœ€å‡†ç¡®</span></span><br><span class="line">    <span class="keyword">for</span> sample_t <span class="keyword">in</span> <span class="built_in">range</span>(sa)</span><br><span class="line">      batch_rays = n_images * n_rays <span class="comment"># é€‰å–åƒç´ ä½ç½®ä¸ªæ•°</span></span><br><span class="line">      gt_rgb = Select_rgb(batch_rays) <span class="comment"># æ ¹æ®ä½ç½®è·å¾— gt rgb</span></span><br><span class="line">      render_rgb = F(batch_rays) <span class="comment"># æ ¹æ®ä½ç½®æ¸²æŸ“ render rgb</span></span><br><span class="line">      loss = <span class="built_in">abs</span>(render_rgb, gt_rgb) <span class="comment"># æ±‚loss</span></span><br><span class="line">      backward() <span class="comment"># åå‘ä¼ æ’­</span></span><br></pre></td></tr></table></figure>
<h3 id="Soft-Mining"><a href="#Soft-Mining" class="headerlink" title="Soft Mining"></a>Soft Mining</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.00075">Accelerating Neural Field Training via Soft Mining</a></p>
<p><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/pii/S0262885623000446">EGRA-NeRF: Edge-Guided Ray Allocation for Neural Radiance Fields</a> NeRF çš„æ¸²æŸ“æ˜¾å¾—è¿‡äºæ¨¡ç³Šï¼Œå¹¶ä¸”åœ¨æŸäº›çº¹ç†æˆ–è¾¹ç¼˜ä¸­åŒ…å«é”¯é½¿ä¼ªå½±ï¼Œä¸ºæ­¤æå‡ºäº†è¾¹ç¼˜å¼•å¯¼å…‰çº¿åˆ†é…ï¼ˆEGRA-NeRFï¼‰æ¨¡å—ï¼Œä»¥<strong>åœ¨è®­ç»ƒé˜¶æ®µå°†æ›´å¤šå…‰çº¿é›†ä¸­åœ¨åœºæ™¯çš„çº¹ç†å’Œè¾¹ç¼˜ä¸Š</strong> <strong>(æ²¡æœ‰åŠ é€Ÿ)</strong></p>
</blockquote>
<p>To implement our idea we use Langevin Monte-Carlo sampling. We show that by doing so, regions with higher error are being selected more frequently, leading to more than 2x improvement in convergence speed.<br>$\mathcal{L}=\frac{1}{N}\sum_{n=1}^{N}\mathrm{err}(\mathbf{x}_{n})\approx\mathbb{E}_{\mathbf{x}\sim P(\mathbf{x})}\left[\mathrm{err}(\mathbf{x})\right]=\int\mathrm{err}(\mathbf{x})P(\mathbf{x})d\mathbf{x}$. P is the distribution of the sampled data points $x_{n}$. ä¹‹å‰æ–¹æ³•å¤§å¤šæ˜¯å‡åŒ€åˆ†å¸ƒ<br>å…·ä½“åšæ³•ï¼š</p>
<ol>
<li>Soft mining with <strong>importance sampling</strong>. å¼•å…¥äº† importance distribution$Q(x)$</li>
</ol>
<blockquote>
<p>è¡¥å……çŸ¥è¯† <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1SV4y1i7bW/?spm_id_from=333.788&amp;vd_source=1dba7493016a36a32b27a14ed2891088">[è’™ç‰¹å¡æ´›æ–¹æ³•] 02 é‡è¦æ€§é‡‡æ ·ï¼ˆimportance samplingï¼‰åŠ python å®ç°_å“”å“©å“”å“©_bilibili</a> å¯ä»¥ä»ä¸€ä¸ªä»»æ„åˆ†å¸ƒä¸­è¿›è¡Œé‡‡æ ·</p>
</blockquote>
<p>è¯¯å·®å¯ä»¥é‡å†™ä¸ºï¼š$\int\operatorname{err}(\mathbf{x})P(\mathbf{x})d\mathbf{x} =\int\frac{\mathrm{err}(\mathbf{x})P(\mathbf{x})}{Q(\mathbf{x})}Q(\mathbf{x})d\mathbf{x}  =\mathbb{E}_{\mathbf{x}\sim Q(\mathbf{x})}\left[\frac{\mathrm{err}(\mathbf{x})P(\mathbf{x})}{Q(\mathbf{x})}\right].$ ç”±äºå‡åŒ€åˆ†å¸ƒ$P(x)$çš„PDFé€šå¸¸ä¸ºå¸¸æ•°ï¼Œå› æ­¤$\mathcal{L}=\frac{1}{N}\sum_{n=1}^{N}\frac{\mathrm{err}(\mathbf{x}_{n})}{Q(\mathbf{x}_{n})}$ $\mathrm{where} \quad\mathbf{x}_{n}\sim Q(\mathbf{x}).$<br>ä½†æ˜¯$\mathcal{L}$æ— æ³•ç”¨äºè®­ç»ƒï¼Œé‡‡ç”¨<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1711.00937">stop gradient operator</a>(åœ¨æ­£å‘è®¡ç®—æ—¶å®šä¹‰ä¸ºåŒä¸€å€¼ï¼Œä¸”åå¯¼æ•°ä¸ºé›¶)<br>$\mathcal{L}\approx\mathbb{E}_{\mathbf{x}\sim\mathrm{sg}(Q(\mathbf{x}))}\left[\frac{\mathrm{err}(\mathbf{x})}{\mathrm{sg}(Q(\mathbf{x}))}\right].$<br>é€‰æ‹©çš„$Q(x)$å¿…é¡»ä¸$err(x)$æˆæ¯”ä¾‹å…³ç³»(æ¶ˆé™¤errorå°ºåº¦çš„å½±å“)ï¼š$\mathrm{err}(\mathbf{x})=|f_{\boldsymbol{\psi}}(\mathbf{x})-f_{\mathrm{gt}}(\mathbf{x})|_{2}^{2},\\Q(\mathbf{x})=|f_{\boldsymbol{\psi}}(\mathbf{x})-f_{\mathrm{gt}}(\mathbf{x})|_{1}.$<br><strong>æ ¹æ®</strong>$Q(x)$çš„å®šä¹‰ï¼Œä¼šåœ¨errorå¤§çš„åœ°æ–¹å¤šé‡‡æ ·ä¸€äº›$x$å³åƒç´ ç‚¹<br>Soft mining. $\mathcal{L}=\frac1N\sum_{n=1}^N\left[\frac{\mathrm{err}(\mathbf{x}_n)}{\mathrm{sg}(Q(\mathbf{x}_n))^\alpha}\right],\quad\text{where }\alpha\in[0,1]$(åœ¨å…³æ³¨errorå¤§çš„åŒºåŸŸçš„åŒæ—¶ä¹Ÿè¦å…³æ³¨ä¸€ä¸‹å…¶ä»–åŒºåŸŸï¼Œä¸ç„¶å¯èƒ½ä¼šå­¦æ­ª)</p>
<ul>
<li>$\alpha = 0$ï¼šhard mining</li>
<li>$\alpha = 1$ï¼š(pure) importance sampling</li>
</ul>
<ol>
<li>Sampling via <strong>Langevin Monte Carlo</strong></li>
</ol>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1811.10072">The promises and pitfalls of Stochastic Gradient Langevin Dynamics</a> æ•°å­¦åˆ†æLMC, SGLD, SGLDFP and SGD<br><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1206.1901">MCMC using Hamiltonian dynamics</a> </p>
</blockquote>
<p>ä»ä»»æ„åˆ†å¸ƒ$Q(x)$ä¸­é‡‡æ ·ï¼Œä½¿ç”¨MCMCæ–¹æ³•ä¸­çš„Langevin Monte Carlo (LMC)<br>$\mathbf{x}_{t+1}=\mathbf{x}_t+a\nabla\log Q(\mathbf{x}_t)+b\boldsymbol{\eta}_{t+1},$</p>
<ul>
<li>a&gt;0 is a hyperparameter defining the step size for the gradient-based walks</li>
<li>b&gt;0 is a hyperparameter defining the step size for the random walk $\boldsymbol{\eta}_{t\boldsymbol{+}1}\boldsymbol{\sim}\mathcal{N}(0,\mathbf{1})$</li>
<li>é‡‡æ ·æ˜¯å±€éƒ¨çš„ï¼Œå› æ­¤é‡‡æ ·çš„å¼€é”€å¾ˆå°</li>
<li>logçš„ä½œç”¨åº”è¯¥æ˜¯æŠŠä¹˜é™¤è½¬æ¢æˆåŠ å‡, eg: $w_i=\frac{p(x_i)}{q(x_i)}, \log w_i=\log p(x_i)-\log q(x_i)$</li>
</ul>
<h4 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h4><p>Hello, I have the same question about the code in line 280 of â€œexamples/train_ngp_nerf_prop.pyâ€.</p>
<p>According to the previous code, the <code>correction</code> and <code>loss_per_pix</code> are respectively:</p>
<script type="math/tex; mode=display">correction = \frac{1}{sg(Q(\mathbf{x}))^{\alpha}}</script><script type="math/tex; mode=display">loss\_per\_pix=\frac{Q(\mathbf{x})^{2}}{sg(Q(\mathbf{x}))^{\alpha}}</script><p>Then the <code>net_grad</code> should be:</p>
<script type="math/tex; mode=display">\begin{align} {netgrad} &= \frac{\partial loss\_per\_pix}{\partial\mathbf{x}} = \frac{2Q(\mathbf{x})}{sg(Q(\mathbf{x}))^{\alpha}} \nabla Q(\mathbf{x}) \\
\end{align}</script><script type="math/tex; mode=display">\begin{align}\nabla\log Q(\mathbf{x}) &= \frac{1}{Q(\mathbf{x})} \nabla Q(\mathbf{x}) \\
&=\frac{1}{Q(\mathbf{x})} \frac{netgrad \cdot sg(Q(\mathbf{x}))^{\alpha}}{2Q(\mathbf{x})}
 \\
&=\frac{netgrad}{2\cdot loss\_per\_pix}\end{align}</script><p>I donâ€™t know why <code>net_grad</code> in the code is need to divide by <code>correction</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net_grad = net_grad / ((grad_scaler._scale * (correction * loss_per_pix).unsqueeze(<span class="number">1</span>))+ torch.finfo(net_grad.dtype).eps)</span><br></pre></td></tr></table></figure>
<p>Maybe my understanding about the partial of <code>loss_per_pix</code> is wrongâ€¦ Could u give me some advice about that, thank u very much.</p>
<h4 id="Other-tricks"><a href="#Other-tricks" class="headerlink" title="Other tricks"></a>Other tricks</h4><p>Sample (re-)initialization.(é‡‡æ ·çš„åˆå§‹åŒ–å¾ˆé‡è¦)ï¼šWe first initialize the sampling distribution to be uniform over the domain of interest as $\mathbf{x}_{0}{\sim}\mathcal{U}(\mathcal{R})$. We further re-initialize samples that either move out of $\mathcal{R}$ or have too low error value causing samples to get â€˜stuckâ€™. We use uniform sampling as well as edge-based sampling for 2D workloads.<br>Warming up soft mining. Start with $\alpha=0$, i.e., no correction, then linearly increase it to the desired $\alpha$ value at 1k iterations.<br>Alternative: multinomial sampling. To use multinomial sampling, one needs to do a forward pass of all data points to build a probability density function, which is computationally expensive. Hence an alternative strategy, such as those based on Markov Chain Monte Carlo (MCMC) is required. ä¸ºäº†é˜²æ­¢å¯¹æ‰€æœ‰åƒç´ ç‚¹è¿›è¡Œå‰å‘è®¡ç®—ä»¥è®¡ç®—PDFçš„é«˜è€—è´¹ï¼Œä½¿ç”¨MCMCé‡‡æ ·</p>
<p>Ablation studiesä¸­: å³ä½¿LMCé‡‡æ ·çš„ç²¾åº¦æ¯”multinomial samplingä½ä¸€ç‚¹ï¼Œä½†ä»ç„¶æ¯”Uniform samplingæ›´é«˜ï¼Œä¸”æ›´effective(æ•ˆç‡ä¸ç²¾åº¦çš„æŠ˜ä¸­(compromise/trade-off))</p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240708102314.png" alt="image.png|666"></p>
<h3 id="Shooting-Much-Fewer-Rays"><a href="#Shooting-Much-Fewer-Rays" class="headerlink" title="Shooting Much Fewer Rays"></a>Shooting Much Fewer Rays</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2208.06821">Fast Learning Radiance Fields by Shooting Much Fewer Rays</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240620160134.png" alt="image.png|888"><br>ä¹‹å‰çš„ä»å›¾ç‰‡ä¸­é‡‡æ ·åƒç´ orå…‰çº¿çš„æ–¹æ³•ï¼š$\mathbf{r}_i(u,v)\sim U(I_i),u\in[0,H_i],v\in[0,W_i],$ æŒ‰å‡åŒ€åˆ†å¸ƒéšæœºé‡‡æ ·</p>
<ul>
<li>trivial areasï¼šå¯¹äºèƒŒæ™¯(å¤§éƒ¨åˆ†é¢œè‰²ç›¸åŒ)ï¼Œè¿™æ ·å›¾ç‰‡çš„åƒç´ å°±æ˜¯éå‡åŒ€çš„åˆ†å¸ƒï¼Œå‡åŒ€é‡‡æ ·æ–¹å¼ä¼šå¯¼è‡´é‡‡æ ·åˆ°ä¸€äº›æ— æ„ä¹‰çš„åƒç´ ã€‚ <strong>Therefore</strong>, we only need to shoot fewer rays in the trivial areas where the color changes slightly to perceive the radiance fields</li>
<li>nontrivial areasï¼šcolor changes greatly contain more information, so more rays are required to capture the detailed information and learn how to distinguish these pixelsâ€™ colors from its neighboring ones</li>
</ul>
<p>trivial areasä¼šå¾ˆå¿«æ”¶æ•›ï¼Œè€Œnontrivial areasä¸å®¹æ˜“æ”¶æ•›<br>Based on the above observation, we propose two strategies to optimize ray distribution on input images. </p>
<ul>
<li>The first one is to calculate a <strong>prior probability distribution based on the image context</strong> GTå›¾ç‰‡çš„å…ˆéªŒåˆ†å¸ƒ</li>
<li>the second one is to apply an <strong>adaptive quadtree subdivision algorithm</strong> to dynamically adjust ray distribution. è‡ªé€‚åº”çš„QSA</li>
</ul>
<p>å…·ä½“åšæ³•ï¼š</p>
<ol>
<li>Context based Probability Distributionï¼šwe use the color variation of pixels relative to their surroundings to quantitatively identify the image context.</li>
</ol>
<p>è®¡ç®—æ¯ä¸ªåƒç´ ç‚¹è·Ÿå‘¨å›´å…«ä¸ªç‚¹çš„stdï¼š$g(u,v)=\operatorname{std}(\mathbf{c}(u,v))=\sqrt{\frac19\sum_{x,y}[\mathbf{c}(x,y)-\overline{\mathbf{c}}]^2},\\x\in\{u-1,u,u+1\},y\in\{v-1,v,v+1\}.$ gè¶Šé«˜è¡¨ç¤ºåƒç´ é¢œè‰²/å¯†åº¦å˜åŒ–è¶Šå‰§çƒˆï¼Œé€šå¸¸åœ¨3Dç‰©ä½“çš„è¡¨é¢è¾¹ç•Œå¤„ã€‚ä¼˜åŠ¿ï¼šour image context based probability distribution function naturally helps to estimate where surfaces are located.<br>ä¸ºäº†å¹³è¡¡$g_{max}$ä¸$g_{min}$ä¹‹é—´çš„å·®å¼‚ï¼Œclampåè¿›è¡Œå½’ä¸€åŒ–ï¼š$g^{\prime}(u,v)=\frac{\mathrm{clamp}(s,\max(g(u,v)))}{\mathrm{max}(g(u,v))}$ï¼Œwe typically define threshold $\begin{aligned}s=0.01\times\text{mean}(g(u,v))\end{aligned}$. Values less than s will be clamped to s to avoid sampling too few rays at the corresponding positions.<br><strong>Sampling strategy</strong>. In the lines of â€œSampled Rays Distributionâ€, we sample 50% rays according to the context based probability distribution and randomly sample the other 50% rays, where each red point represents a sampled ray(<strong>ä¸ºä»€ä¹ˆè¦è®¾ç½®æˆ50%</strong>)</p>
<ol>
<li>Adaptive QuadTree Subdivisionï¼šå¯¹äºrendering errorï¼Œåªåœ¨errorå¤§çš„åœ°æ–¹ç»†åˆ†ï¼Œåœ¨errorå°çš„åœ°æ–¹ä¸åœ¨ç»†åˆ†(æ ¹æ®pre-defined threshold aæ¥åˆ¤æ–­å¤§å°)</li>
</ol>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240620170649.png" alt="image.png|666"><br>å›¾ç‰‡$I_{i}(H_{i} \times W_{i})$ä¸Šæ€»çš„é‡‡æ ·æ•°é‡ï¼š$M_i^l=Q_1^l\times\frac{H_i}{2^l}\times\frac{W_i}{2^l}+Q_2^l\times n_0,$ $l$ denote the times of subdivision, $Q_1^l$ and $Q_2^l$ denote the number of unmarked leaf nodes (error&gt;a) and marked leaf nodes (error&lt;a) separately. $n_{0} = 10(constant)$</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2103.12352">iMAP: Implicit Mapping and Positioning in Real-Time</a></p>
</blockquote>
<p>åŒæ—¶<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2103.12352">iMap</a>ä¹Ÿä½¿ç”¨rendering erroræ¥å¼•å¯¼é‡‡æ ·ï¼Œä¸åŒç‚¹ï¼š</p>
<ul>
<li>The applications of rendering loss are different. iMap uses the rendering loss distribution on image blocks to decide how many points should be sampled on each block, while we use the <strong>rendering loss</strong> on each leaf node to decide whether this node should be subdivided into 4 child nodes.</li>
<li>The number of sampled points and image blocks are different. In our method, the number of sampled points in each leaf node is identical, but the number and area of the image blocks (i.e. leaf nodes) changes during training. In contrast, iMap samples different numbers of rays according to a render loss based distribution in each one of the same size blocks.</li>
<li>The sampling strategies in image blocks are different. In each image block, iMap uniformly samples points for rendering, while we sample points according to the image context. More points are sampled in the nontrivial areas where color changes a lot, while fewer points are sampled in the trivial areas where color changes slightly. Our sampling strategy helps to capture the detailed information in the nontrivial areas and reduce the training burden in the trivial areas.</li>
</ul>
<ol>
<li>Implementation Details</li>
</ol>
<ul>
<li>åœ¨æ¯ä¸ªepochç»“æŸåï¼Œä¹Ÿå°±æ˜¯å¯¹æ•°æ®é›†ä¸­æ‰€æœ‰å›¾åƒçš„åƒç´ éƒ½è¿›è¡Œä¸€æ¬¡renderingï¼Œç„¶åä¸g.t.è¿›è¡Œå¯¹æ¯”å¾—åˆ°rendering error</li>
<li>In practice, we initially subdivide the quadtrees into 2 or 3 depths at the begin of training. This helps our method to distinguish the trivial and nontrivial areas faster among the quadtree leaf nodes</li>
</ul>
<p>å­˜åœ¨çš„é—®é¢˜ï¼š</p>
<ul>
<li>All-Pixel Samplingä¸­ï¼Œä½œè€…ä¸ºäº†é˜²æ­¢MLPå¯¹unmarked leaf nodesè¿›è¡Œæ‹Ÿåˆçš„åŒæ—¶ä¼šæ”¹å˜å·²ç»æ‹Ÿåˆå¥½çš„marked leaf nodesï¼Œåœ¨æ¥è¿‘æœ€åçš„epochï¼Œä½¿ç”¨äº†randomly sample rays from the whole image instead of using quadtrees for sampling, where the number of sampled rays is equal to the total number of pixels. <strong>å¦‚ä½•freezeå·²ç»æ‹Ÿåˆå¥½çš„marked leaf nodes???</strong></li>
</ul>
<h3 id="iNeRF"><a href="#iNeRF" class="headerlink" title="iNeRF"></a>iNeRF</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2012.05877">iNeRF: Inverting Neural Radiance Fields for Pose Estimation</a></p>
</blockquote>
<p>ä¸€ç§åŸºäºNeRFé¢„è®­ç»ƒæ¨¡å‹çš„å§¿æ€ä¼°è®¡çš„æ–¹æ³•. æœ‰äº†NeRF(MLP), å»refineä½å§¿</p>
<ul>
<li>Sampling Rays: è®¡ç®—æ‰€æœ‰pixelæ˜¯éå¸¸è€—æ—¶è€—åŠ›çš„ã€‚ç›®çš„æ˜¯æƒ³è¦é‡‡æ ·çš„ç‚¹å¯ä»¥æ›´å¥½çš„åŒ…å«åœ¨observed imageså’Œrendered imagesä¸Šã€‚ä¸‰ç§ç­–ç•¥ï¼š<ul>
<li>Random Sampling</li>
<li>Interest Point Sampling: employ interest point detectors to localize a set of candidate pixel locations in the observed image, this strategy makes optimization converge faster since less stochasticity is introduced. <strong>But</strong> we found that it is prone to local minima as it only considers interest points on the observed image instead of interest points from both the observed and rendered images.</li>
<li>Interest Region Sampling: After the interest point detector localizes the interest points, we apply a 5 Ã— 5 <strong>morphological dilation</strong> for I iterations to enlarge the sampled region.</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240620151248.png" alt="image.png|666"></p>
<h3 id="Expansive-Supervision"><a href="#Expansive-Supervision" class="headerlink" title="Expansive Supervision"></a>Expansive Supervision</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2409.08056">Expansive Supervision for Neural Radiance Field | PDF</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240928172853.png" alt="image.png|333"></p>
<p>æœ¬æ–‡æ€è·¯ï¼špixels within the same batch must derive from identical input views</p>
<ul>
<li><strong>Strict Sequential order</strong> in imageï¼šthis approach results in a significant decrease in model performance due to the <strong>reduced entropy of the training data</strong> This reduction in entropy negatively impacts the learning performance during each iteration.</li>
<li><strong>Permutation algorithm</strong>(maximizes the entropy) å°†ä»åŒä¸€å¼ å›¾ç‰‡ä¸­é‡‡æ ·å¾—åˆ°çš„batchè¿›è¡Œæ‰“ä¹±é¡ºåºï¼š$P^<em>=\arg\max_PH(P(\mathcal{D}))$ æ‰¾åˆ°ç†µ$H(\cdot)$æœ€å¤§æ—¶çš„ permutation $P^{</em>}$<ul>
<li>$\text{s.t.}C:B\cap I=B,\forall B\in\mathcal{B},\exists I\in I$ ç”¨æ•°å­¦å…¬å¼æè¿° Batch B of Batch set $\mathcal{B}$ ä¸­çš„æ‰€æœ‰åƒç´ åœ¨ image set $\mathcal{I}$ ä¸­çš„å›¾ç‰‡$I$ä¸­ </li>
<li>$\mathcal{D} = g(\mathcal{B}) = g(\mathcal{I})$ å…¶ä¸­ $g(\cdot)$è¡¨ç¤ºreshape function å°†å¤šç»´é›†æ˜ å°„ä¸ºå•ä½é›†å¹¶ä¿å­˜element order: å°†ä»å•ä¸ªå›¾ç‰‡$I$ä¸­æŠ½å–å¾—åˆ°çš„$\mathcal{B}$ ä¸­çš„å¤šä¸ª$B$ å±•æˆä¸€ç»´æ•°æ®ï¼Œæœ€ç»ˆè·å¾—å•ç»´é›†$\mathcal{D}$ï¼Œç„¶åè¿›è¡ŒPæ’åˆ—ï¼Œå¾—åˆ°$P(\mathcal{D})$</li>
<li>æœ€ç»ˆå¾—åˆ°shuffledçš„batch set $\mathcal{B}=P^{*}(\mathcal{D})$ å’Œ the image set $\mathcal{I}$</li>
</ul>
</li>
</ul>
<p><strong>Section 3.2 Content-aware Permutation</strong></p>
<p>$\hat{P}_{\mathrm{intra}}^{I}(B)$è¡¨ç¤ºå¯¹ä»ç›¸åŒçš„è¾“å…¥è§†å›¾ä¸­æŠ½å–çš„ä¸åŒbatchçš„åƒç´ è¿›è¡Œæ’åº<br>$\hat{P}_{\mathrm{inter}}^{\mathcal{B}}(\mathcal{D})$è¡¨ç¤ºå¯¹åŒä¸€ä¸ªbatchçš„åƒç´ è¿›è¡Œæ’åº</p>
<p><strong>Section 3.3 Expansive Supervision</strong></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20240928172804.png" alt="image.png|666"></p>
<ul>
<li>The anchor area are computed by the light-wight edge detector to displays prominent error patterns. è¿™ä¸€åŒºåŸŸä»where patterns exhibit larger errorsè¿›è¡Œé€‰æ‹©</li>
<li>And source area are sampled to expand its values to the reaming area. ğŸ¤”ä¸ºä»€ä¹ˆè¿˜è¦æœ‰sorce areaï¼Œé™¤äº†é‡è¦è¾¹ç¼˜åŒºåŸŸï¼Œè¿˜è€ƒè™‘ä¸€ä¸‹å…¶ä»–åŒºåŸŸï¼ŸIn my opinionï¼š<ul>
<li>The source set is composed of sampled points, and the error is estimated based on these source points, which expand to cover all remaining areasã€‚<strong>é€šè¿‡é‡‡æ ·ä¸€äº›é™¤äº†anchor setä¹‹å¤–çš„åƒç´ ï¼Œç”¨è¿™äº›åƒç´ çš„erroræ¥ä»£è¡¨å…¶ä»–åœ°æ–¹çš„errorï¼Œä»è€Œä¸éœ€è¦è®¡ç®—æ‰€æœ‰åƒç´ çš„errorï¼ŒèŠ‚çœäº†æ—¶é—´</strong></li>
</ul>
</li>
</ul>
<p>æœ€ç»ˆçš„æŸå¤±ï¼š</p>
<script type="math/tex; mode=display">\begin{aligned}
\hat{L}=& \frac1{|A^*|}\sum_{r_A\in A^*}||\hat{C}(r_A)-C(r_A)||_2^2+ \\
&\frac{1}{|S|}(\frac{1}{\beta_{A}+\beta_{S}}-1)\sum_{r_{S}\in S}||\hat{C}(r_{S})-C(r_{S})||_{2}^{2},
\end{aligned}</script><ul>
<li>$\beta_{A}$å’Œ$\beta_{S}$åˆ†åˆ«ç”¨æ¥æ§åˆ¶anchor area å’Œ source areaçš„å¤§å°</li>
</ul>
<h1 id="Uncertainty"><a href="#Uncertainty" class="headerlink" title="Uncertainty"></a>Uncertainty</h1><p>Basic Paper:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Year</th>
<th>Paper</th>
</tr>
</thead>
<tbody>
<tr>
<td>2021</td>
<td>A review of uncertainty quantification in deep learning: Techniques, applications and challenges</td>
</tr>
<tr>
<td>2021</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2110.12122v1">Quantifying Epistemic Uncertainty in Deep Learning</a></td>
</tr>
<tr>
<td>2021</td>
<td><a target="_blank" rel="noopener" href="https://link.springer.com/article/10.1007/s10994-021-05946-3">Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods</a></td>
</tr>
<tr>
<td>2022</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2107.03342#page=21.35">A Survey of Uncertainty in Deep Neural Networks</a></td>
</tr>
</tbody>
</table>
</div>
<p>ä¸‰ç»´æ¨¡å‹ä¸ç¡®å®šæ€§ï¼š</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_50910915/article/details/134133658">ã€è®ºæ–‡é˜…è¯»ã€‘ä½¿ç”¨ç¥ç»å½¢çŠ¶å…ˆéªŒçš„å¤šè§†å›¾ä¸‰ç»´é‡å»ºå’Œä¸ç¡®å®šæ€§å»ºæ¨¡-CSDNåšå®¢</a></li>
</ul>
<h2 id="Sources-of-Uncertainty"><a href="#Sources-of-Uncertainty" class="headerlink" title="Sources of Uncertainty"></a>Sources of Uncertainty</h2><p><a href="Sources%20of%20Uncertainty%20in%203D%20Scene%20Reconstruction.md">Sources of Uncertainty in 3D Scene Reconstruction</a></p>
<ul>
<li>ç¯å¢ƒå…‰ç…§æ˜¯å¦å¯ä»¥é€šè¿‡ä¸ç¡®å®šæ€§è¿›è¡Œé‡åŒ–</li>
<li>ä¸åŒçš„cuda/æ˜¾å¡ç¯å¢ƒæ˜¯å¦ä¹Ÿæ˜¯ä¸ç¡®å®šæ€§</li>
</ul>
<h2 id="Related-Paper"><a href="#Related-Paper" class="headerlink" title="Related Paper"></a>Related Paper</h2><p>è¯„ä»·æŒ‡æ ‡ï¼šNLLï¼Œè¯„ä»·åƒç´ çœŸå®å€¼åœ¨é«˜æ–¯åˆ†å¸ƒä¸‹çš„è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼Œè¶Šå°è¶Šå¥½</p>
<p>Reference:</p>
<blockquote>
<p> <a target="_blank" rel="noopener" href="https://blog.csdn.net/Rad1ant_up/article/details/139115011">ç¥ç»ç½‘ç»œä¸ç¡®å®šæ€§ç»¼è¿°(Part II)â€”â€”Uncertainty estimation_Single deterministic methods-CSDNåšå®¢</a><br><a target="_blank" rel="noopener" href="https://www.cnblogs.com/dengshunge/p/13436808.html">ä¸ç¡®å®šä¼°è®¡å­¦ä¹ å°ç»“ - å•Šé¡º - åšå®¢å›­</a><br><a target="_blank" rel="noopener" href="https://whuxgxj.github.io/article/ensemble-learning-in-classification.html">é›†æˆå­¦ä¹ (Ensemble learning)ç›¸å…³ç†è®º | ççˆæ‘ä¸‹å±±</a></p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th>Year</th>
<th>Paper</th>
<th>ç ”ç©¶å¯¹è±¡</th>
<th>ç ”ç©¶å†…å®¹</th>
<th>ç ”ç©¶æ–¹æ³•</th>
<th>Important for me</th>
</tr>
</thead>
<tbody>
<tr>
<td>2024<br>â­</td>
<td>[Sources of Uncertainty in 3D Scene Reconstruction \</td>
<td>PDF](<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2409.06407">https://arxiv.org/pdf/2409.06407</a>)</td>
<td>NeRF and 3DGS</td>
<td>Sources of Uncertainty</td>
<td>reviewå½“å‰çš„å¤šç§æ–¹æ³•(Active-NeRF/GSã€MC-Dropout NeRFã€Laplace NeRFã€Ensemble NeRF/GS)</td>
<td>åˆ†ç±»ä¸ç¡®å®šæ€§(aleatoryã€epistemic)<br>Ensemble NeRF</td>
</tr>
<tr>
<td>2022</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2209.08718">Density-aware NeRF Ensembles: Quantifying Predictive Uncertainty in Neural Radiance Fields</a></td>
<td>NeRF</td>
<td>Quantifying Predictive Uncertainty</td>
<td>Density-aware NeRF Ensembles</td>
<td>ç®€å•åœ°ensembleæ— æ³•æ•æ‰æœªè§åŒºåŸŸçš„ä¸ç¡®å®šæ€§ã€‚æœ¬æ–‡è®¡ç®—RGBçš„$\sigma$æ—¶é™¤äº†ç®€å•çš„å¤šensembleè®¡ç®—å¤–ï¼Œè¿˜æ·»åŠ äº†å¯†åº¦æ„ŸçŸ¥çš„$\sigma_{\mathrm{epi}}^2(\mathbf{r})=\left(1-\bar{q}(\mathbf{r})\right)^2$ï¼Œ$\bar{q}(\mathbf{r})$æ˜¯å¤šä¸ªensembleçš„æ²¿å…‰çº¿ç´¯ç§¯æƒé‡çš„å‡å€¼ã€‚ç›´æ¥ä¼°è®¡åƒç´ é¢œè‰²çš„ä¸ç¡®å®šæ€§</td>
</tr>
<tr>
<td>2023 â­</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.14664">Density Uncertainty Quantification with NeRF-Ensembles: Impact of Data and Scene Constraints</a></td>
<td>NeRF</td>
<td>Density Uncertainty Quantification</td>
<td>Density Ensembles<br>![image.png\</td>
<td>333](<a target="_blank" rel="noopener" href="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20250305104136.png">https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20250305104136.png</a>)</td>
<td>å¯¹ç©ºé—´ç‚¹å¯†åº¦è¿›è¡Œä¸ç¡®å®šæ€§å»ºæ¨¡ä¼°è®¡<br>å¹¶æ¢ç©¶äº†å›¾ç‰‡å™ªå£°å’Œç›¸æœºå™ªå£°å¯¹ä¸ç¡®å®šæ€§å¯†åº¦çš„å½±å“</td>
</tr>
<tr>
<td>2021</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2109.02123">Stochastic Neural Radiance Fields: Quantifying Uncertainty in Implicit 3D Representations</a></td>
<td>Stochastic Neural Radiance Fields</td>
<td>Quantifying Uncertainty in Implicit 3D Representations</td>
<td>![image.png\</td>
<td>333](<a target="_blank" rel="noopener" href="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20250304204422.png">https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20250304204422.png</a>)</td>
<td>does not guarantee accurate estimations due to the approximation of the probability distribution. MLPç½‘ç»œä¼°è®¡åˆ†å¸ƒå‚æ•°ï¼Œè€Œä¸æ˜¯å…·ä½“çš„å€¼<br>å°†ç½‘ç»œå‚æ•°å»ºæ¨¡ä¸ºåˆ†å¸ƒï¼Œå¹¶ä¼°è®¡å‡ºçš„å¯†åº¦å’Œé¢œè‰²ä¹Ÿæ˜¯ä¸€ä¸ªæœªçŸ¥çš„åˆ†å¸ƒ</td>
</tr>
<tr>
<td>2024</td>
<td><a target="_blank" rel="noopener" href="https://actnerf.github.io/">ActNeRF</a></td>
<td>Robot Manipulators</td>
<td>Uncertainty-aware Active Learning of NeRF-based Object Models</td>
<td>Visual and Re-orientation Actions<br>![overview.png (1378Ã—1122)\</td>
<td>333](<a target="_blank" rel="noopener" href="https://actnerf.github.io/static/images/overview.png">https://actnerf.github.io/static/images/overview.png</a>)</td>
<td>å…è®¸æœºå™¨äººåœ¨æ”¶é›†è§†è§‰è§‚å¯Ÿç»“æœçš„åŒæ—¶é‡æ–°å®šå‘ç‰©ä½“</td>
</tr>
<tr>
<td>2022</td>
<td><a href="ActiveNeRF.md">ActiveNeRF: Learning where to See with Uncertainty Estimation</a></td>
<td>NeRF</td>
<td>model a 3D scene with a constrained input budget<br>ensures robustness under few observations and provides an interpretation of how NeRF understands the scene</td>
<td>![image.png\</td>
<td>333](<a target="_blank" rel="noopener" href="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20250313140313.png">https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20250313140313.png</a>)</td>
<td>å°†é¢œè‰²å€¼å»ºæ¨¡ä¸ºé«˜æ–¯åˆ†å¸ƒï¼Œå¹¶ä¸”é¢œè‰²çš„ä¸ç¡®å®šæ€§é€šè¿‡å¦å¤–çš„ç½‘ç»œè¿›è¡Œé¢„æµ‹<br>å€ŸåŠ©äºä¸»åŠ¨å­¦ä¹ çš„æ–¹æ³•ï¼Œä¸æ–­è¡¥å……ç°åœ¨çš„è®­ç»ƒæ•°æ®<br>åœ¨ç»™å®šå‡è®¾çš„æ–°è¾“å…¥åï¼Œé€šè¿‡è´å¶æ–¯ä¼°è®¡åˆ†ææ•´ä¸ªåœºæ™¯çš„åéªŒåˆ†å¸ƒ(è®¡ç®—é‡ä½)</td>
</tr>
<tr>
<td>2024</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2408.06592">ActiveNeRF: Learning Accurate 3D Geometry by Active Pattern Projection</a></td>
<td>NeRF</td>
<td></td>
<td>![image.png\</td>
<td>333](<a target="_blank" rel="noopener" href="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20250313143136.png">https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20250313143136.png</a>)</td>
<td>åº”è¯¥æ˜¯å€Ÿé‰´äº†ç»“æ„å…‰é‡å»ºæ—¶çš„ä¸»åŠ¨å‘å°„å…‰æ …æ–¹æ³•</td>
</tr>
<tr>
<td>2024 version1</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.02568">[2405.02568] ActiveNeuS: Active 3D Reconstruction using Neural Implicit Surface Uncertainty</a></td>
<td>3D scene reconstruction</td>
<td>Active view selection</td>
<td>![image.png\</td>
<td>222](<a target="_blank" rel="noopener" href="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20250304204610.png">https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20250304204610.png</a>)</td>
<td>å›¾åƒæ¸²æŸ“æˆ–å‡ ä½•ä¸ç¡®å®šæ€§<br>åˆ©ç”¨ä¸åŒç±»å‹çš„ä¸ç¡®å®šæ€§å¯ä»¥å‡å°‘åœ¨æ—©æœŸè®­ç»ƒé˜¶æ®µå› è¾“å…¥ç¨€ç–è€Œå‡ºç°çš„åå·®</td>
</tr>
<tr>
<td>2024 version2</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2405.02568">Active Neural 3D Reconstruction with Colorized Surface Voxel-based View Selection</a></td>
<td>3D scene reconstruction</td>
<td>Active view selection</td>
<td>![image.png\</td>
<td>333](<a target="_blank" rel="noopener" href="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20250313141201.png">https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20250313141201.png</a>)</td>
<td>å°†3Dç‚¹çš„é¢œè‰²å»ºæ¨¡ä¸ºé«˜æ–¯åˆ†å¸ƒ<br>é€šè¿‡é¢œè‰²çš„ä¸ç¡®å®šæ€§è®¡ç®—æ–°è§†è§’çš„IG(Information gain)ï¼Œä¸ç¡®å®šæ€§è¶Šå¤§ï¼ŒIGè¶Šå¤§ã€‚<br>ç›¸å½“äºæ˜¯ç©ºé—´æ¢æ—¶é—´äº†ï¼Œå¦‚æœä¸ç”¨CSVï¼Œåˆ™æ¯æ¬¡è®¡ç®—æ–°è§†å›¾çš„ä¸ç¡®å®šæ€§å›¾ç‰‡æ—¶éœ€è¦è®¡ç®—æ•´ä¸ªè¿ç»­ç©ºé—´åœº</td>
</tr>
<tr>
<td>2024</td>
<td><a target="_blank" rel="noopener" href="https://bayesrays.github.io/">Bayesâ€™ Rays</a></td>
<td>NeRF</td>
<td>BaysRays</td>
<td>Uncertainty Quantification</td>
<td>Bayes, åæ ‡perturbation</td>
</tr>
<tr>
<td>2024â­</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06727">[2404.06727] Bayesian NeRF: Quantifying Uncertainty with Volume Density in Neural Radiance Fields</a></td>
<td>Volume Density in Neural Radiance Fields</td>
<td>quantifying uncertainty based on the geometric structure</td>
<td>Bayesian</td>
<td>å‡ ä½•ä½“ç§¯ç»“æ„ä¸­çš„ä¸ç¡®å®šæ€§ï¼Œä¸ä»…RGBï¼Œè¿˜æœ‰æ·±åº¦ã€‚åŒæ—¶å¯¹ç©ºé—´ç‚¹çš„å¯†åº¦å’Œé¢œè‰²å»ºæ¨¡ä¸ç¡®å®šæ€§</td>
</tr>
<tr>
<td>2024</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.08154">Bayesian uncertainty analysis for underwater 3D reconstruction with neural radiance fields</a></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2024</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.01400">[2404.01400] NVINS: Robust Visual Inertial Navigation Fused with NeRF-augmented Camera Pose Regressor and Uncertainty Quantification</a></td>
<td>real-time and robust robotic tasks(æœºå™¨äººå®æ—¶å¯¼èˆª)</td>
<td>NeRF-augmented Camera Pose Regressor and Uncertainty Quantification</td>
<td>Fused</td>
<td></td>
</tr>
<tr>
<td>2024</td>
<td><a target="_blank" rel="noopener" href="https://sites.google.com/view/nvf-cvpr24/">Neural Visibility Field for Uncertainty-Driven Active Mapping</a></td>
<td></td>
<td></td>
<td></td>
<td>NVF è‡ªç„¶ä¼šä¸ºæœªè§‚å¯ŸåŒºåŸŸåˆ†é…æ›´é«˜çš„ä¸ç¡®å®šæ€§ï¼Œå¸®åŠ©æœºå™¨äººé€‰æ‹©æœ€å…·ä¿¡æ¯é‡çš„ä¸‹ä¸€ä¸ªè§†ç‚¹</td>
</tr>
<tr>
<td>2024</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.18476">[2403.18476] Modeling uncertainty for Gaussian Splatting</a></td>
<td>Gaussian Splatting</td>
<td>Modeling uncertainty</td>
<td>Variational Inference-based approach +  Area Under Sparsification Error (AUSE)</td>
<td>åœ¨<strong>å›¾åƒæ¸²æŸ“è´¨é‡</strong>å’Œä¸ç¡®å®šæ€§ä¼°è®¡ç²¾åº¦æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ–¹æ³•</td>
</tr>
<tr>
<td>2024</td>
<td><a target="_blank" rel="noopener" href="https://jiangwenpl.github.io/FisherRF/">FisherRF: Active View Selection and Uncertainty Quantification for Radiance Fields using Fisher Information</a></td>
<td>NeRF</td>
<td></td>
<td>computes the Fisher Information</td>
</tr>
</tbody>
</table>
</div>
<p>NeRFä¸­çš„ä¸ç¡®å®šæ€§é‡åŒ–æ–¹æ³•ï¼š</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Method</th>
<th>Description</th>
<th>Belong to</th>
</tr>
</thead>
<tbody>
<tr>
<td>Active Learning</td>
<td>MLP è¾“å‡ºé™¤äº†å•é¢œè‰²$\bar{c}$ä¹‹å¤–ï¼Œè¿˜ä¼šè¾“å‡ºé¢œè‰²çš„ä¸ç¡®å®šæ€§$\beta$ï¼Œç„¶åé€šè¿‡ç©ºé—´ç‚¹é¢œè‰²çš„åˆ†å¸ƒ(æœ‰çš„æ˜¯å¯†åº¦çš„åˆ†å¸ƒ)è¿›è¡Œä½“æ¸²æŸ“ï¼Œå¾—åˆ°åƒç´ é¢œè‰²çš„åˆ†å¸ƒ</td>
<td>Single Deterministic Methods</td>
</tr>
<tr>
<td>MC-Dropout</td>
<td>è®­ç»ƒä¸€æ¬¡MLPåï¼Œä½¿ç”¨Mæ¬¡ä¸åŒçš„Dropout(ä¸åŒçš„ç½‘ç»œå‚æ•° set)è¿›è¡Œæ¨ç†ï¼Œå¾—åˆ°ç©ºé—´ç‚¹é¢œè‰²çš„åˆ†å¸ƒï¼Œè¿›è€Œå¾—åˆ°Mä¸ªä¸åŒçš„åƒç´ é¢œè‰²</td>
<td>Bayesian Neural Networks</td>
</tr>
<tr>
<td>Laplace</td>
<td>é€šè¿‡BNNè®­ç»ƒï¼Œå¾—åˆ°ç½‘ç»œå‚æ•°åœ¨æ•°æ®é›†ä¸‹çš„æ¡ä»¶åˆ†å¸ƒï¼Œè¢«è¿‘ä¼¼ä¸ºé«˜æ–¯åˆ†å¸ƒï¼Œå‡å€¼ä¸ºlogåéªŒåˆ†å¸ƒæœ€å¤§å€¼å¯¹åº”çš„å‚æ•°ï¼Œæ–¹å·®ä¸ºéå½’ä¸€åŒ–logåéªŒçš„Hessian matrixï¼Œé€šè¿‡ä»è¿‘ä¼¼åéªŒåˆ†å¸ƒä¸­è¿›è¡Œé‡‡æ ·(MC)ï¼Œç„¶åä½¿ç”¨å¾—åˆ°çš„å‚æ•°è®¡ç®—ç©ºé—´ç‚¹é¢œè‰²å‡å€¼å’Œæ–¹å·®ï¼Œæœ€åå¾—åˆ°åƒç´ é¢œè‰²çš„å‡å€¼å’Œæ–¹å·®</td>
<td>Bayesian Neural Networks</td>
</tr>
<tr>
<td>Ensemble</td>
<td>ä»ä¸åŒçš„åˆå§‹åŒ–æƒé‡å¼€å§‹ï¼Œè®­ç»ƒMä¸ªä¸åŒçš„ç½‘ç»œï¼Œå¾—åˆ°Mä¸ªä¸åŒçš„ç½‘ç»œå‚æ•°ã€‚å¯¹äºç©ºé—´ç‚¹ï¼Œå¯ä»¥è®¡ç®—å‡ºMä¸ªä¸åŒçš„å¯†åº¦å€¼å’Œé¢œè‰²å€¼ï¼Œè¿›è€Œå¾—åˆ°Mä¸ªä¸åŒçš„åƒç´ é¢œè‰²</td>
<td>Ensemble Methods</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p> <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/81170602">Bayesian Neural Networksï¼šè´å¶æ–¯ç¥ç»ç½‘ç»œ - çŸ¥ä¹</a><br> <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41990294/article/details/144643398">è´å¶æ–¯ç¥ç»ç½‘ç»œï¼ˆBayesian Neural Networkï¼‰-CSDNåšå®¢</a><br> <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_49030008/article/details/120208994">Monte-Carlo Dropoutï¼ˆè’™ç‰¹å¡ç½— dropoutï¼‰ï¼ŒAleatoric Uncertaintyï¼ŒEpistemic Uncertainty_monte carlo dropout-CSDNåšå®¢</a><br> <a target="_blank" rel="noopener" href="https://whuxgxj.github.io/article/ensemble-learning-in-classification.html">é›†æˆå­¦ä¹ (Ensemble learning)ç›¸å…³ç†è®º | ççˆæ‘ä¸‹å±±</a></p>
</blockquote>
<p>æ·±åº¦å­¦ä¹ ä¸­çš„ä¸ç¡®å®šæ€§é‡åŒ–/ä¼°è®¡(estimation)æ–¹æ³•</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Method</th>
<th>Classification</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Single Deterministic Methods</td>
<td>1ï¼‰ Internal Uncertainty Quantification Approaches. 2) External Uncertainty Quantification Approaches</td>
<td></td>
</tr>
<tr>
<td>Bayesian Neural Networks</td>
<td>Variational inference \</td>
<td>Sampling approaches \</td>
<td>Laplace approximation</td>
<td>å°†ä¸ç¡®å®šæ€§ä½œä¸ºåéªŒåˆ†å¸ƒè¿›è¡Œæµ‹é‡</td>
</tr>
<tr>
<td>Ensemble Methods</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Test Time Augmentation</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/MyBlogPic/202403/20250313134457.png" alt="image.png|666"></p>

    </div>

    
    
    
        

  <div class="followme">
    <p>Welcome to my other publishing channels</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="https://t.me/+1ZnNxFWnEbk5YzRl">
            <span class="icon">
              <i class="fab fa-telegram"></i>
            </span>

            <span class="label">Telegram</span>
          </a>
        </div>
    </div>
  </div>


      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/Learn/Finite%20Element/Learn-FEA/" rel="prev" title="Finite Element Learning Note">
      <i class="fa fa-chevron-left"></i> Finite Element Learning Note
    </a></div>
      <div class="post-nav-item">
    <a href="/Learn/Neural%20Network/Loss%20Functions/" rel="next" title="Loss Functions">
      Loss Functions <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Accuracy"><span class="nav-text">Accuracy</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Camera-Pose-Estimation"><span class="nav-text">Camera Pose Estimation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3D-Point-Sampling"><span class="nav-text">3D Point Sampling</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#NerfAcc"><span class="nav-text">NerfAcc</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Loss-Function"><span class="nav-text">Loss Function</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#S3IM"><span class="nav-text">S3IM</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Volume-Rendering-SDF2Density"><span class="nav-text">Volume Rendering (SDF2Density)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#VolSDF"><span class="nav-text">VolSDF</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NeuS"><span class="nav-text">NeuS</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TUVR"><span class="nav-text">TUVR</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NeuRodin"><span class="nav-text">NeuRodin</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ReTR"><span class="nav-text">ReTR</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Mixture-of-Experts-MoE"><span class="nav-text">Mixture of Experts (MoE)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Boost-Your-NeRF"><span class="nav-text">Boost Your NeRF</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Efficiency"><span class="nav-text">Efficiency</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Explicit-Grids"><span class="nav-text">Explicit Grids</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#NGP-RT"><span class="nav-text">NGP-RT</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MIMO-MLP"><span class="nav-text">MIMO MLP</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#MIMO-NeRF"><span class="nav-text">MIMO-NeRF</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Points-Sampling"><span class="nav-text">Points Sampling</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#HashPoint"><span class="nav-text">HashPoint</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Pixel-Sampling"><span class="nav-text">Pixel Sampling</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Uniform-sampling"><span class="nav-text">Uniform sampling</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LMC-sampling"><span class="nav-text">LMC sampling</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Soft-Mining"><span class="nav-text">Soft Mining</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Question"><span class="nav-text">Question</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Other-tricks"><span class="nav-text">Other tricks</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Shooting-Much-Fewer-Rays"><span class="nav-text">Shooting Much Fewer Rays</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#iNeRF"><span class="nav-text">iNeRF</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Expansive-Supervision"><span class="nav-text">Expansive Supervision</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Uncertainty"><span class="nav-text">Uncertainty</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Sources-of-Uncertainty"><span class="nav-text">Sources of Uncertainty</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Related-Paper"><span class="nav-text">Related Paper</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Qi Yun"
      src="/images/avatar.jpeg">
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">162</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">59</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/qiyun71" title="GitHub â†’ https:&#x2F;&#x2F;github.com&#x2F;qiyun71" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://space.bilibili.com/29010355" title="Bilibili â†’ https:&#x2F;&#x2F;space.bilibili.com&#x2F;29010355" rel="noopener" target="_blank"><i class="fa fa-star fa-fw"></i>Bilibili</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2020 â€“ 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Qi Yun</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="Symbols count total">529k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">32:05</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/yqq/anime.min.js"></script>
  <script src="/yqq/velocity/velocity.min.js"></script>
  <script src="/yqq/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="//cdn.jsdelivr.net/gh/theme-next/theme-next-three@1/three.min.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
