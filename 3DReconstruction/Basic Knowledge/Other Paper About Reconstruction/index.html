<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/blog.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/blog.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/yqq/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":true},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Awesome Human Body Reconstruction  Depth&amp;Normal Estimation(2K2K) Implicit Function(PIFu or NeRF)      Method 泛化 数据集监督 提取 mesh 方式 获得纹理方式     2k2k 比较好 (mesh+texture:)depth、normal、mask、rgb 高质量深度图 —&amp;g">
<meta property="og:type" content="article">
<meta property="og:title" content="Other Paper About Reconstruction">
<meta property="og:url" content="http://example.com/3DReconstruction/Basic%20Knowledge/Other%20Paper%20About%20Reconstruction/index.html">
<meta property="og:site_name" content="QiYun">
<meta property="og:description" content="Awesome Human Body Reconstruction  Depth&amp;Normal Estimation(2K2K) Implicit Function(PIFu or NeRF)      Method 泛化 数据集监督 提取 mesh 方式 获得纹理方式     2k2k 比较好 (mesh+texture:)depth、normal、mask、rgb 高质量深度图 —&amp;g">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/9x9.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231205152551.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231023163503.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231109094904.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230925133140.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230927202731.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/15fcd4e5b38213b428a4fe32a140bf88_.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231023164638.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231024094322.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231117150239.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231116154921.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231113155552.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231107153921.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231116155214.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231123143210.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20240104173205.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231204133746.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231205153011.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20240104172512.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231110163602.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008104907.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008105237.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231002104131.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231002104310.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231002104340.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008173458.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008172759.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008193531.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230930153949.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230930154048.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231218201652.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231205153138.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230921171140.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231013171508.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231001165622.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231001170255.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231001172828.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231023154027.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231117103528.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008115305.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008120011.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231123142658.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230928170950.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230928175323.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008194000.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008114221.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008113348.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008163003.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008174219.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231016094412.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231023160121.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231123151648.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231123151707.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231218204004.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230930182135.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230930162915.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230930173026.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230921160120.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231002110228.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231031172920.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231116153515.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231116153659.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231218200234.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231223172838.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231102112309.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008110803.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008164813.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20240122172842.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231218201501.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231205153845.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/picturesmethod.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231121121931.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231114093649.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230921173632.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231031181210.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231110155612.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231116153203.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231116153353.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008160354.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008114841.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008160659.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231017182026.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231101153147.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231108222654.png">
<meta property="article:published_time" content="2023-09-21T08:00:14.000Z">
<meta property="article:modified_time" content="2024-02-26T03:51:07.883Z">
<meta property="article:author" content="Qi Yun">
<meta property="article:tag" content="3DReconstruction">
<meta property="article:tag" content="SurfaceReconstruction">
<meta property="article:tag" content="NeRF">
<meta property="article:tag" content="MVS">
<meta property="article:tag" content="PIFu">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/9x9.jpg">

<link rel="canonical" href="http://example.com/3DReconstruction/Basic%20Knowledge/Other%20Paper%20About%20Reconstruction/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Other Paper About Reconstruction | QiYun</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">QiYun</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Note</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/3DReconstruction/Basic%20Knowledge/Other%20Paper%20About%20Reconstruction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpeg">
      <meta itemprop="name" content="Qi Yun">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="QiYun">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Other Paper About Reconstruction
        </h1>

        <div class="post-meta">
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-09-21 16:00:14" itemprop="dateCreated datePublished" datetime="2023-09-21T16:00:14+08:00">2023-09-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-02-26 11:51:07" itemprop="dateModified" datetime="2024-02-26T11:51:07+08:00">2024-02-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/3DReconstruction-Basic-Knowledge/" itemprop="url" rel="index"><span itemprop="name">3DReconstruction/Basic Knowledge</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>2k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>7 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Awesome Human Body Reconstruction</p>
<ol>
<li><strong>Depth&amp;Normal Estimation</strong>(2K2K)</li>
<li><strong>Implicit Function</strong>(PIFu or NeRF)</li>
</ol>
<div class="table-container">
<table>
<thead>
<tr>
<th>Method</th>
<th>泛化</th>
<th>数据集监督</th>
<th>提取 mesh 方式</th>
<th>获得纹理方式</th>
</tr>
</thead>
<tbody>
<tr>
<td>2k2k</td>
<td>比较好</td>
<td>(mesh+texture:)depth、normal、mask、rgb</td>
<td>高质量深度图 —&gt; 点云 —&gt; mesh</td>
<td>图片 rgb 贴图</td>
</tr>
<tr>
<td>PIFu</td>
<td>比较好</td>
<td>点云(obj)、rgb(uv)、mask、camera</td>
<td>占用场 —&gt; MC —&gt; 点云,mesh</td>
<td>表面颜色场</td>
</tr>
<tr>
<td>NeRF</td>
<td>差</td>
<td>rgb、camera</td>
<td>密度场 —&gt; MC —&gt; 点云,mesh</td>
<td>体积颜色场</td>
</tr>
<tr>
<td>NeuS</td>
<td>差</td>
<td>rgb、camera</td>
<td>SDF —&gt; MC —&gt; 点云,mesh</td>
<td>体积颜色场</td>
</tr>
<tr>
<td>ICON</td>
<td>非常好</td>
<td>rgb+mask、SMPL、法向量估计器 DR</td>
<td>占用场 —&gt; MC —&gt; 点云,mesh</td>
<td>图片 rgb 贴图</td>
</tr>
<tr>
<td>ECON</td>
<td>非常好</td>
<td>rgb+mask、SMPL、法向量估计器 DR</td>
<td>d-BiNI + SC(shape completion)</td>
<td>图片 rgb 贴图</td>
</tr>
</tbody>
</table>
</div>
<span id="more"></span>
<h1 id="NeRF-Object-Reconstruction"><a href="#NeRF-Object-Reconstruction" class="headerlink" title="NeRF Object Reconstruction"></a>NeRF Object Reconstruction</h1><p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/9x9.jpg" alt="9x9.jpg|666"></p>
<h2 id="Binary-Opacity-Grids"><a href="#Binary-Opacity-Grids" class="headerlink" title="Binary Opacity Grids"></a>Binary Opacity Grids</h2><p>Binary Opacity Grids: Capturing Fine Geometric Detail for Mesh-Based View Synthesis<br><a target="_blank" rel="noopener" href="https://binary-opacity-grid.github.io/">https://binary-opacity-grid.github.io/</a></p>
<p>推进BakedSDF的工作，</p>
<h2 id="RNb-NeuS"><a href="#RNb-NeuS" class="headerlink" title="RNb-NeuS"></a>RNb-NeuS</h2><p><a target="_blank" rel="noopener" href="https://github.com/bbrument/RNb-NeuS">bbrument/RNb-NeuS: Code release for RNb-NeuS. (github.com)</a></p>
<p>将<strong>反射率</strong>和<strong>法线贴图</strong>无缝集成为基于神经体积渲染的 3D 重建中的输入数据<br>考虑高光和阴影：显著改善了高曲率或低可见度区域的详细 3D 重建<br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231205152551.png" alt="image.png|666"></p>
<h2 id="Voxurf"><a href="#Voxurf" class="headerlink" title="Voxurf"></a>Voxurf</h2><p><a target="_blank" rel="noopener" href="https://github.com/wutong16/Voxurf">wutong16/Voxurf: [ ICLR 2023 Spotlight ] Pytorch implementation for “Voxurf: Voxel-based Efficient and Accurate Neural Surface Reconstruction” (github.Com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231023163503.png" alt="image.png|666"></p>
<h2 id="ReTR"><a href="#ReTR" class="headerlink" title="ReTR"></a>ReTR</h2><p><a target="_blank" rel="noopener" href="https://yixunliang.github.io/ReTR/">Rethinking Rendering in Generalizable Neural Surface Reconstruction: A Learning-based Solution (yixunliang.github.io)</a><br>修改论文 title：ReTR: Modeling Rendering via Transformer for Generalizable Neural Surface Reconstruction</p>
<p>CNN + 3D Decoder + Transformer + NeRF 用深度图监督</p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231109094904.png" alt="image.png|666"></p>
<h2 id="NISR"><a href="#NISR" class="headerlink" title="NISR"></a>NISR</h2><blockquote>
<p><a href="NISR.md">Improving Neural Indoor Surface Reconstruction with Mask-Guided Adaptive Consistency Constraints</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230925133140.png" alt="image.png|666"></p>
<h2 id="D-NeuS"><a href="#D-NeuS" class="headerlink" title="D-NeuS"></a>D-NeuS</h2><blockquote>
<p><a href="D-NeuS.md">Recovering Fine Details for Neural Implicit Surface Reconstruction</a><br><a target="_blank" rel="noopener" href="https://github.com/fraunhoferhhi/D-NeuS">fraunhoferhhi/D-NeuS: Recovering Fine Details for Neural Implicit Surface Reconstruction (WACV2023) (github.com)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230927202731.png" alt="image.png|666"></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/15fcd4e5b38213b428a4fe32a140bf88_.jpg" alt="15fcd4e5b38213b428a4fe32a140bf88_.jpg|333"></p>
<h2 id="AutoRecon"><a href="#AutoRecon" class="headerlink" title="AutoRecon"></a>AutoRecon</h2><p><a target="_blank" rel="noopener" href="https://zju3dv.github.io/autorecon/">AutoRecon: Automated 3D Object Discovery and Reconstruction (zju3dv.github.io)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231023164638.png" alt="image.png|666"></p>
<h2 id="G-Shell"><a href="#G-Shell" class="headerlink" title="G-Shell"></a>G-Shell</h2><p>重建水密物体+衣服等非水密物体——通用<br><a target="_blank" rel="noopener" href="https://gshell3d.github.io/">G-Shell (gshell3d.github.io)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231024094322.png" alt="image.png|666"></p>
<h2 id="Adaptive-Shells"><a href="#Adaptive-Shells" class="headerlink" title="Adaptive Shells"></a>Adaptive Shells</h2><p><a target="_blank" rel="noopener" href="https://research.nvidia.com/labs/toronto-ai/adaptive-shells/">Adaptive Shells for Efficient Neural Radiance Field Rendering (nvidia.com)</a></p>
<p>自适应使用基于体积的渲染和基于表面的渲染<br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231117150239.png" alt="image.png|666"></p>
<h2 id="DynamicSurf"><a href="#DynamicSurf" class="headerlink" title="DynamicSurf"></a>DynamicSurf</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.08159">DynamicSurf: Dynamic Neural RGB-D Surface Reconstruction with an Optimizable Feature Grid</a></p>
<p>单目 RGBD 视频重建 3D</p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231116154921.png" alt="image.png|666"></p>
<h2 id="RayDF"><a href="#RayDF" class="headerlink" title="RayDF"></a>RayDF</h2><p><a target="_blank" rel="noopener" href="https://vlar-group.github.io/RayDF.html">RayDF: Neural Ray-surface Distance Fields with Multi-view Consistency (vlar-group.github.io)</a><br><a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=2037229054391691776&amp;noteId=2047746094923644416">RayDF: Neural Ray-surface Distance Fields with Multi-view Consistency (readpaper.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231113155552.png" alt="image.png|666"></p>
<h2 id="PonderV2"><a href="#PonderV2" class="headerlink" title="PonderV2"></a>PonderV2</h2><p><a target="_blank" rel="noopener" href="https://github.com/OpenGVLab/PonderV2">OpenGVLab/PonderV2: PonderV2: Pave the Way for 3D Foundation Model with A Universal Pre-training Paradigm (github.com)</a></p>
<p>PointCloud 提取特征(点云编码器) + NeRF 渲染图片 + 图片损失优化点云编码器</p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231107153921.png" alt="image.png|666"></p>
<h2 id="Spiking-NeRF"><a href="#Spiking-NeRF" class="headerlink" title="Spiking NeRF"></a>Spiking NeRF</h2><p>Spiking NeRF: Representing the Real-World Geometry by a Discontinuous Representation</p>
<p>MLP 是连续函数，对 NeRF 网络结构的改进来生成不连续的密度场</p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231116155214.png" alt="image.png|666"></p>
<h2 id="Hyb-NeRF"><a href="#Hyb-NeRF" class="headerlink" title="Hyb-NeRF"></a>Hyb-NeRF</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.12490">[2311.12490] Hyb-NeRF: A Multiresolution Hybrid Encoding for Neural Radiance Fields (arxiv.org)</a></p>
<p>多分辨率混合编码</p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231123143210.png" alt="image.png|666"></p>
<h2 id="In-Hand-3D-Object-Reconstruction-from-a-Monocular-RGB-Video"><a href="#In-Hand-3D-Object-Reconstruction-from-a-Monocular-RGB-Video" class="headerlink" title="In-Hand 3D Object Reconstruction from a Monocular RGB Video"></a>In-Hand 3D Object Reconstruction from a Monocular RGB Video</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2312.16425">In-Hand 3D Object Reconstruction from a Monocular RGB Video</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20240104173205.png" alt="image.png|666"></p>
<h2 id="Dynamic"><a href="#Dynamic" class="headerlink" title="Dynamic"></a>Dynamic</h2><h3 id="MorpheuS"><a href="#MorpheuS" class="headerlink" title="MorpheuS"></a>MorpheuS</h3><p><a target="_blank" rel="noopener" href="https://hengyiwang.github.io/projects/morpheus">MorpheuS (hengyiwang.github.io)</a><br>MorpheuS: Neural Dynamic 360° Surface Reconstruction from <strong>Monocular RGB-D Video</strong><br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231204133746.png" alt="image.png|666"></p>
<h3 id="NPGs"><a href="#NPGs" class="headerlink" title="NPGs"></a>NPGs</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2312.01196">[2312.01196] Neural Parametric Gaussians for Monocular Non-Rigid Object Reconstruction (arxiv.org)</a><br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231205153011.png" alt="image.png|666"></p>
<h1 id="NeRF-Human-Body-Reconstruction"><a href="#NeRF-Human-Body-Reconstruction" class="headerlink" title="NeRF Human Body Reconstruction"></a>NeRF Human Body Reconstruction</h1><h2 id="HISR"><a href="#HISR" class="headerlink" title="HISR"></a>HISR</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2312.17192">[2312.17192] HISR: Hybrid Implicit Surface Representation for Photorealistic 3D Human Reconstruction (arxiv.org)</a><br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20240104172512.png" alt="image.png|666"></p>
<ul>
<li>对不透明区域（例如身体、脸部、衣服）执行基于表面的渲染</li>
<li>在半透明区域（例如头发）上执行体积渲染</li>
</ul>
<h2 id="DoubleField"><a href="#DoubleField" class="headerlink" title="DoubleField"></a>DoubleField</h2><p><a target="_blank" rel="noopener" href="http://www.liuyebin.com/dbfield/dbfield.html">DoubleField Project Page (liuyebin.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231110163602.png" alt="image.png|666"></p>
<h2 id="Learning-Visibility-Field-for-Detailed-3D-Human-Reconstruction-and-Relighting"><a href="#Learning-Visibility-Field-for-Detailed-3D-Human-Reconstruction-and-Relighting" class="headerlink" title="Learning Visibility Field for Detailed 3D Human Reconstruction and Relighting"></a>Learning Visibility Field for Detailed 3D Human Reconstruction and Relighting</h2><p><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_Learning_Visibility_Field_for_Detailed_3D_Human_Reconstruction_and_Relighting_CVPR_2023_paper.pdf">Learning Visibility Field for Detailed 3D Human Reconstruction and Relighting (thecvf.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008104907.png" alt="image.png|666"></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008105237.png" alt="image.png|666"></p>
<h2 id="HumanGen"><a href="#HumanGen" class="headerlink" title="HumanGen"></a>HumanGen</h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://suezjiang.github.io/humangen/">HumanGen: Generating Human Radiance Fields with Explicit Priors (suezjiang.github.io)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231002104131.png" alt="image.png|666"></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231002104310.png" alt="image.png|333"></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231002104340.png" alt="image.png|666"></p>
<h2 id="GNeuVox"><a href="#GNeuVox" class="headerlink" title="GNeuVox"></a>GNeuVox</h2><p><a target="_blank" rel="noopener" href="https://taoranyi.com/gneuvox/">GNeuVox: Generalizable Neural Voxels for Fast Human Radiance Fields (taoranyi.com)</a><br><a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=4738288024060706817&amp;noteId=1996978666924478208">Generalizable Neural Voxels for Fast Human Radiance Fields (readpaper.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008173458.png" alt="image.png|666"></p>
<h2 id="CAR"><a href="#CAR" class="headerlink" title="CAR"></a>CAR</h2><p><a target="_blank" rel="noopener" href="https://tingtingliao.github.io/CAR/">CAR (tingtingliao.github.io)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008172759.png" alt="image.png|666"></p>
<h2 id="HDHumans"><a href="#HDHumans" class="headerlink" title="HDHumans"></a>HDHumans</h2><p><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/3606927">HDHumans (acm.org)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008193531.png" alt="image.png|666"></p>
<h2 id="EVA3D-2022"><a href="#EVA3D-2022" class="headerlink" title="EVA3D 2022"></a>EVA3D 2022</h2><p>Compositional Human body<br>质量很低<br>Idea：</p>
<ul>
<li>将人体分为几个部分分别训练</li>
<li>将 NeRF 融合进 GAN 的生成器中，并与一个判别器进行联合训练</li>
</ul>
<p>Cost：</p>
<ul>
<li>8 NVIDIA V100 Gpus for 5 days</li>
</ul>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://hongfz16.github.io/projects/EVA3D.html">EVA3D - Project Page (hongfz16.github.io)</a><br><a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=4677480793493209089&amp;noteId=1985412009585125888">EVA3D: Compositional 3D Human Generation from 2D Image Collections (readpaper.com)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230930153949.png" alt="image|666"></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230930154048.png" alt="image.png|666"></p>
<h2 id="Dynamic-1"><a href="#Dynamic-1" class="headerlink" title="Dynamic"></a>Dynamic</h2><h3 id="3DGS-Avatar"><a href="#3DGS-Avatar" class="headerlink" title="3DGS-Avatar"></a>3DGS-Avatar</h3><p><a target="_blank" rel="noopener" href="https://neuralbodies.github.io/3DGS-Avatar/">3DGS-Avatar: Animatable Avatars via Deformable 3D Gaussian Splatting (neuralbodies.github.io)</a><br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231218201652.png" alt="image.png|666"></p>
<h3 id="GaussianAvatar"><a href="#GaussianAvatar" class="headerlink" title="GaussianAvatar"></a>GaussianAvatar</h3><p><a target="_blank" rel="noopener" href="https://huliangxiao.github.io/GaussianAvatar">Projectpage of GaussianAvatar (huliangxiao.github.io)</a><br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231205153138.png" alt="image.png|666"></p>
<h3 id="Vid2Avatar"><a href="#Vid2Avatar" class="headerlink" title="Vid2Avatar"></a>Vid2Avatar</h3><blockquote>
<p><a href="Vid2Avatar.md">Vid2Avatar: 3D Avatar Reconstruction from Videos in the Wild via Self-supervised Scene Decomposition</a><br><a target="_blank" rel="noopener" href="https://moygcc.github.io/vid2avatar/">Vid2Avatar: 3D Avatar Reconstruction from Videos in the Wild via Self-supervised Scene Decomposition (moygcc.github.io)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230921171140.png" alt="image.png|666"></p>
<h3 id="Im4D"><a href="#Im4D" class="headerlink" title="Im4D"></a>Im4D</h3><p><a target="_blank" rel="noopener" href="https://zju3dv.github.io/im4d/">Im4D (zju3dv.github.io)</a><br>Im4D: High-Fidelity and Real-Time Novel View Synthesis for Dynamic Scenes</p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231013171508.png" alt="image.png|666"></p>
<h3 id="HumanRF"><a href="#HumanRF" class="headerlink" title="HumanRF"></a>HumanRF</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://synthesiaresearch.github.io/humanrf/">HumanRF: High-Fidelity Neural Radiance Fields for Humans in Motion (synthesiaresearch.github.io)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231001165622.png" alt="image.png|666"></p>
<h3 id="Neural-Body"><a href="#Neural-Body" class="headerlink" title="Neural Body"></a>Neural Body</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://zju3dv.github.io/neuralbody/">Neural Body: Implicit Neural Representations with Structured Latent Codes for Novel View Synthesis of Dynamic Humans (zju3dv.github.io)</a></p>
</blockquote>
<p>首先在SMPL6890个顶点上定义一组潜在代码，然后<br>使用<a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=4498402014756757505&amp;noteId=2065156297063368192">Total Capture: A 3D Deformation Model for Tracking Faces, Hands, and Bodies (readpaper.com)</a><br>从多视图图片中获取SMPL参数$S_{t}$</p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231001170255.png" alt="image.png|666"></p>
<h3 id="InstantNVR"><a href="#InstantNVR" class="headerlink" title="InstantNVR"></a>InstantNVR</h3><p><a target="_blank" rel="noopener" href="https://zju3dv.github.io/instant_nvr/">Learning Neural Volumetric Representations of Dynamic Humans in Minutes (zju3dv.github.io)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231001172828.png" alt="image.png|666"></p>
<h3 id="4K4D"><a href="#4K4D" class="headerlink" title="4K4D"></a>4K4D</h3><p><a target="_blank" rel="noopener" href="https://zju3dv.github.io/4k4d/">4K4D (zju3dv.github.io)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231023154027.png" alt="image.png|666"></p>
<h3 id="D3GA"><a href="#D3GA" class="headerlink" title="D3GA"></a>D3GA</h3><p><a target="_blank" rel="noopener" href="https://zielon.github.io/d3ga/">D3GA - Drivable 3D Gaussian Avatars - Wojciech Zielonka</a></p>
<p>多视图视频作为输入 + 3DGS + 笼形变形</p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231117103528.png" alt="image.png|666"></p>
<h2 id="Human-Object-Interactions"><a href="#Human-Object-Interactions" class="headerlink" title="Human-Object Interactions"></a>Human-Object Interactions</h2><h3 id="Instant-NVR"><a href="#Instant-NVR" class="headerlink" title="Instant-NVR"></a>Instant-NVR</h3><p><a target="_blank" rel="noopener" href="https://nowheretrix.github.io/Instant-NVR/">Instant-NVR: Instant Neural Volumetric Rendering for Human-object Interactions from Monocular RGBD Stream</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008115305.png" alt="image.png|666"></p>
<h3 id="NeuralDome"><a href="#NeuralDome" class="headerlink" title="NeuralDome"></a>NeuralDome</h3><p><a target="_blank" rel="noopener" href="https://juzezhang.github.io/NeuralDome/">NeuralDome (juzezhang.github.io)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008120011.png" alt="image.png|666"></p>
<h1 id="Gaussian-Splatting-Method"><a href="#Gaussian-Splatting-Method" class="headerlink" title="Gaussian Splatting Method"></a>Gaussian Splatting Method</h1><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2401.03890.pdf">A Survey on 3D Gaussian Splatting</a></p>
<h2 id="SuGaR"><a href="#SuGaR" class="headerlink" title="SuGaR"></a>SuGaR</h2><p><a target="_blank" rel="noopener" href="https://imagine.enpc.fr/~guedona/sugar/">SuGaR (enpc.fr)</a></p>
<p>3D Gaussian Splatting 提取mesh<br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231123142658.png" alt="image.png|666"></p>
<h1 id="PIFu-Occupancy-Field"><a href="#PIFu-Occupancy-Field" class="headerlink" title="PIFu Occupancy Field"></a>PIFu Occupancy Field</h1><blockquote>
<p><a href="PIFu.md">PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization</a><br><a target="_blank" rel="noopener" href="https://shunsukesaito.github.io/PIFu/">PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization (shunsukesaito.github.io)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230928170950.png" alt="image.png|666"></p>
<h2 id="PIFuHD"><a href="#PIFuHD" class="headerlink" title="PIFuHD"></a>PIFuHD</h2><blockquote>
<p><a href="PIFuHD.md">PIFuHD: Multi-Level Pixel-Aligned Implicit Function for High-Resolution 3D Human Digitization</a><br><a target="_blank" rel="noopener" href="https://shunsukesaito.github.io/PIFuHD/">PIFuHD: Multi-Level Pixel-Aligned Implicit Function for High-Resolution 3D Human Digitization (shunsukesaito.github.io)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230928175323.png" alt="image.png|666"></p>
<h2 id="PIFu-for-the-Real-World"><a href="#PIFu-for-the-Real-World" class="headerlink" title="PIFu for the Real World"></a>PIFu for the Real World</h2><p><a target="_blank" rel="noopener" href="https://github.com/X-zhangyang/SelfPIFu--PIFu-for-the-Real-World">X-zhangyang/SelfPIFu—PIFu-for-the-Real-World: Dressed Human Reconstrcution from Single-view Real World Image (github.com)</a><br><a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=4660017586591776769&amp;noteId=1996688855483354880">PIFu for the Real World: A Self-supervised Framework to Reconstruct Dressed Human from Single-view Images (readpaper.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008194000.png" alt="image.png|666"></p>
<h2 id="DIFu"><a href="#DIFu" class="headerlink" title="DIFu"></a>DIFu</h2><p><a target="_blank" rel="noopener" href="https://eadcat.github.io/DIFu/">DIFu: Depth-Guided Implicit Function for Clothed Human Reconstruction (eadcat.github.io)</a><br><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Song_DIFu_Depth-Guided_Implicit_Function_for_Clothed_Human_Reconstruction_CVPR_2023_paper.pdf">DIFu: Depth-Guided Implicit Function for Clothed Human Reconstruction (thecvf.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008114221.png" alt="image.png|666"></p>
<h2 id="SeSDF"><a href="#SeSDF" class="headerlink" title="SeSDF"></a>SeSDF</h2><p><a target="_blank" rel="noopener" href="https://yukangcao.github.io/SeSDF/">SeSDF: Self-evolved Signed Distance Field for Implicit 3D Clothed Human Reconstruction (yukangcao.github.io)</a><br><a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=4740902287992438785&amp;noteId=1996730143273232896">SeSDF: Self-evolved Signed Distance Field for Implicit 3D Clothed Human Reconstruction (readpaper.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008113348.png" alt="image.png|666"></p>
<h2 id="UNIF"><a href="#UNIF" class="headerlink" title="UNIF"></a>UNIF</h2><p><a target="_blank" rel="noopener" href="https://shenhanqian.github.io/unif">UNIF: United Neural Implicit Functions for Clothed Human Reconstruction and Animation | Shenhan Qian</a><br><a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=4648065386802069505&amp;noteId=1996740483288731392">UNIF: United Neural Implicit Functions for Clothed Human Reconstruction and Animation (readpaper.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008163003.png" alt="image.png|666"></p>
<h2 id="Structured-3D-Features"><a href="#Structured-3D-Features" class="headerlink" title="Structured 3D Features"></a>Structured 3D Features</h2><p>Reconstructing <strong>Relightable</strong> and <strong>Animatable</strong> Avatars<br><a target="_blank" rel="noopener" href="https://enriccorona.github.io/s3f/">Enric Corona</a><br><a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=4700589883291336705&amp;noteId=1996756493166029056">Structured 3D Features for Reconstructing Relightable and Animatable Avatars (readpaper.com)</a></p>
<p>X,3d fea,2d fea —&gt; transformer —&gt; sdf, albedo<br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008174219.png" alt="image.png|666"></p>
<h2 id="GTA"><a href="#GTA" class="headerlink" title="GTA"></a>GTA</h2><p><a target="_blank" rel="noopener" href="https://river-zhang.github.io/GTA-projectpage/">Global-correlated 3D-decoupling Transformer for Clothed Avatar Reconstruction (river-zhang.github.io)</a><br><a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=4804636732393783297&amp;noteId=2021327250504312576">Global-correlated 3D-decoupling Transformer for Clothed Avatar Reconstruction (readpaper.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231016094412.png" alt="image.png|666"></p>
<h2 id="Get3DHuman"><a href="#Get3DHuman" class="headerlink" title="Get3DHuman"></a>Get3DHuman</h2><p><a target="_blank" rel="noopener" href="https://x-zhangyang.github.io/2023_Get3DHuman/">Get3DHuman: Lifting StyleGAN-Human into a 3D Generative Model using Pixel-aligned Reconstruction Priors. (x-zhangyang.github.io)</a></p>
<p>GAN + PIFus<br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231023160121.png" alt="image.png|666"></p>
<h2 id="DRIFu"><a href="#DRIFu" class="headerlink" title="DRIFu"></a>DRIFu</h2><p><a target="_blank" rel="noopener" href="https://github.com/kuangzijian/drifu-for-animals">kuangzijian/drifu-for-animals: meta-learning based pifu model for animals (github.com)</a></p>
<p>鸟类PIFu<br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231123151648.png" alt="image.png|666"><br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231123151707.png" alt="image.png|666"></p>
<h3 id="SIFU"><a href="#SIFU" class="headerlink" title="SIFU"></a>SIFU</h3><p><a target="_blank" rel="noopener" href="https://river-zhang.github.io/SIFU-projectpage/">SIFU Project Page (river-zhang.github.io)</a><br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231218204004.png" alt="image.png|666"></p>
<h1 id="Depth-amp-Normal-Estimation"><a href="#Depth-amp-Normal-Estimation" class="headerlink" title="Depth&amp;Normal Estimation"></a>Depth&amp;Normal Estimation</h1><p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230930182135.png" alt="image.png|444"></p>
<h2 id="ICON"><a href="#ICON" class="headerlink" title="ICON"></a>ICON</h2><blockquote>
<p><a href="ICON.md">ICON: Implicit Clothed humans Obtained from Normals</a><br><a target="_blank" rel="noopener" href="https://icon.is.tue.mpg.de/">ICON (mpg.de)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230930162915.png" alt="image.png|666"></p>
<h2 id="ECON"><a href="#ECON" class="headerlink" title="ECON"></a>ECON</h2><blockquote>
<p><a href="ECON.md">ECON: Explicit Clothed humans Obtained from Normals</a><br><a target="_blank" rel="noopener" href="https://xiuyuliang.cn/econ/">ECON: Explicit Clothed humans Optimized via Normal integration (xiuyuliang.cn)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230930173026.png" alt="image.png|666"></p>
<h2 id="2K2K"><a href="#2K2K" class="headerlink" title="2K2K"></a>2K2K</h2><p>DepthEstimation</p>
<blockquote>
<p><a href="2K2K.md">2K2K：High-fidelity 3D Human Digitization from Single 2K Resolution Images</a><br><a target="_blank" rel="noopener" href="https://sanghunhan92.github.io/conference/2K2K/">High-fidelity 3D Human Digitization from Single 2K Resolution Images Project Page (sanghunhan92.github.io)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230921160120.png" alt="image.png|666"></p>
<h2 id="MVSNet"><a href="#MVSNet" class="headerlink" title="MVSNet"></a>MVSNet</h2><p>DepthEstimation</p>
<blockquote>
<p><a href="MVSNet.md">MVSNet: Depth Inference for Unstructured Multi-view Stereo</a><br><a target="_blank" rel="noopener" href="https://github.com/YoYo000/MVSNet">YoYo000/MVSNet: MVSNet (ECCV2018) &amp; R-MVSNet (CVPR2019) (github.com)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231002110228.png" alt="image.png|666"></p>
<h2 id="GC-MVSNet"><a href="#GC-MVSNet" class="headerlink" title="GC-MVSNet"></a>GC-MVSNet</h2><p>多尺度+多视图几何一致性<br><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.19583">GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View Stereo (arxiv.org)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231031172920.png" alt="image.png|666"></p>
<h2 id="MonoDiffusion"><a href="#MonoDiffusion" class="headerlink" title="MonoDiffusion"></a>MonoDiffusion</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.07198">MonoDiffusion: Self-Supervised Monocular Depth Estimation Using Diffusion Model</a></p>
<p>用 Diffusion Model 进行深度估计(自动驾驶)</p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231116153515.png" alt="image.png|666"></p>
<h2 id="NDDepth"><a href="#NDDepth" class="headerlink" title="NDDepth"></a>NDDepth</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.07166">NDDepth: Normal-Distance Assisted Monocular Depth Estimation and Completion</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231116153659.png" alt="image.png|666"></p>
<h2 id="OccNeRF"><a href="#OccNeRF" class="headerlink" title="OccNeRF"></a>OccNeRF</h2><p><a target="_blank" rel="noopener" href="https://github.com/LinShan-Bin/OccNeRF">LinShan-Bin/OccNeRF: Code of “OccNeRF: Self-Supervised Multi-Camera Occupancy Prediction with Neural Radiance Fields”. (github.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231218200234.png" alt="image.png|666"></p>
<h1 id="Other"><a href="#Other" class="headerlink" title="Other"></a>Other</h1><h2 id="Texture"><a href="#Texture" class="headerlink" title="Texture"></a>Texture</h2><h3 id="Paint3D"><a href="#Paint3D" class="headerlink" title="Paint3D"></a>Paint3D</h3><p><a target="_blank" rel="noopener" href="https://github.com/OpenTexture/Paint3D">OpenTexture/Paint3D: Paint3D: Paint Anything 3D with Lighting-Less Texture Diffusion Models, a no lighting baked texture generative model (github.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231223172838.png" alt="image.png|666"></p>
<h2 id="Explicit-Template-Decomposition"><a href="#Explicit-Template-Decomposition" class="headerlink" title="Explicit Template Decomposition"></a>Explicit Template Decomposition</h2><h3 id="TeCH"><a href="#TeCH" class="headerlink" title="TeCH"></a>TeCH</h3><p><a target="_blank" rel="noopener" href="https://huangyangyi.github.io/TeCH/">TeCH: Text-guided Reconstruction of Lifelike Clothed Humans (huangyangyi.github.io)</a></p>
<p>DMTet 表示：consists of an explicit body shape grid and an implicit distance field<br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231102112309.png" alt="image.png|666"></p>
<h3 id="CloSET"><a href="#CloSET" class="headerlink" title="CloSET"></a>CloSET</h3><p><a target="_blank" rel="noopener" href="https://www.liuyebin.com/closet/">CloSET CVPR 2023 (liuyebin.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008110803.png" alt="image.png|666"></p>
<h3 id="Chupa"><a href="#Chupa" class="headerlink" title="Chupa"></a>Chupa</h3><p><a target="_blank" rel="noopener" href="https://snuvclab.github.io/chupa/">Chupa (snuvclab.github.io)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008164813.png" alt="image.png|666"></p>
<h2 id="Human-Face"><a href="#Human-Face" class="headerlink" title="Human Face"></a>Human Face</h2><h2 id="GPAvatar"><a href="#GPAvatar" class="headerlink" title="GPAvatar"></a>GPAvatar</h2><p><a target="_blank" rel="noopener" href="https://github.com/xg-chu/GPAvatar">xg-chu/GPAvatar: [ICLR 2024] Generalizable and Precise Head Avatar from Image(s) (github.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20240122172842.png" alt="image.png|666"></p>
<h3 id="HeadRecon"><a href="#HeadRecon" class="headerlink" title="HeadRecon"></a>HeadRecon</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2312.08863">[2312.08863] HeadRecon: High-Fidelity 3D Head Reconstruction from Monocular Video (arxiv.org)</a><br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231218201501.png" alt="image.png|666"></p>
<h3 id="GaussianHead"><a href="#GaussianHead" class="headerlink" title="GaussianHead"></a>GaussianHead</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2312.01632">[2312.01632] GaussianHead: Impressive 3D Gaussian-based Head Avatars with Dynamic Hybrid Neural Field (arxiv.org)</a><br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231205153845.png" alt="image.png|666"></p>
<h3 id="GaussianAvatars"><a href="#GaussianAvatars" class="headerlink" title="GaussianAvatars"></a>GaussianAvatars</h3><p><a target="_blank" rel="noopener" href="https://shenhanqian.github.io/gaussian-avatars">GaussianAvatars: Photorealistic Head Avatars with Rigged 3D Gaussians | Shenhan Qian</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/picturesmethod.jpg" alt="method.jpg|666"></p>
<h3 id="TRAvatar"><a href="#TRAvatar" class="headerlink" title="TRAvatar"></a>TRAvatar</h3><p><a target="_blank" rel="noopener" href="https://travatar-paper.github.io/">Towards Practical Capture of High-Fidelity Relightable Avatars (travatar-paper.github.io)</a></p>
<p>动态人脸<br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231121121931.png" alt="image.png|666"></p>
<h3 id="FLARE"><a href="#FLARE" class="headerlink" title="FLARE"></a>FLARE</h3><p><a target="_blank" rel="noopener" href="https://flare.is.tue.mpg.de/">FLARE (mpg.de)</a></p>
<p>FLARE: Fast Learning of Animatable and Relightable Mesh Avatars</p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231114093649.png" alt="image.png|666"></p>
<h3 id="HRN"><a href="#HRN" class="headerlink" title="HRN"></a>HRN</h3><blockquote>
<p><a href="HRN.md">A Hierarchical Representation Network for Accurate and Detailed Face Reconstruction from In-The-Wild Images</a><br><a target="_blank" rel="noopener" href="https://younglbw.github.io/HRN-homepage/">HRN (younglbw.github.io)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230921173632.png" alt="image.png|666"></p>
<h3 id="单目-3D-人脸重建"><a href="#单目-3D-人脸重建" class="headerlink" title="单目 3D 人脸重建"></a>单目 3D 人脸重建</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.19580">A Perceptual Shape Loss for Monocular 3D Face Reconstruction</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231031181210.png" alt="image.png|666"></p>
<h3 id="BakedAvatar"><a href="#BakedAvatar" class="headerlink" title="BakedAvatar"></a>BakedAvatar</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2311.05521.pdf">BakedAvatar: Baking Neural Fields for Real-Time Head Avatar Synthesis (arxiv.org)</a></p>
<p>头部实时新视图生成<br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231110155612.png" alt="image.png|666"></p>
<h3 id="Video"><a href="#Video" class="headerlink" title="Video"></a>Video</h3><ul>
<li><strong>3D-Aware Talking-Head Video Motion Transfer</strong> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.02549">https://arxiv.org/abs/2311.02549</a></li>
<li><a target="_blank" rel="noopener" href="https://yudeng.github.io/Portrait4D/">Portrait4D: Learning One-Shot 4D Head Avatar Synthesis using Synthetic Data (yudeng.github.io)</a></li>
<li><a target="_blank" rel="noopener" href="https://tobias-kirschstein.github.io/diffusion-avatars/">DiffusionAvatars: Deferred Diffusion for High-fidelity 3D Head Avatars (tobias-kirschstein.github.io)</a></li>
<li><a target="_blank" rel="noopener" href="https://ustc3dv.github.io/CosAvatar/">CosAvatar (ustc3dv.github.io)</a></li>
</ul>
<h2 id="Segmented-Instance-Object"><a href="#Segmented-Instance-Object" class="headerlink" title="Segmented Instance/Object"></a>Segmented Instance/Object</h2><h3 id="Registered-and-Segmented-Deformable-Object-Reconstruction-from-a-Single-View-Point-Cloud"><a href="#Registered-and-Segmented-Deformable-Object-Reconstruction-from-a-Single-View-Point-Cloud" class="headerlink" title="Registered and Segmented Deformable Object Reconstruction from a Single View Point Cloud"></a>Registered and Segmented Deformable Object Reconstruction from a Single View Point Cloud</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.07357">Registered and Segmented Deformable Object Reconstruction from a Single View Point Cloud</a></p>
<p>配准 + 分割物体重建<br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231116153203.png" alt="image.png|666"></p>
<h3 id="3DFusion-A-real-time-3D-object-reconstruction-pipeline-based-on-streamed-instance-segmented-data"><a href="#3DFusion-A-real-time-3D-object-reconstruction-pipeline-based-on-streamed-instance-segmented-data" class="headerlink" title="3DFusion, A real-time 3D object reconstruction pipeline based on streamed instance segmented data"></a>3DFusion, A real-time 3D object reconstruction pipeline based on streamed instance segmented data</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.06659">3DFusion, A real-time 3D object reconstruction pipeline based on streamed instance segmented data</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231116153353.png" alt="image.png|555"></p>
<h2 id="Human-Body-Shape-Completion"><a href="#Human-Body-Shape-Completion" class="headerlink" title="Human Body Shape Completion"></a>Human Body Shape Completion</h2><p><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Human_Body_Shape_Completion_With_Implicit_Shape_and_Flow_Learning_CVPR_2023_paper.pdf">Human Body Shape Completion With Implicit Shape and Flow Learning (thecvf.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008160354.png" alt="image.png|666"></p>
<h2 id="Incomplete-Image"><a href="#Incomplete-Image" class="headerlink" title="Incomplete Image"></a>Incomplete Image</h2><p>Complete 3D Human Reconstruction from a Single Incomplete Image</p>
<p><a target="_blank" rel="noopener" href="https://junyingw.github.io/paper/3d_inpainting/">Complete 3D Human Reconstruction from a Single Incomplete Image (junyingw.github.io)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008114841.png" alt="image.png|666"></p>
<h2 id="New-NetWork-FeatER"><a href="#New-NetWork-FeatER" class="headerlink" title="New NetWork FeatER"></a>New NetWork FeatER</h2><p><a target="_blank" rel="noopener" href="https://zczcwh.github.io/feater_page/">FeatER: An Efficient Network for Human Reconstruction via Feature Map-Based TransformER (zczcwh.github.io)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008160659.png" alt="image.png|666"></p>
<h2 id="HF-Avatar"><a href="#HF-Avatar" class="headerlink" title="HF-Avatar"></a>HF-Avatar</h2><p><a target="_blank" rel="noopener" href="https://github.com/hzhao1997/HF-Avatar?tab=readme-ov-file">hzhao1997/HF-Avatar (github.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231017182026.png" alt="image.png|666"></p>
<h2 id="多模态数字人生成-数字人视频"><a href="#多模态数字人生成-数字人视频" class="headerlink" title="多模态数字人生成(数字人视频)"></a>多模态数字人生成(数字人视频)</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2310.20251.pdf">An Implementation of Multimodal Fusion System for Intelligent Digital Human Generation</a></p>
<p>输入：文本、音频、图片<br>输出：自定义人物视频(图片/+修改/+风格化)+音频(文本合成+音频音色参考)</p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231101153147.png" alt="image.png|666"></p>
<h3 id="IPVNet"><a href="#IPVNet" class="headerlink" title="IPVNet"></a>IPVNet</h3><p><a target="_blank" rel="noopener" href="https://github.com/robotic-vision-lab/Implicit-Point-Voxel-Features-Network">robotic-vision-lab/Implicit-Point-Voxel-Features-Network: Implicit deep neural network for 3D surface reconstruction. (github.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231108222654.png" alt="image.png|666"></p>

    </div>

    
    
    
        

  <div class="followme">
    <p>Welcome to my other publishing channels</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="https://t.me/+1ZnNxFWnEbk5YzRl">
            <span class="icon">
              <i class="fab fa-telegram"></i>
            </span>

            <span class="label">Telegram</span>
          </a>
        </div>
    </div>
  </div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/3DReconstruction/" rel="tag"><i class="fa fa-tag"></i> 3DReconstruction</a>
              <a href="/tags/SurfaceReconstruction/" rel="tag"><i class="fa fa-tag"></i> SurfaceReconstruction</a>
              <a href="/tags/NeRF/" rel="tag"><i class="fa fa-tag"></i> NeRF</a>
              <a href="/tags/MVS/" rel="tag"><i class="fa fa-tag"></i> MVS</a>
              <a href="/tags/PIFu/" rel="tag"><i class="fa fa-tag"></i> PIFu</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/3DReconstruction/Basic%20Knowledge/NeRF/Review/A%20Review%20of%20Deep%20Learning-Powered%20Mesh%20Reconstruction%20Methods/" rel="prev" title="A Review of Deep Learning-Powered Mesh Reconstruction Methods">
      <i class="fa fa-chevron-left"></i> A Review of Deep Learning-Powered Mesh Reconstruction Methods
    </a></div>
      <div class="post-nav-item">
    <a href="/3DReconstruction/Basic%20Knowledge/NeRF/NeRF/Datasets/" rel="next" title="Datasets">
      Datasets <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#NeRF-Object-Reconstruction"><span class="nav-text">NeRF Object Reconstruction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Binary-Opacity-Grids"><span class="nav-text">Binary Opacity Grids</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RNb-NeuS"><span class="nav-text">RNb-NeuS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Voxurf"><span class="nav-text">Voxurf</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ReTR"><span class="nav-text">ReTR</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NISR"><span class="nav-text">NISR</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#D-NeuS"><span class="nav-text">D-NeuS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#AutoRecon"><span class="nav-text">AutoRecon</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#G-Shell"><span class="nav-text">G-Shell</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Adaptive-Shells"><span class="nav-text">Adaptive Shells</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DynamicSurf"><span class="nav-text">DynamicSurf</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RayDF"><span class="nav-text">RayDF</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PonderV2"><span class="nav-text">PonderV2</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Spiking-NeRF"><span class="nav-text">Spiking NeRF</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hyb-NeRF"><span class="nav-text">Hyb-NeRF</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#In-Hand-3D-Object-Reconstruction-from-a-Monocular-RGB-Video"><span class="nav-text">In-Hand 3D Object Reconstruction from a Monocular RGB Video</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Dynamic"><span class="nav-text">Dynamic</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#MorpheuS"><span class="nav-text">MorpheuS</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NPGs"><span class="nav-text">NPGs</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#NeRF-Human-Body-Reconstruction"><span class="nav-text">NeRF Human Body Reconstruction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#HISR"><span class="nav-text">HISR</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DoubleField"><span class="nav-text">DoubleField</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Learning-Visibility-Field-for-Detailed-3D-Human-Reconstruction-and-Relighting"><span class="nav-text">Learning Visibility Field for Detailed 3D Human Reconstruction and Relighting</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HumanGen"><span class="nav-text">HumanGen</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GNeuVox"><span class="nav-text">GNeuVox</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CAR"><span class="nav-text">CAR</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDHumans"><span class="nav-text">HDHumans</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#EVA3D-2022"><span class="nav-text">EVA3D 2022</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Dynamic-1"><span class="nav-text">Dynamic</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3DGS-Avatar"><span class="nav-text">3DGS-Avatar</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GaussianAvatar"><span class="nav-text">GaussianAvatar</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Vid2Avatar"><span class="nav-text">Vid2Avatar</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Im4D"><span class="nav-text">Im4D</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HumanRF"><span class="nav-text">HumanRF</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Neural-Body"><span class="nav-text">Neural Body</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#InstantNVR"><span class="nav-text">InstantNVR</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4K4D"><span class="nav-text">4K4D</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#D3GA"><span class="nav-text">D3GA</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Human-Object-Interactions"><span class="nav-text">Human-Object Interactions</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Instant-NVR"><span class="nav-text">Instant-NVR</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NeuralDome"><span class="nav-text">NeuralDome</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Gaussian-Splatting-Method"><span class="nav-text">Gaussian Splatting Method</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#SuGaR"><span class="nav-text">SuGaR</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#PIFu-Occupancy-Field"><span class="nav-text">PIFu Occupancy Field</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#PIFuHD"><span class="nav-text">PIFuHD</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PIFu-for-the-Real-World"><span class="nav-text">PIFu for the Real World</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DIFu"><span class="nav-text">DIFu</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SeSDF"><span class="nav-text">SeSDF</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#UNIF"><span class="nav-text">UNIF</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Structured-3D-Features"><span class="nav-text">Structured 3D Features</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GTA"><span class="nav-text">GTA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Get3DHuman"><span class="nav-text">Get3DHuman</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DRIFu"><span class="nav-text">DRIFu</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#SIFU"><span class="nav-text">SIFU</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Depth-amp-Normal-Estimation"><span class="nav-text">Depth&amp;Normal Estimation</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#ICON"><span class="nav-text">ICON</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ECON"><span class="nav-text">ECON</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2K2K"><span class="nav-text">2K2K</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MVSNet"><span class="nav-text">MVSNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GC-MVSNet"><span class="nav-text">GC-MVSNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MonoDiffusion"><span class="nav-text">MonoDiffusion</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NDDepth"><span class="nav-text">NDDepth</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#OccNeRF"><span class="nav-text">OccNeRF</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Other"><span class="nav-text">Other</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Texture"><span class="nav-text">Texture</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Paint3D"><span class="nav-text">Paint3D</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Explicit-Template-Decomposition"><span class="nav-text">Explicit Template Decomposition</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#TeCH"><span class="nav-text">TeCH</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CloSET"><span class="nav-text">CloSET</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Chupa"><span class="nav-text">Chupa</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Human-Face"><span class="nav-text">Human Face</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GPAvatar"><span class="nav-text">GPAvatar</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#HeadRecon"><span class="nav-text">HeadRecon</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GaussianHead"><span class="nav-text">GaussianHead</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GaussianAvatars"><span class="nav-text">GaussianAvatars</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TRAvatar"><span class="nav-text">TRAvatar</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#FLARE"><span class="nav-text">FLARE</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HRN"><span class="nav-text">HRN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%95%E7%9B%AE-3D-%E4%BA%BA%E8%84%B8%E9%87%8D%E5%BB%BA"><span class="nav-text">单目 3D 人脸重建</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#BakedAvatar"><span class="nav-text">BakedAvatar</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Video"><span class="nav-text">Video</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Segmented-Instance-Object"><span class="nav-text">Segmented Instance&#x2F;Object</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Registered-and-Segmented-Deformable-Object-Reconstruction-from-a-Single-View-Point-Cloud"><span class="nav-text">Registered and Segmented Deformable Object Reconstruction from a Single View Point Cloud</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3DFusion-A-real-time-3D-object-reconstruction-pipeline-based-on-streamed-instance-segmented-data"><span class="nav-text">3DFusion, A real-time 3D object reconstruction pipeline based on streamed instance segmented data</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Human-Body-Shape-Completion"><span class="nav-text">Human Body Shape Completion</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Incomplete-Image"><span class="nav-text">Incomplete Image</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#New-NetWork-FeatER"><span class="nav-text">New NetWork FeatER</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HF-Avatar"><span class="nav-text">HF-Avatar</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E6%A8%A1%E6%80%81%E6%95%B0%E5%AD%97%E4%BA%BA%E7%94%9F%E6%88%90-%E6%95%B0%E5%AD%97%E4%BA%BA%E8%A7%86%E9%A2%91"><span class="nav-text">多模态数字人生成(数字人视频)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#IPVNet"><span class="nav-text">IPVNet</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Qi Yun"
      src="/images/avatar.jpeg">
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">137</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">31</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">59</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/qiyun71" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;qiyun71" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://space.bilibili.com/29010355" title="Bilibili → https:&#x2F;&#x2F;space.bilibili.com&#x2F;29010355" rel="noopener" target="_blank"><i class="fa fa-star fa-fw"></i>Bilibili</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2020 – 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Qi Yun</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="Symbols count total">465k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">28:13</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/yqq/anime.min.js"></script>
  <script src="/yqq/velocity/velocity.min.js"></script>
  <script src="/yqq/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="//cdn.jsdelivr.net/gh/theme-next/theme-next-three@1/three.min.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
