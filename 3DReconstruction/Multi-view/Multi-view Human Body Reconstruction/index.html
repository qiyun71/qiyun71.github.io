<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/blog.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/blog.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/yqq/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":true},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Terminology&#x2F;Jargon  Human Radiance Fields 3D Clothed Human Reconstruction | Digitization  Application  三维重建设备：手持扫描仪或 360 度相机矩阵（成本高） 复刻一个迷你版的自己  Method  Depth&amp;Normal Estimation(2K2K)  Implicit Fun">
<meta property="og:type" content="article">
<meta property="og:title" content="Multi-view Human Body Reconstruction">
<meta property="og:url" content="http://example.com/3DReconstruction/Multi-view/Multi-view%20Human%20Body%20Reconstruction/index.html">
<meta property="og:site_name" content="QiYun">
<meta property="og:description" content="Terminology&#x2F;Jargon  Human Radiance Fields 3D Clothed Human Reconstruction | Digitization  Application  三维重建设备：手持扫描仪或 360 度相机矩阵（成本高） 复刻一个迷你版的自己  Method  Depth&amp;Normal Estimation(2K2K)  Implicit Fun">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/Human.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231024153406.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230928170950.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230921160120.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231021114740.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231024111221.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20240104172512.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231110163602.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008104907.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008105237.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231002104131.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231002104310.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231002104340.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008173458.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008172759.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008193531.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230930153949.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230930154048.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231218201652.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231205153138.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230921171140.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231013171508.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231001165622.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231001170255.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231001172828.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231023154027.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231117103528.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008115305.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008120011.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230928170950.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230928175323.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008194000.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008114221.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008113348.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008163003.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008174219.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231016094412.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231023160121.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231123151648.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231123151707.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231218204004.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230930182135.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230930162915.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230930173026.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230921160120.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231002110228.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231031172920.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231116153515.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231116153659.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231218200234.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231223172838.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231102112309.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008110803.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008164813.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20240122172842.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231218201501.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231205153845.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/picturesmethod.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231121121931.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231114093649.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230921173632.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231031181210.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231110155612.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231116153203.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231116153353.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008160354.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008114841.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008160659.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231017182026.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231101153147.png">
<meta property="og:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231108222654.png">
<meta property="article:published_time" content="2023-10-09T08:33:31.000Z">
<meta property="article:modified_time" content="2024-06-29T12:20:05.944Z">
<meta property="article:author" content="Qi Yun">
<meta property="article:tag" content="3DReconstruction">
<meta property="article:tag" content="ClothedHumans">
<meta property="article:tag" content="PointCloud">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/Human.png">

<link rel="canonical" href="http://example.com/3DReconstruction/Multi-view/Multi-view%20Human%20Body%20Reconstruction/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Multi-view Human Body Reconstruction | QiYun</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">QiYun</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Note</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/3DReconstruction/Multi-view/Multi-view%20Human%20Body%20Reconstruction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpeg">
      <meta itemprop="name" content="Qi Yun">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="QiYun">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Multi-view Human Body Reconstruction
        </h1>

        <div class="post-meta">
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-10-09 16:33:31" itemprop="dateCreated datePublished" datetime="2023-10-09T16:33:31+08:00">2023-10-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-06-29 20:20:05" itemprop="dateModified" datetime="2024-06-29T20:20:05+08:00">2024-06-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/3DReconstruction-Multi-view/" itemprop="url" rel="index"><span itemprop="name">3DReconstruction/Multi-view</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>2.4k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>9 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/Human.png" alt="Human.png|666"></p>
<p>Terminology/Jargon</p>
<ul>
<li>Human Radiance Fields</li>
<li>3D <strong>Clothed Human</strong> Reconstruction | <strong>Digitization</strong></li>
</ul>
<p>Application</p>
<ul>
<li>三维重建设备：手持扫描仪或 360 度相机矩阵（成本高）</li>
<li><a target="_blank" rel="noopener" href="https://www.yangtse.com/content/1604507html">复刻一个迷你版的自己</a></li>
</ul>
<p>Method</p>
<ol>
<li><strong>Depth&amp;Normal Estimation</strong>(2K2K) </li>
<li><strong>Implicit Function</strong>(PIFu or NeRF) </li>
<li><strong>Generative approach</strong>  <a href="Generative%20Models%20Reconstruction.md">Generative Models Reconstruction</a></li>
</ol>
<p><strong>Awesome Human Body Reconstruction</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Method</th>
<th>泛化</th>
<th>数据集监督</th>
<th>提取 mesh 方式</th>
<th>获得纹理方式</th>
</tr>
</thead>
<tbody>
<tr>
<td>2k2k</td>
<td>比较好</td>
<td>(mesh+texture:)depth、normal、mask、rgb</td>
<td>高质量深度图 —&gt; 点云 —&gt; mesh</td>
<td>图片 rgb 贴图</td>
</tr>
<tr>
<td>PIFu</td>
<td>比较好</td>
<td>点云(obj)、rgb(uv)、mask、camera</td>
<td>占用场 —&gt; MC —&gt; 点云,mesh</td>
<td>表面颜色场</td>
</tr>
<tr>
<td>NeRF</td>
<td>差</td>
<td>rgb、camera</td>
<td>密度场 —&gt; MC —&gt; 点云,mesh</td>
<td>体积颜色场</td>
</tr>
<tr>
<td>NeuS</td>
<td>差</td>
<td>rgb、camera</td>
<td>SDF —&gt; MC —&gt; 点云,mesh</td>
<td>体积颜色场</td>
</tr>
<tr>
<td>ICON</td>
<td>非常好</td>
<td>rgb+mask、SMPL、法向量估计器 DR</td>
<td>占用场 —&gt; MC —&gt; 点云,mesh</td>
<td>图片 rgb 贴图</td>
</tr>
<tr>
<td>ECON</td>
<td>非常好</td>
<td>rgb+mask、SMPL、法向量估计器 DR</td>
<td>d-BiNI + SC(shape completion)</td>
<td>图片 rgb 贴图</td>
</tr>
</tbody>
</table>
</div>
<span id="more"></span>
<h1 id="人体三维重建方法综述"><a href="#人体三维重建方法综述" class="headerlink" title="人体三维重建方法综述"></a>人体三维重建方法综述</h1><h2 id="Implicit-Function"><a href="#Implicit-Function" class="headerlink" title="Implicit Function"></a>Implicit Function</h2><p><strong>方法 0</strong>：训练隐式函数表示<br>(eg: NeRF、PIFu、ICON)<br><strong>DoubleField</strong>(多视图)</p>
<p><strong><em>问题：需要估计相机位姿，估计方法有一定的误差，视图少时误差更大</em></strong></p>
<h2 id="Depth-amp-Normal-Estimation"><a href="#Depth-amp-Normal-Estimation" class="headerlink" title="Depth&amp;Normal Estimation"></a>Depth&amp;Normal Estimation</h2><p><strong>方法 1</strong>：深度估计+多视图深度图融合 or 多视图点云配准<br>(2K2K-based)</p>
<p>深度估计: 2K2K、MVSNet、ECON…</p>
<ul>
<li><p>多视图深度图融合：<a target="_blank" rel="noopener" href="https://github.com/touristCheng/DepthFusion">DepthFusion: Fuse multiple depth frames into a point cloud</a></p>
<ul>
<li>需要相机位姿，位姿估计有误差</li>
<li>更准确的位姿: BA(Bundle Adjusted 光束法平差，优化相机 pose 和 landmark)</li>
</ul>
</li>
<li><p>多视图点云配准：<a href="PointCloud%20Review.md">Point Cloud Registration</a></p>
<ul>
<li><strong>点云配准</strong>(Point Cloud Registration) 2K 生成的多角度点云形状不统一</li>
</ul>
</li>
</ul>
<p><strong><em>问题：无法保证生成的多视角深度图具有多视图一致性</em></strong></p>
<h2 id="Generative-approach"><a href="#Generative-approach" class="headerlink" title="Generative approach"></a>Generative approach</h2><p><strong>方法 2</strong>：生成式方法由图片生成点云<br>Generative approach(Multi-view image、pose (keypoints)… —&gt; PointCloud)</p>
<ol>
<li>扩散模型<ol>
<li>直接生成点云 <em>BuilDiff</em></li>
<li>生成三平面特征+NeRF <em>RODIN</em></li>
<li>多视图 Diffusion <a target="_blank" rel="noopener" href="https://liuyebin.com/diffustereo/diffustereo.html">DiffuStereo</a></li>
</ol>
</li>
<li>GAN 网络生成点云 <em>SG-GAN</em></li>
<li>生成一致性图片+NeRF</li>
</ol>
<ul>
<li>参考 <a target="_blank" rel="noopener" href="https://github.com/weiyao1996/BuilDiff">BuilDiff</a>，构建网络(<a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=4544669809538392065&amp;noteId=2018413897297176576">PVCNNs</a> 单类训练)<ul>
<li>是否更换扩散网络 <a target="_blank" rel="noopener" href="https://dit-3d.github.io/">DiT-3D</a>，可以学习显式的类条件嵌入(生成多样化的点云)</li>
<li>是否依靠 SMPL，根据 LBS(Linear Blending Skinning)将人体 mesh 变形到规范化空间<ul>
<li><a target="_blank" rel="noopener" href="https://moygcc.github.io/vid2avatar/">Video2Avatar</a> (NeRF-based)将整个人体规范化后采样</li>
<li><a target="_blank" rel="noopener" href="https://hongfz16.github.io/projects/EVA3D">EVA3D</a> 将 NeRF 融入 GAN 生成图片，并与真实图片一同训练判别器(人体规范化后分块 NeRF)</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong><em>问题：直接生成点云或者对点云进行扩散优化，会花费大量的内存</em></strong></p>
<h2 id="混合方法"><a href="#混合方法" class="headerlink" title="混合方法"></a>混合方法</h2><p><strong>方法 3</strong>：组合深度估计 + 生成式方法（缝合多个方法）<br><a target="_blank" rel="noopener" href="https://github.com/yztang4/HaP">HaP</a>：深度估计+SMPL 估计+Diffusion Model 精细化</p>
<p><strong><em>问题：依赖深度估计和 SMPL 估计得到的结果</em></strong></p>
<p><strong>方法 4</strong>：隐函数 + 生成式方法 + 非刚ICP配准<br><a target="_blank" rel="noopener" href="https://liuyebin.com/diffustereo/diffustereo.html">DiffuStereo</a>：NeRF(DoubleField) + Diffusion Model + non-rigid ICP （<strong><em>不开源</em></strong>）</p>
<h1 id="三维重建方法流程对比"><a href="#三维重建方法流程对比" class="headerlink" title="三维重建方法流程对比"></a>三维重建方法流程对比</h1><h2 id="Implicit-Function-1"><a href="#Implicit-Function-1" class="headerlink" title="Implicit Function"></a>Implicit Function</h2><h3 id="NeRF"><a href="#NeRF" class="headerlink" title="NeRF"></a>NeRF</h3><p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231024153406.png" alt="NeuS2.png|666"><br>预测每个采样点 sdf 和 feature 向量<br>$(sdf,\mathbf{feature})=f_\Theta(\mathbf{e}),\quad\mathbf{e}=(\mathbf{x},h_\Omega(\mathbf{x})).$</p>
<p>预测每个采样点颜色值<br>$\mathbf c=c_{\Upsilon}(\mathbf x,\mathbf n,\mathbf v,sdf,\mathbf{feature})$，$\mathbf n=\nabla_\mathbf x sdf.$</p>
<p>体渲染像素颜色<br>$\hat{C}=\sum_{i=1}^n T_i\alpha_i c_i$， $T_i=\prod_{j=1}^{i-1}(1-\alpha_j)$ ，$\alpha_i=\max\left(\frac{\Phi_s(f(\mathbf{p}(t_i))))-\Phi_s(f(\mathbf{p}(t_{i+1})))}{\Phi_s(f(\mathbf{p}(t_i)))},0\right)$</p>
<p>训练得到 MLP，根据 MarchingCube 得到点云</p>
<h3 id="PIFu"><a href="#PIFu" class="headerlink" title="PIFu"></a>PIFu</h3><p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230928170950.png" alt="image.png|666"></p>
<p>将输入图像中每个像素的特征通过 MLP 映射为占用场</p>
<h2 id="Depth-amp-Normal-Estimation-1"><a href="#Depth-amp-Normal-Estimation-1" class="headerlink" title="Depth&amp;Normal Estimation"></a>Depth&amp;Normal Estimation</h2><p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230921160120.png" alt="2K2K.png|666"></p>
<p>预测低分辨率法向量图和深度图，$\hat M$ 为预测出的 mask<br>$\mathbf{D}^l=\hat{\mathbf{D}}^l\odot\hat{\mathbf{M}}^l$， $\hat{\mathbf{D}}^l,\hat{\mathbf{M}}^l,\mathbf{N}^l=G^l_{\mathbf{D}}(I^l)$</p>
<p>预测高分辨率 part 法向量图，M 为变换矩阵<br>$\bar{\mathbf{n}}_i=G_{\mathbf{N},i}(\bar{\mathbf{p}}_i,\mathbf{M}_i^{-1}\mathbf{N}^l)$， $\bar{\mathbf{p}}_i=\mathbf{M}_i\mathbf{p}_i,$</p>
<p>拼接为高分辨率整体法向量图<br>$\mathbf{N}^h=\sum\limits_{i=1}^K\left(\mathbf{W}_i\odot\mathbf{n}_i\right)$ ，$\mathbf{n}_i=\mathbf{M}_i^{-1}\bar{\mathbf{n}}_i$</p>
<p>预测高分辨率深度图<br>$\mathbf{D}^h=\hat{\mathbf{D}}^h\odot\hat{\mathbf{M}}^h$，$\hat{\mathbf{D}}^h,\hat{\mathbf{M}}^h=G^h_{\mathbf{D}}(\mathbf{N}^h,\mathbf{D}^l)$</p>
<p>深度图转点云</p>
<h2 id="Generative-approach-1"><a href="#Generative-approach-1" class="headerlink" title="Generative approach"></a>Generative approach</h2><h3 id="Diffusion-Model-Network"><a href="#Diffusion-Model-Network" class="headerlink" title="Diffusion Model Network"></a>Diffusion Model Network</h3><p><a href="Diffusion%20Models.md">Diffusion Model Network学习笔记</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231021114740.png" alt="image.png|666"></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231024111221.png" alt="image.png|444"></p>
<p><strong>3D CNN</strong>: PVCNN、PointNet、PointNet++</p>
<p><strong>2D CNN:</strong> 3D-aware convolution(RODIN)</p>
<h3 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h3><hr>
<h1 id="Paper-about-Human-Reconstruction👇"><a href="#Paper-about-Human-Reconstruction👇" class="headerlink" title="Paper about Human Reconstruction👇"></a>Paper about Human Reconstruction👇</h1><h1 id="NeRF-based-Human-Body-Reconstruction"><a href="#NeRF-based-Human-Body-Reconstruction" class="headerlink" title="NeRF-based Human Body Reconstruction"></a>NeRF-based Human Body Reconstruction</h1><h2 id="HISR"><a href="#HISR" class="headerlink" title="HISR"></a>HISR</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2312.17192">[2312.17192] HISR: Hybrid Implicit Surface Representation for Photorealistic 3D Human Reconstruction (arxiv.org)</a><br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20240104172512.png" alt="image.png|666"></p>
<ul>
<li>对不透明区域（例如身体、脸部、衣服）执行基于表面的渲染</li>
<li>在半透明区域（例如头发）上执行体积渲染</li>
</ul>
<h2 id="DoubleField"><a href="#DoubleField" class="headerlink" title="DoubleField"></a>DoubleField</h2><p><a target="_blank" rel="noopener" href="http://www.liuyebin.com/dbfield/dbfield.html">DoubleField Project Page (liuyebin.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231110163602.png" alt="image.png|666"></p>
<h2 id="Learning-Visibility-Field-for-Detailed-3D-Human-Reconstruction-and-Relighting"><a href="#Learning-Visibility-Field-for-Detailed-3D-Human-Reconstruction-and-Relighting" class="headerlink" title="Learning Visibility Field for Detailed 3D Human Reconstruction and Relighting"></a>Learning Visibility Field for Detailed 3D Human Reconstruction and Relighting</h2><p><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_Learning_Visibility_Field_for_Detailed_3D_Human_Reconstruction_and_Relighting_CVPR_2023_paper.pdf">Learning Visibility Field for Detailed 3D Human Reconstruction and Relighting (thecvf.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008104907.png" alt="image.png|666"></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008105237.png" alt="image.png|666"></p>
<h2 id="HumanGen"><a href="#HumanGen" class="headerlink" title="HumanGen"></a>HumanGen</h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://suezjiang.github.io/humangen/">HumanGen: Generating Human Radiance Fields with Explicit Priors (suezjiang.github.io)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231002104131.png" alt="image.png|666"></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231002104310.png" alt="image.png|333"></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231002104340.png" alt="image.png|666"></p>
<h2 id="GNeuVox"><a href="#GNeuVox" class="headerlink" title="GNeuVox"></a>GNeuVox</h2><p><a target="_blank" rel="noopener" href="https://taoranyi.com/gneuvox/">GNeuVox: Generalizable Neural Voxels for Fast Human Radiance Fields (taoranyi.com)</a><br><a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=4738288024060706817&amp;noteId=1996978666924478208">Generalizable Neural Voxels for Fast Human Radiance Fields (readpaper.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008173458.png" alt="image.png|666"></p>
<h2 id="CAR"><a href="#CAR" class="headerlink" title="CAR"></a>CAR</h2><p><a target="_blank" rel="noopener" href="https://tingtingliao.github.io/CAR/">CAR (tingtingliao.github.io)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008172759.png" alt="image.png|666"></p>
<h2 id="HDHumans"><a href="#HDHumans" class="headerlink" title="HDHumans"></a>HDHumans</h2><p><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/3606927">HDHumans (acm.org)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008193531.png" alt="image.png|666"></p>
<h2 id="EVA3D-2022"><a href="#EVA3D-2022" class="headerlink" title="EVA3D 2022"></a>EVA3D 2022</h2><p>Compositional Human body<br>质量很低<br>Idea：</p>
<ul>
<li>将人体分为几个部分分别训练</li>
<li>将 NeRF 融合进 GAN 的生成器中，并与一个判别器进行联合训练</li>
</ul>
<p>Cost：</p>
<ul>
<li>8 NVIDIA V100 Gpus for 5 days</li>
</ul>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://hongfz16.github.io/projects/EVA3D.html">EVA3D - Project Page (hongfz16.github.io)</a><br><a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=4677480793493209089&amp;noteId=1985412009585125888">EVA3D: Compositional 3D Human Generation from 2D Image Collections (readpaper.com)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230930153949.png" alt="image|666"></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230930154048.png" alt="image.png|666"></p>
<h2 id="Dynamic"><a href="#Dynamic" class="headerlink" title="Dynamic"></a>Dynamic</h2><h3 id="3DGS-Avatar"><a href="#3DGS-Avatar" class="headerlink" title="3DGS-Avatar"></a>3DGS-Avatar</h3><p><a target="_blank" rel="noopener" href="https://neuralbodies.github.io/3DGS-Avatar/">3DGS-Avatar: Animatable Avatars via Deformable 3D Gaussian Splatting (neuralbodies.github.io)</a><br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231218201652.png" alt="image.png|666"></p>
<h3 id="GaussianAvatar"><a href="#GaussianAvatar" class="headerlink" title="GaussianAvatar"></a>GaussianAvatar</h3><p><a target="_blank" rel="noopener" href="https://huliangxiao.github.io/GaussianAvatar">Projectpage of GaussianAvatar (huliangxiao.github.io)</a><br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231205153138.png" alt="image.png|666"></p>
<h3 id="Vid2Avatar"><a href="#Vid2Avatar" class="headerlink" title="Vid2Avatar"></a>Vid2Avatar</h3><blockquote>
<p><a href="Vid2Avatar.md">Vid2Avatar: 3D Avatar Reconstruction from Videos in the Wild via Self-supervised Scene Decomposition</a><br><a target="_blank" rel="noopener" href="https://moygcc.github.io/vid2avatar/">Vid2Avatar: 3D Avatar Reconstruction from Videos in the Wild via Self-supervised Scene Decomposition (moygcc.github.io)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230921171140.png" alt="image.png|666"></p>
<h3 id="Im4D"><a href="#Im4D" class="headerlink" title="Im4D"></a>Im4D</h3><p><a target="_blank" rel="noopener" href="https://zju3dv.github.io/im4d/">Im4D (zju3dv.github.io)</a><br>Im4D: High-Fidelity and Real-Time Novel View Synthesis for Dynamic Scenes</p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231013171508.png" alt="image.png|666"></p>
<h3 id="HumanRF"><a href="#HumanRF" class="headerlink" title="HumanRF"></a>HumanRF</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://synthesiaresearch.github.io/humanrf/">HumanRF: High-Fidelity Neural Radiance Fields for Humans in Motion (synthesiaresearch.github.io)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231001165622.png" alt="image.png|666"></p>
<h3 id="Neural-Body"><a href="#Neural-Body" class="headerlink" title="Neural Body"></a>Neural Body</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://zju3dv.github.io/neuralbody/">Neural Body: Implicit Neural Representations with Structured Latent Codes for Novel View Synthesis of Dynamic Humans (zju3dv.github.io)</a></p>
</blockquote>
<p>首先在SMPL6890个顶点上定义一组潜在代码，然后<br>使用<a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=4498402014756757505&amp;noteId=2065156297063368192">Total Capture: A 3D Deformation Model for Tracking Faces, Hands, and Bodies (readpaper.com)</a><br>从多视图图片中获取SMPL参数$S_{t}$</p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231001170255.png" alt="image.png|666"></p>
<h3 id="InstantNVR"><a href="#InstantNVR" class="headerlink" title="InstantNVR"></a>InstantNVR</h3><p><a target="_blank" rel="noopener" href="https://zju3dv.github.io/instant_nvr/">Learning Neural Volumetric Representations of Dynamic Humans in Minutes (zju3dv.github.io)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231001172828.png" alt="image.png|666"></p>
<h3 id="4K4D"><a href="#4K4D" class="headerlink" title="4K4D"></a>4K4D</h3><p><a target="_blank" rel="noopener" href="https://zju3dv.github.io/4k4d/">4K4D (zju3dv.github.io)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231023154027.png" alt="image.png|666"></p>
<h3 id="D3GA"><a href="#D3GA" class="headerlink" title="D3GA"></a>D3GA</h3><p><a target="_blank" rel="noopener" href="https://zielon.github.io/d3ga/">D3GA - Drivable 3D Gaussian Avatars - Wojciech Zielonka</a></p>
<p>多视图视频作为输入 + 3DGS + 笼形变形</p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231117103528.png" alt="image.png|666"></p>
<h2 id="Human-Object-Interactions"><a href="#Human-Object-Interactions" class="headerlink" title="Human-Object Interactions"></a>Human-Object Interactions</h2><h3 id="Instant-NVR"><a href="#Instant-NVR" class="headerlink" title="Instant-NVR"></a>Instant-NVR</h3><p><a target="_blank" rel="noopener" href="https://nowheretrix.github.io/Instant-NVR/">Instant-NVR: Instant Neural Volumetric Rendering for Human-object Interactions from Monocular RGBD Stream</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008115305.png" alt="image.png|666"></p>
<h3 id="NeuralDome"><a href="#NeuralDome" class="headerlink" title="NeuralDome"></a>NeuralDome</h3><p><a target="_blank" rel="noopener" href="https://juzezhang.github.io/NeuralDome/">NeuralDome (juzezhang.github.io)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008120011.png" alt="image.png|666"></p>
<h1 id="PIFu-Occupancy-Field"><a href="#PIFu-Occupancy-Field" class="headerlink" title="PIFu Occupancy Field"></a>PIFu Occupancy Field</h1><blockquote>
<p><a href="PIFu.md">PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization</a><br><a target="_blank" rel="noopener" href="https://shunsukesaito.github.io/PIFu/">PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization (shunsukesaito.github.io)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230928170950.png" alt="image.png|666"></p>
<h2 id="PIFuHD"><a href="#PIFuHD" class="headerlink" title="PIFuHD"></a>PIFuHD</h2><blockquote>
<p><a href="PIFuHD.md">PIFuHD: Multi-Level Pixel-Aligned Implicit Function for High-Resolution 3D Human Digitization</a><br><a target="_blank" rel="noopener" href="https://shunsukesaito.github.io/PIFuHD/">PIFuHD: Multi-Level Pixel-Aligned Implicit Function for High-Resolution 3D Human Digitization (shunsukesaito.github.io)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230928175323.png" alt="image.png|666"></p>
<h2 id="PIFu-for-the-Real-World"><a href="#PIFu-for-the-Real-World" class="headerlink" title="PIFu for the Real World"></a>PIFu for the Real World</h2><p><a target="_blank" rel="noopener" href="https://github.com/X-zhangyang/SelfPIFu--PIFu-for-the-Real-World">X-zhangyang/SelfPIFu—PIFu-for-the-Real-World: Dressed Human Reconstrcution from Single-view Real World Image (github.com)</a><br><a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=4660017586591776769&amp;noteId=1996688855483354880">PIFu for the Real World: A Self-supervised Framework to Reconstruct Dressed Human from Single-view Images (readpaper.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008194000.png" alt="image.png|666"></p>
<h2 id="DIFu"><a href="#DIFu" class="headerlink" title="DIFu"></a>DIFu</h2><p><a target="_blank" rel="noopener" href="https://eadcat.github.io/DIFu/">DIFu: Depth-Guided Implicit Function for Clothed Human Reconstruction (eadcat.github.io)</a><br><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Song_DIFu_Depth-Guided_Implicit_Function_for_Clothed_Human_Reconstruction_CVPR_2023_paper.pdf">DIFu: Depth-Guided Implicit Function for Clothed Human Reconstruction (thecvf.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008114221.png" alt="image.png|666"></p>
<h2 id="SeSDF"><a href="#SeSDF" class="headerlink" title="SeSDF"></a>SeSDF</h2><p><a target="_blank" rel="noopener" href="https://yukangcao.github.io/SeSDF/">SeSDF: Self-evolved Signed Distance Field for Implicit 3D Clothed Human Reconstruction (yukangcao.github.io)</a><br><a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=4740902287992438785&amp;noteId=1996730143273232896">SeSDF: Self-evolved Signed Distance Field for Implicit 3D Clothed Human Reconstruction (readpaper.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008113348.png" alt="image.png|666"></p>
<h2 id="UNIF"><a href="#UNIF" class="headerlink" title="UNIF"></a>UNIF</h2><p><a target="_blank" rel="noopener" href="https://shenhanqian.github.io/unif">UNIF: United Neural Implicit Functions for Clothed Human Reconstruction and Animation | Shenhan Qian</a><br><a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=4648065386802069505&amp;noteId=1996740483288731392">UNIF: United Neural Implicit Functions for Clothed Human Reconstruction and Animation (readpaper.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008163003.png" alt="image.png|666"></p>
<h2 id="Structured-3D-Features"><a href="#Structured-3D-Features" class="headerlink" title="Structured 3D Features"></a>Structured 3D Features</h2><p>Reconstructing <strong>Relightable</strong> and <strong>Animatable</strong> Avatars<br><a target="_blank" rel="noopener" href="https://enriccorona.github.io/s3f/">Enric Corona</a><br><a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=4700589883291336705&amp;noteId=1996756493166029056">Structured 3D Features for Reconstructing Relightable and Animatable Avatars (readpaper.com)</a></p>
<p>X,3d fea,2d fea —&gt; transformer —&gt; sdf, albedo<br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008174219.png" alt="image.png|666"></p>
<h2 id="GTA"><a href="#GTA" class="headerlink" title="GTA"></a>GTA</h2><p><a target="_blank" rel="noopener" href="https://river-zhang.github.io/GTA-projectpage/">Global-correlated 3D-decoupling Transformer for Clothed Avatar Reconstruction (river-zhang.github.io)</a><br><a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=4804636732393783297&amp;noteId=2021327250504312576">Global-correlated 3D-decoupling Transformer for Clothed Avatar Reconstruction (readpaper.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231016094412.png" alt="image.png|666"></p>
<h2 id="Get3DHuman"><a href="#Get3DHuman" class="headerlink" title="Get3DHuman"></a>Get3DHuman</h2><p><a target="_blank" rel="noopener" href="https://x-zhangyang.github.io/2023_Get3DHuman/">Get3DHuman: Lifting StyleGAN-Human into a 3D Generative Model using Pixel-aligned Reconstruction Priors. (x-zhangyang.github.io)</a></p>
<p>GAN + PIFus<br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231023160121.png" alt="image.png|666"></p>
<h2 id="DRIFu"><a href="#DRIFu" class="headerlink" title="DRIFu"></a>DRIFu</h2><p><a target="_blank" rel="noopener" href="https://github.com/kuangzijian/drifu-for-animals">kuangzijian/drifu-for-animals: meta-learning based pifu model for animals (github.com)</a></p>
<p>鸟类PIFu<br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231123151648.png" alt="image.png|666"><br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231123151707.png" alt="image.png|666"></p>
<h3 id="SIFU"><a href="#SIFU" class="headerlink" title="SIFU"></a>SIFU</h3><p><a target="_blank" rel="noopener" href="https://river-zhang.github.io/SIFU-projectpage/">SIFU Project Page (river-zhang.github.io)</a><br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231218204004.png" alt="image.png|666"></p>
<h1 id="Depth-amp-Normal-Estimation-2"><a href="#Depth-amp-Normal-Estimation-2" class="headerlink" title="Depth&amp;Normal Estimation"></a>Depth&amp;Normal Estimation</h1><p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230930182135.png" alt="image.png|444"></p>
<h2 id="ICON"><a href="#ICON" class="headerlink" title="ICON"></a>ICON</h2><blockquote>
<p><a href="ICON.md">ICON: Implicit Clothed humans Obtained from Normals</a><br><a target="_blank" rel="noopener" href="https://icon.is.tue.mpg.de/">ICON (mpg.de)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230930162915.png" alt="image.png|666"></p>
<h2 id="ECON"><a href="#ECON" class="headerlink" title="ECON"></a>ECON</h2><blockquote>
<p><a href="ECON.md">ECON: Explicit Clothed humans Obtained from Normals</a><br><a target="_blank" rel="noopener" href="https://xiuyuliang.cn/econ/">ECON: Explicit Clothed humans Optimized via Normal integration (xiuyuliang.cn)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230930173026.png" alt="image.png|666"></p>
<h2 id="2K2K"><a href="#2K2K" class="headerlink" title="2K2K"></a>2K2K</h2><p>DepthEstimation</p>
<blockquote>
<p><a href="2K2K.md">2K2K：High-fidelity 3D Human Digitization from Single 2K Resolution Images</a><br><a target="_blank" rel="noopener" href="https://sanghunhan92.github.io/conference/2K2K/">High-fidelity 3D Human Digitization from Single 2K Resolution Images Project Page (sanghunhan92.github.io)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230921160120.png" alt="image.png|666"></p>
<h2 id="MVSNet"><a href="#MVSNet" class="headerlink" title="MVSNet"></a>MVSNet</h2><p>DepthEstimation</p>
<blockquote>
<p><a href="MVSNet.md">MVSNet: Depth Inference for Unstructured Multi-view Stereo</a><br><a target="_blank" rel="noopener" href="https://github.com/YoYo000/MVSNet">YoYo000/MVSNet: MVSNet (ECCV2018) &amp; R-MVSNet (CVPR2019) (github.com)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231002110228.png" alt="image.png|666"></p>
<h2 id="GC-MVSNet"><a href="#GC-MVSNet" class="headerlink" title="GC-MVSNet"></a>GC-MVSNet</h2><p>多尺度+多视图几何一致性<br><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.19583">GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View Stereo (arxiv.org)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231031172920.png" alt="image.png|666"></p>
<h2 id="MonoDiffusion"><a href="#MonoDiffusion" class="headerlink" title="MonoDiffusion"></a>MonoDiffusion</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.07198">MonoDiffusion: Self-Supervised Monocular Depth Estimation Using Diffusion Model</a></p>
<p>用 Diffusion Model 进行深度估计(自动驾驶)</p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231116153515.png" alt="image.png|666"></p>
<h2 id="NDDepth"><a href="#NDDepth" class="headerlink" title="NDDepth"></a>NDDepth</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.07166">NDDepth: Normal-Distance Assisted Monocular Depth Estimation and Completion</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231116153659.png" alt="image.png|666"></p>
<h2 id="OccNeRF"><a href="#OccNeRF" class="headerlink" title="OccNeRF"></a>OccNeRF</h2><p><a target="_blank" rel="noopener" href="https://github.com/LinShan-Bin/OccNeRF">LinShan-Bin/OccNeRF: Code of “OccNeRF: Self-Supervised Multi-Camera Occupancy Prediction with Neural Radiance Fields”. (github.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231218200234.png" alt="image.png|666"></p>
<h1 id="Other"><a href="#Other" class="headerlink" title="Other"></a>Other</h1><h2 id="Texture"><a href="#Texture" class="headerlink" title="Texture"></a>Texture</h2><h3 id="Paint3D"><a href="#Paint3D" class="headerlink" title="Paint3D"></a>Paint3D</h3><p><a target="_blank" rel="noopener" href="https://github.com/OpenTexture/Paint3D">OpenTexture/Paint3D: Paint3D: Paint Anything 3D with Lighting-Less Texture Diffusion Models, a no lighting baked texture generative model (github.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231223172838.png" alt="image.png|666"></p>
<h2 id="Explicit-Template-Decomposition"><a href="#Explicit-Template-Decomposition" class="headerlink" title="Explicit Template Decomposition"></a>Explicit Template Decomposition</h2><h3 id="TeCH"><a href="#TeCH" class="headerlink" title="TeCH"></a>TeCH</h3><p><a target="_blank" rel="noopener" href="https://huangyangyi.github.io/TeCH/">TeCH: Text-guided Reconstruction of Lifelike Clothed Humans (huangyangyi.github.io)</a></p>
<p>DMTet 表示：consists of an explicit body shape grid and an implicit distance field<br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231102112309.png" alt="image.png|666"></p>
<h3 id="CloSET"><a href="#CloSET" class="headerlink" title="CloSET"></a>CloSET</h3><p><a target="_blank" rel="noopener" href="https://www.liuyebin.com/closet/">CloSET CVPR 2023 (liuyebin.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008110803.png" alt="image.png|666"></p>
<h3 id="Chupa"><a href="#Chupa" class="headerlink" title="Chupa"></a>Chupa</h3><p><a target="_blank" rel="noopener" href="https://snuvclab.github.io/chupa/">Chupa (snuvclab.github.io)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008164813.png" alt="image.png|666"></p>
<h2 id="Human-Face"><a href="#Human-Face" class="headerlink" title="Human Face"></a>Human Face</h2><h2 id="GPAvatar"><a href="#GPAvatar" class="headerlink" title="GPAvatar"></a>GPAvatar</h2><p><a target="_blank" rel="noopener" href="https://github.com/xg-chu/GPAvatar">xg-chu/GPAvatar: [ICLR 2024] Generalizable and Precise Head Avatar from Image(s) (github.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20240122172842.png" alt="image.png|666"></p>
<h3 id="HeadRecon"><a href="#HeadRecon" class="headerlink" title="HeadRecon"></a>HeadRecon</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2312.08863">[2312.08863] HeadRecon: High-Fidelity 3D Head Reconstruction from Monocular Video (arxiv.org)</a><br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231218201501.png" alt="image.png|666"></p>
<h3 id="GaussianHead"><a href="#GaussianHead" class="headerlink" title="GaussianHead"></a>GaussianHead</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2312.01632">[2312.01632] GaussianHead: Impressive 3D Gaussian-based Head Avatars with Dynamic Hybrid Neural Field (arxiv.org)</a><br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231205153845.png" alt="image.png|666"></p>
<h3 id="GaussianAvatars"><a href="#GaussianAvatars" class="headerlink" title="GaussianAvatars"></a>GaussianAvatars</h3><p><a target="_blank" rel="noopener" href="https://shenhanqian.github.io/gaussian-avatars">GaussianAvatars: Photorealistic Head Avatars with Rigged 3D Gaussians | Shenhan Qian</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/picturesmethod.jpg" alt="method.jpg|666"></p>
<h3 id="TRAvatar"><a href="#TRAvatar" class="headerlink" title="TRAvatar"></a>TRAvatar</h3><p><a target="_blank" rel="noopener" href="https://travatar-paper.github.io/">Towards Practical Capture of High-Fidelity Relightable Avatars (travatar-paper.github.io)</a></p>
<p>动态人脸<br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231121121931.png" alt="image.png|666"></p>
<h3 id="FLARE"><a href="#FLARE" class="headerlink" title="FLARE"></a>FLARE</h3><p><a target="_blank" rel="noopener" href="https://flare.is.tue.mpg.de/">FLARE (mpg.de)</a></p>
<p>FLARE: Fast Learning of Animatable and Relightable Mesh Avatars</p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231114093649.png" alt="image.png|666"></p>
<h3 id="HRN"><a href="#HRN" class="headerlink" title="HRN"></a>HRN</h3><blockquote>
<p><a href="HRN.md">A Hierarchical Representation Network for Accurate and Detailed Face Reconstruction from In-The-Wild Images</a><br><a target="_blank" rel="noopener" href="https://younglbw.github.io/HRN-homepage/">HRN (younglbw.github.io)</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20230921173632.png" alt="image.png|666"></p>
<h3 id="单目-3D-人脸重建"><a href="#单目-3D-人脸重建" class="headerlink" title="单目 3D 人脸重建"></a>单目 3D 人脸重建</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.19580">A Perceptual Shape Loss for Monocular 3D Face Reconstruction</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231031181210.png" alt="image.png|666"></p>
<h3 id="BakedAvatar"><a href="#BakedAvatar" class="headerlink" title="BakedAvatar"></a>BakedAvatar</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2311.05521.pdf">BakedAvatar: Baking Neural Fields for Real-Time Head Avatar Synthesis (arxiv.org)</a></p>
<p>头部实时新视图生成<br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231110155612.png" alt="image.png|666"></p>
<h3 id="Video"><a href="#Video" class="headerlink" title="Video"></a>Video</h3><ul>
<li><strong>3D-Aware Talking-Head Video Motion Transfer</strong> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.02549">https://arxiv.org/abs/2311.02549</a></li>
<li><a target="_blank" rel="noopener" href="https://yudeng.github.io/Portrait4D/">Portrait4D: Learning One-Shot 4D Head Avatar Synthesis using Synthetic Data (yudeng.github.io)</a></li>
<li><a target="_blank" rel="noopener" href="https://tobias-kirschstein.github.io/diffusion-avatars/">DiffusionAvatars: Deferred Diffusion for High-fidelity 3D Head Avatars (tobias-kirschstein.github.io)</a></li>
<li><a target="_blank" rel="noopener" href="https://ustc3dv.github.io/CosAvatar/">CosAvatar (ustc3dv.github.io)</a></li>
</ul>
<h2 id="Segmented-Instance-Object"><a href="#Segmented-Instance-Object" class="headerlink" title="Segmented Instance/Object"></a>Segmented Instance/Object</h2><h3 id="Registered-and-Segmented-Deformable-Object-Reconstruction-from-a-Single-View-Point-Cloud"><a href="#Registered-and-Segmented-Deformable-Object-Reconstruction-from-a-Single-View-Point-Cloud" class="headerlink" title="Registered and Segmented Deformable Object Reconstruction from a Single View Point Cloud"></a>Registered and Segmented Deformable Object Reconstruction from a Single View Point Cloud</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.07357">Registered and Segmented Deformable Object Reconstruction from a Single View Point Cloud</a></p>
<p>配准 + 分割物体重建<br><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231116153203.png" alt="image.png|666"></p>
<h3 id="3DFusion-A-real-time-3D-object-reconstruction-pipeline-based-on-streamed-instance-segmented-data"><a href="#3DFusion-A-real-time-3D-object-reconstruction-pipeline-based-on-streamed-instance-segmented-data" class="headerlink" title="3DFusion, A real-time 3D object reconstruction pipeline based on streamed instance segmented data"></a>3DFusion, A real-time 3D object reconstruction pipeline based on streamed instance segmented data</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.06659">3DFusion, A real-time 3D object reconstruction pipeline based on streamed instance segmented data</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231116153353.png" alt="image.png|555"></p>
<h2 id="Human-Body-Shape-Completion"><a href="#Human-Body-Shape-Completion" class="headerlink" title="Human Body Shape Completion"></a>Human Body Shape Completion</h2><p><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Human_Body_Shape_Completion_With_Implicit_Shape_and_Flow_Learning_CVPR_2023_paper.pdf">Human Body Shape Completion With Implicit Shape and Flow Learning (thecvf.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008160354.png" alt="image.png|666"></p>
<h2 id="Incomplete-Image"><a href="#Incomplete-Image" class="headerlink" title="Incomplete Image"></a>Incomplete Image</h2><p>Complete 3D Human Reconstruction from a Single Incomplete Image</p>
<p><a target="_blank" rel="noopener" href="https://junyingw.github.io/paper/3d_inpainting/">Complete 3D Human Reconstruction from a Single Incomplete Image (junyingw.github.io)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008114841.png" alt="image.png|666"></p>
<h2 id="New-NetWork-FeatER"><a href="#New-NetWork-FeatER" class="headerlink" title="New NetWork FeatER"></a>New NetWork FeatER</h2><p><a target="_blank" rel="noopener" href="https://zczcwh.github.io/feater_page/">FeatER: An Efficient Network for Human Reconstruction via Feature Map-Based TransformER (zczcwh.github.io)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231008160659.png" alt="image.png|666"></p>
<h2 id="HF-Avatar"><a href="#HF-Avatar" class="headerlink" title="HF-Avatar"></a>HF-Avatar</h2><p><a target="_blank" rel="noopener" href="https://github.com/hzhao1997/HF-Avatar?tab=readme-ov-file">hzhao1997/HF-Avatar (github.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures/20231017182026.png" alt="image.png|666"></p>
<h2 id="多模态数字人生成-数字人视频"><a href="#多模态数字人生成-数字人视频" class="headerlink" title="多模态数字人生成(数字人视频)"></a>多模态数字人生成(数字人视频)</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2310.20251.pdf">An Implementation of Multimodal Fusion System for Intelligent Digital Human Generation</a></p>
<p>输入：文本、音频、图片<br>输出：自定义人物视频(图片/+修改/+风格化)+音频(文本合成+音频音色参考)</p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231101153147.png" alt="image.png|666"></p>
<h3 id="IPVNet"><a href="#IPVNet" class="headerlink" title="IPVNet"></a>IPVNet</h3><p><a target="_blank" rel="noopener" href="https://github.com/robotic-vision-lab/Implicit-Point-Voxel-Features-Network">robotic-vision-lab/Implicit-Point-Voxel-Features-Network: Implicit deep neural network for 3D surface reconstruction. (github.com)</a></p>
<p><img src="https://raw.githubusercontent.com/qiyun71/Blog_images/main/pictures20231108222654.png" alt="image.png|666"></p>

    </div>

    
    
    
        

  <div class="followme">
    <p>Welcome to my other publishing channels</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="https://t.me/+1ZnNxFWnEbk5YzRl">
            <span class="icon">
              <i class="fab fa-telegram"></i>
            </span>

            <span class="label">Telegram</span>
          </a>
        </div>
    </div>
  </div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/3DReconstruction/" rel="tag"><i class="fa fa-tag"></i> 3DReconstruction</a>
              <a href="/tags/ClothedHumans/" rel="tag"><i class="fa fa-tag"></i> ClothedHumans</a>
              <a href="/tags/PointCloud/" rel="tag"><i class="fa fa-tag"></i> PointCloud</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/3DReconstruction/Multi-view/Depth%20Estimation/GeoMVSNet/" rel="prev" title="GeoMVSNet">
      <i class="fa fa-chevron-left"></i> GeoMVSNet
    </a></div>
      <div class="post-nav-item">
    <a href="/3DReconstruction/Basics%20about%203D%20Reconstruction/" rel="next" title="Basics about 3D Reconstruction">
      Basics about 3D Reconstruction <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BA%BA%E4%BD%93%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E6%96%B9%E6%B3%95%E7%BB%BC%E8%BF%B0"><span class="nav-text">人体三维重建方法综述</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Implicit-Function"><span class="nav-text">Implicit Function</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Depth-amp-Normal-Estimation"><span class="nav-text">Depth&amp;Normal Estimation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Generative-approach"><span class="nav-text">Generative approach</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B7%B7%E5%90%88%E6%96%B9%E6%B3%95"><span class="nav-text">混合方法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E6%96%B9%E6%B3%95%E6%B5%81%E7%A8%8B%E5%AF%B9%E6%AF%94"><span class="nav-text">三维重建方法流程对比</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Implicit-Function-1"><span class="nav-text">Implicit Function</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#NeRF"><span class="nav-text">NeRF</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PIFu"><span class="nav-text">PIFu</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Depth-amp-Normal-Estimation-1"><span class="nav-text">Depth&amp;Normal Estimation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Generative-approach-1"><span class="nav-text">Generative approach</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Diffusion-Model-Network"><span class="nav-text">Diffusion Model Network</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GAN"><span class="nav-text">GAN</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper-about-Human-Reconstruction%F0%9F%91%87"><span class="nav-text">Paper about Human Reconstruction👇</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#NeRF-based-Human-Body-Reconstruction"><span class="nav-text">NeRF-based Human Body Reconstruction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#HISR"><span class="nav-text">HISR</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DoubleField"><span class="nav-text">DoubleField</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Learning-Visibility-Field-for-Detailed-3D-Human-Reconstruction-and-Relighting"><span class="nav-text">Learning Visibility Field for Detailed 3D Human Reconstruction and Relighting</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HumanGen"><span class="nav-text">HumanGen</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GNeuVox"><span class="nav-text">GNeuVox</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CAR"><span class="nav-text">CAR</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDHumans"><span class="nav-text">HDHumans</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#EVA3D-2022"><span class="nav-text">EVA3D 2022</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Dynamic"><span class="nav-text">Dynamic</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3DGS-Avatar"><span class="nav-text">3DGS-Avatar</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GaussianAvatar"><span class="nav-text">GaussianAvatar</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Vid2Avatar"><span class="nav-text">Vid2Avatar</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Im4D"><span class="nav-text">Im4D</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HumanRF"><span class="nav-text">HumanRF</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Neural-Body"><span class="nav-text">Neural Body</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#InstantNVR"><span class="nav-text">InstantNVR</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4K4D"><span class="nav-text">4K4D</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#D3GA"><span class="nav-text">D3GA</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Human-Object-Interactions"><span class="nav-text">Human-Object Interactions</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Instant-NVR"><span class="nav-text">Instant-NVR</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NeuralDome"><span class="nav-text">NeuralDome</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#PIFu-Occupancy-Field"><span class="nav-text">PIFu Occupancy Field</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#PIFuHD"><span class="nav-text">PIFuHD</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PIFu-for-the-Real-World"><span class="nav-text">PIFu for the Real World</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DIFu"><span class="nav-text">DIFu</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SeSDF"><span class="nav-text">SeSDF</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#UNIF"><span class="nav-text">UNIF</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Structured-3D-Features"><span class="nav-text">Structured 3D Features</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GTA"><span class="nav-text">GTA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Get3DHuman"><span class="nav-text">Get3DHuman</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DRIFu"><span class="nav-text">DRIFu</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#SIFU"><span class="nav-text">SIFU</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Depth-amp-Normal-Estimation-2"><span class="nav-text">Depth&amp;Normal Estimation</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#ICON"><span class="nav-text">ICON</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ECON"><span class="nav-text">ECON</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2K2K"><span class="nav-text">2K2K</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MVSNet"><span class="nav-text">MVSNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GC-MVSNet"><span class="nav-text">GC-MVSNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MonoDiffusion"><span class="nav-text">MonoDiffusion</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NDDepth"><span class="nav-text">NDDepth</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#OccNeRF"><span class="nav-text">OccNeRF</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Other"><span class="nav-text">Other</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Texture"><span class="nav-text">Texture</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Paint3D"><span class="nav-text">Paint3D</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Explicit-Template-Decomposition"><span class="nav-text">Explicit Template Decomposition</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#TeCH"><span class="nav-text">TeCH</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CloSET"><span class="nav-text">CloSET</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Chupa"><span class="nav-text">Chupa</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Human-Face"><span class="nav-text">Human Face</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GPAvatar"><span class="nav-text">GPAvatar</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#HeadRecon"><span class="nav-text">HeadRecon</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GaussianHead"><span class="nav-text">GaussianHead</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GaussianAvatars"><span class="nav-text">GaussianAvatars</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TRAvatar"><span class="nav-text">TRAvatar</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#FLARE"><span class="nav-text">FLARE</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HRN"><span class="nav-text">HRN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%95%E7%9B%AE-3D-%E4%BA%BA%E8%84%B8%E9%87%8D%E5%BB%BA"><span class="nav-text">单目 3D 人脸重建</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#BakedAvatar"><span class="nav-text">BakedAvatar</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Video"><span class="nav-text">Video</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Segmented-Instance-Object"><span class="nav-text">Segmented Instance&#x2F;Object</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Registered-and-Segmented-Deformable-Object-Reconstruction-from-a-Single-View-Point-Cloud"><span class="nav-text">Registered and Segmented Deformable Object Reconstruction from a Single View Point Cloud</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3DFusion-A-real-time-3D-object-reconstruction-pipeline-based-on-streamed-instance-segmented-data"><span class="nav-text">3DFusion, A real-time 3D object reconstruction pipeline based on streamed instance segmented data</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Human-Body-Shape-Completion"><span class="nav-text">Human Body Shape Completion</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Incomplete-Image"><span class="nav-text">Incomplete Image</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#New-NetWork-FeatER"><span class="nav-text">New NetWork FeatER</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HF-Avatar"><span class="nav-text">HF-Avatar</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E6%A8%A1%E6%80%81%E6%95%B0%E5%AD%97%E4%BA%BA%E7%94%9F%E6%88%90-%E6%95%B0%E5%AD%97%E4%BA%BA%E8%A7%86%E9%A2%91"><span class="nav-text">多模态数字人生成(数字人视频)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#IPVNet"><span class="nav-text">IPVNet</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Qi Yun"
      src="/images/avatar.jpeg">
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">132</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">24</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">57</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/qiyun71" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;qiyun71" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://space.bilibili.com/29010355" title="Bilibili → https:&#x2F;&#x2F;space.bilibili.com&#x2F;29010355" rel="noopener" target="_blank"><i class="fa fa-star fa-fw"></i>Bilibili</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2020 – 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Qi Yun</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="Symbols count total">463k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">28:04</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/yqq/anime.min.js"></script>
  <script src="/yqq/velocity/velocity.min.js"></script>
  <script src="/yqq/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="//cdn.jsdelivr.net/gh/theme-next/theme-next-three@1/three.min.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
